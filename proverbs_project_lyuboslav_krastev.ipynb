{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "injured-pledge",
   "metadata": {},
   "source": [
    "# Project name: Proverb Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-zimbabwe",
   "metadata": {},
   "source": [
    "## Project author: Lyuboslav Krastev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-toronto",
   "metadata": {},
   "source": [
    "## Section I: Generate Bulgarian proverbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-royalty",
   "metadata": {},
   "source": [
    "### Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-closing",
   "metadata": {},
   "source": [
    "Recently I found myself browsing Bulgarian proverbs from A-Z and thinking that we have too few of those. Thus I decided to expand the list by attempting to generate some new ones through machine learning. I built the dataset by using the most extensive list of Bulgarian proverbs I found online. <br>\n",
    "Source: https://bg.wikiquote.org/wiki/Български_пословици_и_поговорки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-tsunami",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "above-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten, LSTM, Dropout, Reshape, Activation,Bidirectional,Layer\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import optimizers,activations,initializers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-value",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-bottom",
   "metadata": {},
   "source": [
    "#### Read the dataset and check the number of characters in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thorough-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus number of characters: 30896\n"
     ]
    }
   ],
   "source": [
    "with io.open('./data/bg_proverbs.txt', encoding='utf-8') as f:\n",
    "    text = f.read().lower().replace('\\n', ' \\n ')\n",
    "print('Corpus number of characters:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-mills",
   "metadata": {},
   "source": [
    "#### Check the number of words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "provincial-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus number of words: 6251\n"
     ]
    }
   ],
   "source": [
    "words = [w for w in text.split(' ') if w.strip() != '' or w == '\\n']\n",
    "print('Corpus number of words:', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-geometry",
   "metadata": {},
   "source": [
    "There are 827 proverbs in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-marriage",
   "metadata": {},
   "source": [
    "#### Visualise the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "featured-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n      826\n",
      "не      212\n",
      "се      181\n",
      "да      145\n",
      "и       112\n",
      "е       104\n",
      "на       97\n",
      "като     75\n",
      "си       70\n",
      "от       64\n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "word_df = pd.DataFrame(words,columns=['word'])\n",
    "top = word_df.word.value_counts().head(10)\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "durable-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=100,\n",
    "               max_font_size=50, random_state=42)\n",
    "output = wc.generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(output,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-scheme",
   "metadata": {},
   "source": [
    "Most of the words that can be observed above are actually stop words, however since I am performing text generation I will not be removing them. It is crucial to have these tokens when the goal is to generate text. <br>\n",
    "Source: https://medium.com/@limavallantin/why-is-removing-stop-words-not-always-a-good-idea-c8d35bd77214"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-pizza",
   "metadata": {},
   "source": [
    "#### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pursuant-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub('\\[,.*?“”…\\]', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-garbage",
   "metadata": {},
   "source": [
    "#### Convert the text into input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "formal-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed for reproducible results\n",
    "tf.compat.v1.set_random_seed(64)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "corpus = [w for w in text.split('\\n') \n",
    "          if w.strip() != '' or w == '\\n']\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "TOTAL_WORDS = len(tokenizer.word_index)+1\n",
    "input_seq = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_seq = token_list[:i+1]\n",
    "        input_seq.append(n_gram_seq)\n",
    "\n",
    "MAX_SEQ_LEN = max([len(x) for x in input_seq])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_seq,\n",
    "                           maxlen=MAX_SEQ_LEN, padding='pre'))\n",
    "xs = input_sequences[:,:-1]\n",
    "labels = input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=TOTAL_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-replacement",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-yorkshire",
   "metadata": {},
   "source": [
    "#### Objective: Build and select a model for Bulgarian proverb generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-walter",
   "metadata": {},
   "source": [
    "I decided to use an LSTM, as it is said to be the most efficient in text generation and it has an acceptable loss amount.\n",
    "Soruce: https://arxiv.org/ftp/arxiv/papers/1908/1908.04332.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-blink",
   "metadata": {},
   "source": [
    "##### Why I chose BiLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-direction",
   "metadata": {},
   "source": [
    "Bidirectional networks have access to the past as well as the future information and hence the output is generated from both the past and future context. As far as I understand, they have a better understanding of the context than unidirectional networks and yield better results.\n",
    "To predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-warning",
   "metadata": {},
   "source": [
    "I will be using softmax activation to compute the probability of the output class, because it is appropriate for multinomial mutually exclusive classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-tobago",
   "metadata": {},
   "source": [
    "#### Single Bidirectional LSTM layer model 300 epochs 128 units 0.001 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "progressive-insulin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "145/145 [==============================] - 7s 22ms/step - loss: 7.0815 - accuracy: 0.0337\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 2s 15ms/step - loss: 6.4347 - accuracy: 0.0413\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.3372 - accuracy: 0.0404\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.2463 - accuracy: 0.0462\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1368 - accuracy: 0.0586\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0368 - accuracy: 0.0545\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9063 - accuracy: 0.0568\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7666 - accuracy: 0.0635\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7333 - accuracy: 0.0598\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5471 - accuracy: 0.0731\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4223 - accuracy: 0.0774\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3399 - accuracy: 0.0747\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1765 - accuracy: 0.0831\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9842 - accuracy: 0.0970\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9959 - accuracy: 0.0911\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7678 - accuracy: 0.1046\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7059 - accuracy: 0.1129\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5586 - accuracy: 0.1242\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4325 - accuracy: 0.1360\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3697 - accuracy: 0.1467\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2059 - accuracy: 0.1598\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0870 - accuracy: 0.1826\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0117 - accuracy: 0.1882\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8883 - accuracy: 0.2028\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.7991 - accuracy: 0.2205\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.6923 - accuracy: 0.2272\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.5910 - accuracy: 0.2323\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.5123 - accuracy: 0.2661\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.4163 - accuracy: 0.2825\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.3367 - accuracy: 0.3026\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.3180 - accuracy: 0.2897\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.2038 - accuracy: 0.3148\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0654 - accuracy: 0.3457\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0036 - accuracy: 0.3508\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9807 - accuracy: 0.3604\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8856 - accuracy: 0.3808\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.7570 - accuracy: 0.4124\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.7547 - accuracy: 0.4039\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.7301 - accuracy: 0.4148\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.6088 - accuracy: 0.4344\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.5899 - accuracy: 0.4282\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.5003 - accuracy: 0.4420\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.4759 - accuracy: 0.4598\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.4010 - accuracy: 0.4645\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.3942 - accuracy: 0.4697\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.3573 - accuracy: 0.4770\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.2359 - accuracy: 0.5053\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.2543 - accuracy: 0.4810\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.1615 - accuracy: 0.5129\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.0838 - accuracy: 0.5360\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.0967 - accuracy: 0.5129\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.0559 - accuracy: 0.5402\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.0169 - accuracy: 0.5328\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.0226 - accuracy: 0.5293\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.9300 - accuracy: 0.5673\n",
      "Epoch 56/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.9017 - accuracy: 0.5601\n",
      "Epoch 57/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.9377 - accuracy: 0.5611\n",
      "Epoch 58/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.8305 - accuracy: 0.5821\n",
      "Epoch 59/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.7827 - accuracy: 0.5777\n",
      "Epoch 60/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.7686 - accuracy: 0.6039\n",
      "Epoch 61/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.7758 - accuracy: 0.5849\n",
      "Epoch 62/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.7420 - accuracy: 0.5816\n",
      "Epoch 63/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.6592 - accuracy: 0.6025\n",
      "Epoch 64/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.6044 - accuracy: 0.6258\n",
      "Epoch 65/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5905 - accuracy: 0.6190\n",
      "Epoch 66/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5932 - accuracy: 0.6088\n",
      "Epoch 67/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5545 - accuracy: 0.6301\n",
      "Epoch 68/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5480 - accuracy: 0.6334\n",
      "Epoch 69/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5426 - accuracy: 0.6366\n",
      "Epoch 70/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5078 - accuracy: 0.6423\n",
      "Epoch 71/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5073 - accuracy: 0.6336\n",
      "Epoch 72/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.4543 - accuracy: 0.6639\n",
      "Epoch 73/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.4575 - accuracy: 0.6452\n",
      "Epoch 74/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3832 - accuracy: 0.6566\n",
      "Epoch 75/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3614 - accuracy: 0.6703\n",
      "Epoch 76/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3713 - accuracy: 0.6694\n",
      "Epoch 77/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3148 - accuracy: 0.6858\n",
      "Epoch 78/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3397 - accuracy: 0.6593\n",
      "Epoch 79/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3225 - accuracy: 0.6821\n",
      "Epoch 80/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3063 - accuracy: 0.6900\n",
      "Epoch 81/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2768 - accuracy: 0.6838\n",
      "Epoch 82/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2389 - accuracy: 0.6951\n",
      "Epoch 83/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2697 - accuracy: 0.6800\n",
      "Epoch 84/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2258 - accuracy: 0.6979\n",
      "Epoch 85/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2262 - accuracy: 0.6931\n",
      "Epoch 86/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1799 - accuracy: 0.7079\n",
      "Epoch 87/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2064 - accuracy: 0.6996\n",
      "Epoch 88/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1842 - accuracy: 0.7120\n",
      "Epoch 89/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2118 - accuracy: 0.6951\n",
      "Epoch 90/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1610 - accuracy: 0.7065\n",
      "Epoch 91/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1494 - accuracy: 0.7187\n",
      "Epoch 92/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1032 - accuracy: 0.7286\n",
      "Epoch 93/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1340 - accuracy: 0.7095\n",
      "Epoch 94/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0837 - accuracy: 0.7214\n",
      "Epoch 95/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1027 - accuracy: 0.7192\n",
      "Epoch 96/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0776 - accuracy: 0.7288\n",
      "Epoch 97/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0364 - accuracy: 0.7341\n",
      "Epoch 98/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0485 - accuracy: 0.7348\n",
      "Epoch 99/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0497 - accuracy: 0.7304\n",
      "Epoch 100/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0061 - accuracy: 0.7421\n",
      "Epoch 101/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0071 - accuracy: 0.7488\n",
      "Epoch 102/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9928 - accuracy: 0.7400\n",
      "Epoch 103/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0055 - accuracy: 0.7419\n",
      "Epoch 104/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9861 - accuracy: 0.7461\n",
      "Epoch 105/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9544 - accuracy: 0.7594\n",
      "Epoch 106/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0277 - accuracy: 0.7399\n",
      "Epoch 107/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9445 - accuracy: 0.7521\n",
      "Epoch 108/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9522 - accuracy: 0.7543\n",
      "Epoch 109/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9657 - accuracy: 0.7482\n",
      "Epoch 110/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9277 - accuracy: 0.7568\n",
      "Epoch 111/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9732 - accuracy: 0.7542\n",
      "Epoch 112/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9226 - accuracy: 0.7557\n",
      "Epoch 113/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9048 - accuracy: 0.7632\n",
      "Epoch 114/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8823 - accuracy: 0.7732\n",
      "Epoch 115/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9273 - accuracy: 0.7506\n",
      "Epoch 116/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9165 - accuracy: 0.7534\n",
      "Epoch 117/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8690 - accuracy: 0.7658\n",
      "Epoch 118/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8553 - accuracy: 0.7714\n",
      "Epoch 119/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8685 - accuracy: 0.7743\n",
      "Epoch 120/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8575 - accuracy: 0.7745\n",
      "Epoch 121/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8715 - accuracy: 0.7602\n",
      "Epoch 122/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8623 - accuracy: 0.7768\n",
      "Epoch 123/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8409 - accuracy: 0.7837\n",
      "Epoch 124/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8327 - accuracy: 0.7863\n",
      "Epoch 125/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8322 - accuracy: 0.7667\n",
      "Epoch 126/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8117 - accuracy: 0.7840\n",
      "Epoch 127/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8332 - accuracy: 0.7749\n",
      "Epoch 128/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8013 - accuracy: 0.7851\n",
      "Epoch 129/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8067 - accuracy: 0.7842\n",
      "Epoch 130/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7999 - accuracy: 0.7769\n",
      "Epoch 131/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8007 - accuracy: 0.7798\n",
      "Epoch 132/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7894 - accuracy: 0.7838\n",
      "Epoch 133/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7881 - accuracy: 0.7923\n",
      "Epoch 134/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7986 - accuracy: 0.7878\n",
      "Epoch 135/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7902 - accuracy: 0.7867\n",
      "Epoch 136/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7671 - accuracy: 0.7870\n",
      "Epoch 137/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7690 - accuracy: 0.7905\n",
      "Epoch 138/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7344 - accuracy: 0.8090\n",
      "Epoch 139/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7782 - accuracy: 0.7868\n",
      "Epoch 140/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7629 - accuracy: 0.7929\n",
      "Epoch 141/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7448 - accuracy: 0.7976\n",
      "Epoch 142/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7332 - accuracy: 0.7933\n",
      "Epoch 143/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7099 - accuracy: 0.8085\n",
      "Epoch 144/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6886 - accuracy: 0.8076\n",
      "Epoch 145/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6935 - accuracy: 0.8140\n",
      "Epoch 146/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7427 - accuracy: 0.8035\n",
      "Epoch 147/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6835 - accuracy: 0.8186\n",
      "Epoch 148/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6720 - accuracy: 0.8180\n",
      "Epoch 149/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6768 - accuracy: 0.8258\n",
      "Epoch 150/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6902 - accuracy: 0.7998\n",
      "Epoch 151/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7179 - accuracy: 0.7967\n",
      "Epoch 152/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7231 - accuracy: 0.7997\n",
      "Epoch 153/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7179 - accuracy: 0.8059\n",
      "Epoch 154/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6690 - accuracy: 0.8163\n",
      "Epoch 155/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6892 - accuracy: 0.8091\n",
      "Epoch 156/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6772 - accuracy: 0.8110\n",
      "Epoch 157/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6621 - accuracy: 0.8213\n",
      "Epoch 158/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6601 - accuracy: 0.8214\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6602 - accuracy: 0.8126\n",
      "Epoch 160/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6455 - accuracy: 0.8194\n",
      "Epoch 161/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7194 - accuracy: 0.7992\n",
      "Epoch 162/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6773 - accuracy: 0.8037\n",
      "Epoch 163/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6838 - accuracy: 0.8114\n",
      "Epoch 164/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6350 - accuracy: 0.8246\n",
      "Epoch 165/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6871 - accuracy: 0.8002\n",
      "Epoch 166/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6213 - accuracy: 0.8244\n",
      "Epoch 167/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6596 - accuracy: 0.8108\n",
      "Epoch 168/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6581 - accuracy: 0.8119\n",
      "Epoch 169/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6181 - accuracy: 0.8302\n",
      "Epoch 170/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6093 - accuracy: 0.8263\n",
      "Epoch 171/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6064 - accuracy: 0.8279\n",
      "Epoch 172/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6143 - accuracy: 0.8331\n",
      "Epoch 173/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6342 - accuracy: 0.8185\n",
      "Epoch 174/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6431 - accuracy: 0.8228\n",
      "Epoch 175/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6261 - accuracy: 0.8206\n",
      "Epoch 176/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6851 - accuracy: 0.7988\n",
      "Epoch 177/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6282 - accuracy: 0.8187\n",
      "Epoch 178/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6278 - accuracy: 0.8157\n",
      "Epoch 179/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6086 - accuracy: 0.8282\n",
      "Epoch 180/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6186 - accuracy: 0.8260\n",
      "Epoch 181/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6357 - accuracy: 0.8183\n",
      "Epoch 182/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5785 - accuracy: 0.8378\n",
      "Epoch 183/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6149 - accuracy: 0.8274\n",
      "Epoch 184/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5917 - accuracy: 0.8326\n",
      "Epoch 185/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6049 - accuracy: 0.8306\n",
      "Epoch 186/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6067 - accuracy: 0.8263\n",
      "Epoch 187/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5960 - accuracy: 0.8302\n",
      "Epoch 188/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5630 - accuracy: 0.8300\n",
      "Epoch 189/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5947 - accuracy: 0.8354\n",
      "Epoch 190/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5876 - accuracy: 0.8324\n",
      "Epoch 191/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5816 - accuracy: 0.8338\n",
      "Epoch 192/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5926 - accuracy: 0.8349\n",
      "Epoch 193/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5877 - accuracy: 0.8298\n",
      "Epoch 194/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6387 - accuracy: 0.8165\n",
      "Epoch 195/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5552 - accuracy: 0.8385\n",
      "Epoch 196/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5607 - accuracy: 0.8419\n",
      "Epoch 197/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5915 - accuracy: 0.8278\n",
      "Epoch 198/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5622 - accuracy: 0.8324\n",
      "Epoch 199/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5798 - accuracy: 0.8287\n",
      "Epoch 200/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6159 - accuracy: 0.8212\n",
      "Epoch 201/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6013 - accuracy: 0.8272\n",
      "Epoch 202/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5831 - accuracy: 0.8351\n",
      "Epoch 203/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5744 - accuracy: 0.8304\n",
      "Epoch 204/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5540 - accuracy: 0.8378\n",
      "Epoch 205/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5719 - accuracy: 0.8329\n",
      "Epoch 206/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5763 - accuracy: 0.8300\n",
      "Epoch 207/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5471 - accuracy: 0.8427\n",
      "Epoch 208/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5600 - accuracy: 0.8364\n",
      "Epoch 209/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5249 - accuracy: 0.8503\n",
      "Epoch 210/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5085 - accuracy: 0.8552\n",
      "Epoch 211/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5449 - accuracy: 0.8389\n",
      "Epoch 212/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5187 - accuracy: 0.8492\n",
      "Epoch 213/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5747 - accuracy: 0.8405\n",
      "Epoch 214/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5444 - accuracy: 0.8514\n",
      "Epoch 215/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5353 - accuracy: 0.8520\n",
      "Epoch 216/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5340 - accuracy: 0.8455\n",
      "Epoch 217/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5561 - accuracy: 0.8379\n",
      "Epoch 218/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5260 - accuracy: 0.8460\n",
      "Epoch 219/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5571 - accuracy: 0.8487\n",
      "Epoch 220/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5240 - accuracy: 0.8435\n",
      "Epoch 221/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5448 - accuracy: 0.8415\n",
      "Epoch 222/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5263 - accuracy: 0.8460\n",
      "Epoch 223/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5468 - accuracy: 0.8356\n",
      "Epoch 224/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5312 - accuracy: 0.8455\n",
      "Epoch 225/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5309 - accuracy: 0.8454\n",
      "Epoch 226/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5072 - accuracy: 0.8471\n",
      "Epoch 227/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5433 - accuracy: 0.8435\n",
      "Epoch 228/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5649 - accuracy: 0.8319\n",
      "Epoch 229/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5244 - accuracy: 0.8469\n",
      "Epoch 230/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4922 - accuracy: 0.8549\n",
      "Epoch 231/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5100 - accuracy: 0.8451\n",
      "Epoch 232/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5113 - accuracy: 0.8545\n",
      "Epoch 233/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5307 - accuracy: 0.8428\n",
      "Epoch 234/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5069 - accuracy: 0.8548\n",
      "Epoch 235/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5047 - accuracy: 0.8515\n",
      "Epoch 236/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5124 - accuracy: 0.8437\n",
      "Epoch 237/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5275 - accuracy: 0.8460\n",
      "Epoch 238/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5506 - accuracy: 0.8407\n",
      "Epoch 239/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5044 - accuracy: 0.8521\n",
      "Epoch 240/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5255 - accuracy: 0.8513\n",
      "Epoch 241/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5210 - accuracy: 0.8469\n",
      "Epoch 242/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5206 - accuracy: 0.8493\n",
      "Epoch 243/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4997 - accuracy: 0.8530\n",
      "Epoch 244/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4845 - accuracy: 0.8554\n",
      "Epoch 245/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4823 - accuracy: 0.8534\n",
      "Epoch 246/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4704 - accuracy: 0.8543\n",
      "Epoch 247/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5167 - accuracy: 0.8498\n",
      "Epoch 248/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4956 - accuracy: 0.8461\n",
      "Epoch 249/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5203 - accuracy: 0.8497\n",
      "Epoch 250/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5157 - accuracy: 0.8493\n",
      "Epoch 251/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4937 - accuracy: 0.8578\n",
      "Epoch 252/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5064 - accuracy: 0.8566\n",
      "Epoch 253/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5194 - accuracy: 0.8433\n",
      "Epoch 254/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4897 - accuracy: 0.8469\n",
      "Epoch 255/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4844 - accuracy: 0.8576\n",
      "Epoch 256/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4721 - accuracy: 0.8531\n",
      "Epoch 257/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5022 - accuracy: 0.8497\n",
      "Epoch 258/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4926 - accuracy: 0.8553\n",
      "Epoch 259/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4552 - accuracy: 0.8658\n",
      "Epoch 260/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4727 - accuracy: 0.8634\n",
      "Epoch 261/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4873 - accuracy: 0.8548\n",
      "Epoch 262/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4789 - accuracy: 0.8629\n",
      "Epoch 263/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4943 - accuracy: 0.8591\n",
      "Epoch 264/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4682 - accuracy: 0.8572\n",
      "Epoch 265/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4653 - accuracy: 0.8664\n",
      "Epoch 266/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4905 - accuracy: 0.8499\n",
      "Epoch 267/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4786 - accuracy: 0.8580\n",
      "Epoch 268/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4756 - accuracy: 0.8589\n",
      "Epoch 269/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4706 - accuracy: 0.8623\n",
      "Epoch 270/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4968 - accuracy: 0.8529\n",
      "Epoch 271/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4602 - accuracy: 0.8652\n",
      "Epoch 272/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4638 - accuracy: 0.8590\n",
      "Epoch 273/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4724 - accuracy: 0.8572\n",
      "Epoch 274/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4936 - accuracy: 0.8557\n",
      "Epoch 275/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5050 - accuracy: 0.8437\n",
      "Epoch 276/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4688 - accuracy: 0.8568\n",
      "Epoch 277/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4797 - accuracy: 0.8580\n",
      "Epoch 278/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4895 - accuracy: 0.8548\n",
      "Epoch 279/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4591 - accuracy: 0.8618\n",
      "Epoch 280/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4759 - accuracy: 0.8587\n",
      "Epoch 281/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5065 - accuracy: 0.8462\n",
      "Epoch 282/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4689 - accuracy: 0.8609\n",
      "Epoch 283/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4321 - accuracy: 0.8735\n",
      "Epoch 284/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4551 - accuracy: 0.8622\n",
      "Epoch 285/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4829 - accuracy: 0.8515\n",
      "Epoch 286/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4559 - accuracy: 0.8663\n",
      "Epoch 287/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4607 - accuracy: 0.8649\n",
      "Epoch 288/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4921 - accuracy: 0.8533\n",
      "Epoch 289/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4817 - accuracy: 0.8504\n",
      "Epoch 290/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4295 - accuracy: 0.8711\n",
      "Epoch 291/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4360 - accuracy: 0.8668\n",
      "Epoch 292/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4938 - accuracy: 0.8600\n",
      "Epoch 293/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4549 - accuracy: 0.8526\n",
      "Epoch 294/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4589 - accuracy: 0.8655\n",
      "Epoch 295/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4423 - accuracy: 0.8682\n",
      "Epoch 296/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4361 - accuracy: 0.8687\n",
      "Epoch 297/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4666 - accuracy: 0.8541\n",
      "Epoch 298/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4543 - accuracy: 0.8637\n",
      "Epoch 299/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4482 - accuracy: 0.8632\n",
      "Epoch 300/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4553 - accuracy: 0.8627\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 23, 128)           259456    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2027)              520939    \n",
      "=================================================================\n",
      "Total params: 1,043,563\n",
      "Trainable params: 1,043,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_bilstm_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 128, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(128,return_sequences=False, kernel_initializer='random_uniform')),\n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "single_bilstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "single_bilstm_model.fit(xs,ys,epochs=300,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "single_bilstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-guatemala",
   "metadata": {},
   "source": [
    "#### Single Bidirectional LSTM layer model 300 epochs 128 units 0.01 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "portuguese-print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "145/145 [==============================] - 6s 22ms/step - loss: 6.9222 - accuracy: 0.0389\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 2s 15ms/step - loss: 6.3832 - accuracy: 0.0469\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 2s 15ms/step - loss: 6.0832 - accuracy: 0.0686\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 2s 15ms/step - loss: 5.7830 - accuracy: 0.0730\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4375 - accuracy: 0.1148\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1916 - accuracy: 0.1204\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8947 - accuracy: 0.1405\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6195 - accuracy: 0.1573\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5113 - accuracy: 0.1647\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2650 - accuracy: 0.2017\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1359 - accuracy: 0.1950\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9825 - accuracy: 0.2158\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 2s 15ms/step - loss: 3.9116 - accuracy: 0.2173\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.7615 - accuracy: 0.2407\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.7584 - accuracy: 0.2268\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.5688 - accuracy: 0.2571\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.5522 - accuracy: 0.2572\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.4273 - accuracy: 0.2748\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.4359 - accuracy: 0.2808\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.3411 - accuracy: 0.2729\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.3548 - accuracy: 0.2773\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.2487 - accuracy: 0.2946\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.2323 - accuracy: 0.3015\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.2420 - accuracy: 0.2898\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.2675 - accuracy: 0.2864\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1813 - accuracy: 0.2910\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1340 - accuracy: 0.3012\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1307 - accuracy: 0.3109\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0825 - accuracy: 0.3116\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0443 - accuracy: 0.3326\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0555 - accuracy: 0.3146\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0572 - accuracy: 0.3105\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0336 - accuracy: 0.3168\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9382 - accuracy: 0.3232\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9818 - accuracy: 0.3245\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9562 - accuracy: 0.3269\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9108 - accuracy: 0.3398\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9258 - accuracy: 0.3328\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9429 - accuracy: 0.3259\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9359 - accuracy: 0.3406\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9482 - accuracy: 0.3196\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9339 - accuracy: 0.3365\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9002 - accuracy: 0.3355\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9814 - accuracy: 0.3276\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9314 - accuracy: 0.3274\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8965 - accuracy: 0.3369\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8746 - accuracy: 0.3451\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9441 - accuracy: 0.3313\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8794 - accuracy: 0.3466\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8143 - accuracy: 0.3460\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9550 - accuracy: 0.3235\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8814 - accuracy: 0.3370\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9193 - accuracy: 0.3333\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9274 - accuracy: 0.3491\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8572 - accuracy: 0.3520\n",
      "Epoch 56/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8931 - accuracy: 0.3480\n",
      "Epoch 57/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8893 - accuracy: 0.3565\n",
      "Epoch 58/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.7940 - accuracy: 0.3547\n",
      "Epoch 59/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8415 - accuracy: 0.3675\n",
      "Epoch 60/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8141 - accuracy: 0.3559\n",
      "Epoch 61/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9720 - accuracy: 0.3235\n",
      "Epoch 62/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8247 - accuracy: 0.3561\n",
      "Epoch 63/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8096 - accuracy: 0.3559\n",
      "Epoch 64/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8473 - accuracy: 0.3494\n",
      "Epoch 65/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.7855 - accuracy: 0.3668\n",
      "Epoch 66/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8366 - accuracy: 0.3533\n",
      "Epoch 67/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9105 - accuracy: 0.3354\n",
      "Epoch 68/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9521 - accuracy: 0.3399\n",
      "Epoch 69/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9835 - accuracy: 0.3416\n",
      "Epoch 70/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9165 - accuracy: 0.3425\n",
      "Epoch 71/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.7548 - accuracy: 0.3639\n",
      "Epoch 72/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8209 - accuracy: 0.3614\n",
      "Epoch 73/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8726 - accuracy: 0.3494\n",
      "Epoch 74/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8799 - accuracy: 0.3319\n",
      "Epoch 75/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8908 - accuracy: 0.3507\n",
      "Epoch 76/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8929 - accuracy: 0.3478\n",
      "Epoch 77/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8519 - accuracy: 0.3411\n",
      "Epoch 78/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8290 - accuracy: 0.3508\n",
      "Epoch 79/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9373 - accuracy: 0.3450\n",
      "Epoch 80/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9255 - accuracy: 0.3477\n",
      "Epoch 81/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8210 - accuracy: 0.3601\n",
      "Epoch 82/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9109 - accuracy: 0.3417\n",
      "Epoch 83/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9524 - accuracy: 0.3508\n",
      "Epoch 84/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8851 - accuracy: 0.3527\n",
      "Epoch 85/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8824 - accuracy: 0.3408\n",
      "Epoch 86/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8460 - accuracy: 0.3503\n",
      "Epoch 87/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9161 - accuracy: 0.3354\n",
      "Epoch 88/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8459 - accuracy: 0.3666\n",
      "Epoch 89/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9776 - accuracy: 0.3414\n",
      "Epoch 90/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8170 - accuracy: 0.3574\n",
      "Epoch 91/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8031 - accuracy: 0.3607\n",
      "Epoch 92/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9114 - accuracy: 0.3442\n",
      "Epoch 93/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8624 - accuracy: 0.3458\n",
      "Epoch 94/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8794 - accuracy: 0.3565\n",
      "Epoch 95/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.6959 - accuracy: 0.3864\n",
      "Epoch 96/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8421 - accuracy: 0.3468\n",
      "Epoch 97/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8698 - accuracy: 0.3539\n",
      "Epoch 98/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8105 - accuracy: 0.3628\n",
      "Epoch 99/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0110 - accuracy: 0.3373\n",
      "Epoch 100/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9666 - accuracy: 0.3492\n",
      "Epoch 101/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9378 - accuracy: 0.3454\n",
      "Epoch 102/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9628 - accuracy: 0.3312\n",
      "Epoch 103/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8440 - accuracy: 0.3470\n",
      "Epoch 104/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9691 - accuracy: 0.3500\n",
      "Epoch 105/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8670 - accuracy: 0.3566\n",
      "Epoch 106/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9050 - accuracy: 0.3500\n",
      "Epoch 107/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0046 - accuracy: 0.3273\n",
      "Epoch 108/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8742 - accuracy: 0.3502\n",
      "Epoch 109/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9920 - accuracy: 0.3443\n",
      "Epoch 110/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9560 - accuracy: 0.3557\n",
      "Epoch 111/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9613 - accuracy: 0.3495\n",
      "Epoch 112/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8834 - accuracy: 0.3618\n",
      "Epoch 113/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8340 - accuracy: 0.3730\n",
      "Epoch 114/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9297 - accuracy: 0.3489\n",
      "Epoch 115/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8567 - accuracy: 0.3623\n",
      "Epoch 116/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9817 - accuracy: 0.3317\n",
      "Epoch 117/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8066 - accuracy: 0.3586\n",
      "Epoch 118/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8663 - accuracy: 0.3432\n",
      "Epoch 119/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8754 - accuracy: 0.3571\n",
      "Epoch 120/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8822 - accuracy: 0.3389\n",
      "Epoch 121/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9212 - accuracy: 0.3384\n",
      "Epoch 122/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8125 - accuracy: 0.3541\n",
      "Epoch 123/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.7850 - accuracy: 0.3791\n",
      "Epoch 124/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9584 - accuracy: 0.3368\n",
      "Epoch 125/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8357 - accuracy: 0.3592\n",
      "Epoch 126/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8588 - accuracy: 0.3543\n",
      "Epoch 127/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8753 - accuracy: 0.3609\n",
      "Epoch 128/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9336 - accuracy: 0.3470\n",
      "Epoch 129/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9361 - accuracy: 0.3458\n",
      "Epoch 130/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8841 - accuracy: 0.3651\n",
      "Epoch 131/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8843 - accuracy: 0.3507\n",
      "Epoch 132/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8779 - accuracy: 0.3648\n",
      "Epoch 133/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9069 - accuracy: 0.3723\n",
      "Epoch 134/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9621 - accuracy: 0.3465\n",
      "Epoch 135/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9174 - accuracy: 0.3436\n",
      "Epoch 136/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9789 - accuracy: 0.3514\n",
      "Epoch 137/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9427 - accuracy: 0.3418\n",
      "Epoch 138/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8304 - accuracy: 0.3803\n",
      "Epoch 139/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8226 - accuracy: 0.3623\n",
      "Epoch 140/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9415 - accuracy: 0.3538\n",
      "Epoch 141/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8698 - accuracy: 0.3594\n",
      "Epoch 142/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9075 - accuracy: 0.3590\n",
      "Epoch 143/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8634 - accuracy: 0.3620\n",
      "Epoch 144/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8598 - accuracy: 0.3623\n",
      "Epoch 145/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8553 - accuracy: 0.3707\n",
      "Epoch 146/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8580 - accuracy: 0.3595\n",
      "Epoch 147/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8805 - accuracy: 0.3637\n",
      "Epoch 148/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8596 - accuracy: 0.3659\n",
      "Epoch 149/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9441 - accuracy: 0.3480\n",
      "Epoch 150/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8173 - accuracy: 0.3607\n",
      "Epoch 151/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8590 - accuracy: 0.3659\n",
      "Epoch 152/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8004 - accuracy: 0.3760\n",
      "Epoch 153/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9738 - accuracy: 0.3437\n",
      "Epoch 154/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9109 - accuracy: 0.3458\n",
      "Epoch 155/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8356 - accuracy: 0.3700\n",
      "Epoch 156/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8661 - accuracy: 0.3651\n",
      "Epoch 157/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8767 - accuracy: 0.3600\n",
      "Epoch 158/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9099 - accuracy: 0.3422\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9640 - accuracy: 0.3471\n",
      "Epoch 160/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9089 - accuracy: 0.3437\n",
      "Epoch 161/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8028 - accuracy: 0.3573\n",
      "Epoch 162/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9110 - accuracy: 0.3573\n",
      "Epoch 163/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9082 - accuracy: 0.3571\n",
      "Epoch 164/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0093 - accuracy: 0.3360\n",
      "Epoch 165/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8959 - accuracy: 0.3688\n",
      "Epoch 166/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8736 - accuracy: 0.3521\n",
      "Epoch 167/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9729 - accuracy: 0.3360\n",
      "Epoch 168/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9065 - accuracy: 0.3597\n",
      "Epoch 169/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9169 - accuracy: 0.3504\n",
      "Epoch 170/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9499 - accuracy: 0.3560\n",
      "Epoch 171/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8961 - accuracy: 0.3615\n",
      "Epoch 172/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9271 - accuracy: 0.3544\n",
      "Epoch 173/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8907 - accuracy: 0.3561\n",
      "Epoch 174/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8855 - accuracy: 0.3636\n",
      "Epoch 175/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9274 - accuracy: 0.3515\n",
      "Epoch 176/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8937 - accuracy: 0.3764\n",
      "Epoch 177/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8685 - accuracy: 0.3560\n",
      "Epoch 178/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9677 - accuracy: 0.3445\n",
      "Epoch 179/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8255 - accuracy: 0.3821\n",
      "Epoch 180/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9464 - accuracy: 0.3525\n",
      "Epoch 181/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9700 - accuracy: 0.3511\n",
      "Epoch 182/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8569 - accuracy: 0.3715\n",
      "Epoch 183/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9930 - accuracy: 0.3481\n",
      "Epoch 184/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8357 - accuracy: 0.3601\n",
      "Epoch 185/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0161 - accuracy: 0.3433\n",
      "Epoch 186/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9036 - accuracy: 0.3678\n",
      "Epoch 187/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9976 - accuracy: 0.3474\n",
      "Epoch 188/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8642 - accuracy: 0.3505\n",
      "Epoch 189/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0578 - accuracy: 0.3512\n",
      "Epoch 190/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9171 - accuracy: 0.3524\n",
      "Epoch 191/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0456 - accuracy: 0.3496\n",
      "Epoch 192/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9470 - accuracy: 0.3559\n",
      "Epoch 193/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9077 - accuracy: 0.3718\n",
      "Epoch 194/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9497 - accuracy: 0.3451\n",
      "Epoch 195/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9393 - accuracy: 0.3641\n",
      "Epoch 196/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9676 - accuracy: 0.3574\n",
      "Epoch 197/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9019 - accuracy: 0.3512\n",
      "Epoch 198/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9825 - accuracy: 0.3513\n",
      "Epoch 199/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9934 - accuracy: 0.3536\n",
      "Epoch 200/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9608 - accuracy: 0.3390\n",
      "Epoch 201/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0013 - accuracy: 0.3458\n",
      "Epoch 202/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9392 - accuracy: 0.3638\n",
      "Epoch 203/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8882 - accuracy: 0.3541\n",
      "Epoch 204/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8994 - accuracy: 0.3553\n",
      "Epoch 205/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9195 - accuracy: 0.3530\n",
      "Epoch 206/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9559 - accuracy: 0.3502\n",
      "Epoch 207/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9679 - accuracy: 0.3535\n",
      "Epoch 208/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9831 - accuracy: 0.3449\n",
      "Epoch 209/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9564 - accuracy: 0.3516\n",
      "Epoch 210/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9849 - accuracy: 0.3502\n",
      "Epoch 211/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9445 - accuracy: 0.3568\n",
      "Epoch 212/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8822 - accuracy: 0.3605\n",
      "Epoch 213/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8842 - accuracy: 0.3600\n",
      "Epoch 214/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9609 - accuracy: 0.3503\n",
      "Epoch 215/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9027 - accuracy: 0.3543\n",
      "Epoch 216/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9466 - accuracy: 0.3588\n",
      "Epoch 217/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8499 - accuracy: 0.3689\n",
      "Epoch 218/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9147 - accuracy: 0.3502\n",
      "Epoch 219/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9937 - accuracy: 0.3437\n",
      "Epoch 220/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8656 - accuracy: 0.3609\n",
      "Epoch 221/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9393 - accuracy: 0.3487\n",
      "Epoch 222/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0503 - accuracy: 0.3591\n",
      "Epoch 223/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8701 - accuracy: 0.3434\n",
      "Epoch 224/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9197 - accuracy: 0.3575\n",
      "Epoch 225/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9025 - accuracy: 0.3558\n",
      "Epoch 226/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8376 - accuracy: 0.3634\n",
      "Epoch 227/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0036 - accuracy: 0.3419\n",
      "Epoch 228/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9384 - accuracy: 0.3545\n",
      "Epoch 229/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0102 - accuracy: 0.3431\n",
      "Epoch 230/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8643 - accuracy: 0.3708\n",
      "Epoch 231/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0346 - accuracy: 0.3531\n",
      "Epoch 232/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8691 - accuracy: 0.3505\n",
      "Epoch 233/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0187 - accuracy: 0.3579\n",
      "Epoch 234/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9679 - accuracy: 0.3366\n",
      "Epoch 235/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0609 - accuracy: 0.3372\n",
      "Epoch 236/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0343 - accuracy: 0.3331\n",
      "Epoch 237/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9369 - accuracy: 0.3635\n",
      "Epoch 238/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0352 - accuracy: 0.3552\n",
      "Epoch 239/300\n",
      "145/145 [==============================] - 2s 15ms/step - loss: 2.9403 - accuracy: 0.3545\n",
      "Epoch 240/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9608 - accuracy: 0.3616\n",
      "Epoch 241/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1172 - accuracy: 0.3329\n",
      "Epoch 242/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9797 - accuracy: 0.3551\n",
      "Epoch 243/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9898 - accuracy: 0.3389\n",
      "Epoch 244/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0058 - accuracy: 0.3594\n",
      "Epoch 245/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0688 - accuracy: 0.3531\n",
      "Epoch 246/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9848 - accuracy: 0.3568\n",
      "Epoch 247/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8749 - accuracy: 0.3657\n",
      "Epoch 248/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0223 - accuracy: 0.3408\n",
      "Epoch 249/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0435 - accuracy: 0.3506\n",
      "Epoch 250/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9356 - accuracy: 0.3504\n",
      "Epoch 251/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8881 - accuracy: 0.3555\n",
      "Epoch 252/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9660 - accuracy: 0.3636\n",
      "Epoch 253/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9191 - accuracy: 0.3546\n",
      "Epoch 254/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9373 - accuracy: 0.3484\n",
      "Epoch 255/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1039 - accuracy: 0.3351\n",
      "Epoch 256/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0675 - accuracy: 0.3474\n",
      "Epoch 257/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9887 - accuracy: 0.3686\n",
      "Epoch 258/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9783 - accuracy: 0.3564\n",
      "Epoch 259/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0551 - accuracy: 0.3345\n",
      "Epoch 260/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9016 - accuracy: 0.3607\n",
      "Epoch 261/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9775 - accuracy: 0.3580\n",
      "Epoch 262/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9945 - accuracy: 0.3455\n",
      "Epoch 263/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0228 - accuracy: 0.3559\n",
      "Epoch 264/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9895 - accuracy: 0.3481\n",
      "Epoch 265/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9494 - accuracy: 0.3655\n",
      "Epoch 266/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9858 - accuracy: 0.3596\n",
      "Epoch 267/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9790 - accuracy: 0.3646\n",
      "Epoch 268/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8292 - accuracy: 0.3610\n",
      "Epoch 269/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0148 - accuracy: 0.3500\n",
      "Epoch 270/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0320 - accuracy: 0.3549\n",
      "Epoch 271/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0669 - accuracy: 0.3450\n",
      "Epoch 272/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0107 - accuracy: 0.3592\n",
      "Epoch 273/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0315 - accuracy: 0.3376\n",
      "Epoch 274/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9418 - accuracy: 0.3460\n",
      "Epoch 275/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9440 - accuracy: 0.3557\n",
      "Epoch 276/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0113 - accuracy: 0.3492\n",
      "Epoch 277/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9639 - accuracy: 0.3552\n",
      "Epoch 278/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0224 - accuracy: 0.3436\n",
      "Epoch 279/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0358 - accuracy: 0.3578\n",
      "Epoch 280/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0247 - accuracy: 0.3521\n",
      "Epoch 281/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0222 - accuracy: 0.3448\n",
      "Epoch 282/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0327 - accuracy: 0.3462\n",
      "Epoch 283/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0059 - accuracy: 0.3444\n",
      "Epoch 284/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0160 - accuracy: 0.3381\n",
      "Epoch 285/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0548 - accuracy: 0.3521\n",
      "Epoch 286/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0170 - accuracy: 0.3596\n",
      "Epoch 287/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0897 - accuracy: 0.3501\n",
      "Epoch 288/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0663 - accuracy: 0.3531\n",
      "Epoch 289/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9844 - accuracy: 0.3624\n",
      "Epoch 290/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0187 - accuracy: 0.3404\n",
      "Epoch 291/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0220 - accuracy: 0.3539\n",
      "Epoch 292/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1106 - accuracy: 0.3350\n",
      "Epoch 293/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0538 - accuracy: 0.3504\n",
      "Epoch 294/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9659 - accuracy: 0.3614\n",
      "Epoch 295/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1004 - accuracy: 0.3505\n",
      "Epoch 296/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0294 - accuracy: 0.3490\n",
      "Epoch 297/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0212 - accuracy: 0.3569\n",
      "Epoch 298/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0592 - accuracy: 0.3494\n",
      "Epoch 299/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0247 - accuracy: 0.3422\n",
      "Epoch 300/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0437 - accuracy: 0.3517\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 23, 128)           259456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2027)              520939    \n",
      "=================================================================\n",
      "Total params: 1,043,563\n",
      "Trainable params: 1,043,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_bilstm_larger_step_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 128, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(128,return_sequences=False, kernel_initializer='random_uniform')),\n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "single_bilstm_larger_step_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "single_bilstm_larger_step_model.fit(xs,ys,epochs=300,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "single_bilstm_larger_step_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-yugoslavia",
   "metadata": {},
   "source": [
    "#### Single Bidirectional LSTM layer model 300 epochs 128 units 0.0001 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indonesian-enforcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "145/145 [==============================] - 6s 22ms/step - loss: 7.5399 - accuracy: 0.0197\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 2s 15ms/step - loss: 6.4614 - accuracy: 0.0464\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.4335 - accuracy: 0.0383\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.4249 - accuracy: 0.0419\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.3995 - accuracy: 0.0512\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.4003 - accuracy: 0.0488\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.3749 - accuracy: 0.0450\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.3259 - accuracy: 0.0536\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.3809 - accuracy: 0.0381\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.3030 - accuracy: 0.0423\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.2728 - accuracy: 0.0456\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.2836 - accuracy: 0.0388\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.2293 - accuracy: 0.0424\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1655 - accuracy: 0.0450\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.2437 - accuracy: 0.0378\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1610 - accuracy: 0.0393\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1684 - accuracy: 0.0432\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1404 - accuracy: 0.0394\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1090 - accuracy: 0.0453\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1663 - accuracy: 0.0403\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0659 - accuracy: 0.0467\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0877 - accuracy: 0.0459\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0930 - accuracy: 0.0402\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0312 - accuracy: 0.0483\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0562 - accuracy: 0.0432\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0585 - accuracy: 0.0435\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0208 - accuracy: 0.0518\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0177 - accuracy: 0.0452\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9750 - accuracy: 0.0403\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9557 - accuracy: 0.0454\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9602 - accuracy: 0.0485\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9738 - accuracy: 0.0503\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9697 - accuracy: 0.0464\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9346 - accuracy: 0.0428\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9434 - accuracy: 0.0409\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9459 - accuracy: 0.0467\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8903 - accuracy: 0.0462\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9289 - accuracy: 0.0402\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9136 - accuracy: 0.0434\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8769 - accuracy: 0.0444\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.9188 - accuracy: 0.0508\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8639 - accuracy: 0.0478\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8612 - accuracy: 0.0492\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8758 - accuracy: 0.0452\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8203 - accuracy: 0.0518\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8811 - accuracy: 0.0413\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8358 - accuracy: 0.0394\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8344 - accuracy: 0.0526\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8323 - accuracy: 0.0422\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7813 - accuracy: 0.0499\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7771 - accuracy: 0.0485\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7575 - accuracy: 0.0443\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7516 - accuracy: 0.0516\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7107 - accuracy: 0.0487\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7774 - accuracy: 0.0439\n",
      "Epoch 56/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7157 - accuracy: 0.0447\n",
      "Epoch 57/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7282 - accuracy: 0.0441\n",
      "Epoch 58/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6823 - accuracy: 0.0484\n",
      "Epoch 59/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6714 - accuracy: 0.0440\n",
      "Epoch 60/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6756 - accuracy: 0.0500\n",
      "Epoch 61/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6738 - accuracy: 0.0472\n",
      "Epoch 62/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6751 - accuracy: 0.0528\n",
      "Epoch 63/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6284 - accuracy: 0.0448\n",
      "Epoch 64/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6297 - accuracy: 0.0472\n",
      "Epoch 65/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6008 - accuracy: 0.0536\n",
      "Epoch 66/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6459 - accuracy: 0.0519\n",
      "Epoch 67/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6277 - accuracy: 0.0458\n",
      "Epoch 68/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5862 - accuracy: 0.0553\n",
      "Epoch 69/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5928 - accuracy: 0.0508\n",
      "Epoch 70/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5726 - accuracy: 0.0498\n",
      "Epoch 71/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5263 - accuracy: 0.0559\n",
      "Epoch 72/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5445 - accuracy: 0.0528\n",
      "Epoch 73/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5624 - accuracy: 0.0519\n",
      "Epoch 74/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5332 - accuracy: 0.0579\n",
      "Epoch 75/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5682 - accuracy: 0.0510\n",
      "Epoch 76/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5670 - accuracy: 0.0517\n",
      "Epoch 77/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5098 - accuracy: 0.0462\n",
      "Epoch 78/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5065 - accuracy: 0.0567\n",
      "Epoch 79/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4792 - accuracy: 0.0515\n",
      "Epoch 80/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5313 - accuracy: 0.0468\n",
      "Epoch 81/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4871 - accuracy: 0.0526\n",
      "Epoch 82/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4796 - accuracy: 0.0524\n",
      "Epoch 83/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4280 - accuracy: 0.0578\n",
      "Epoch 84/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4366 - accuracy: 0.0540\n",
      "Epoch 85/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3747 - accuracy: 0.0627\n",
      "Epoch 86/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3991 - accuracy: 0.0594\n",
      "Epoch 87/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.4199 - accuracy: 0.0562\n",
      "Epoch 88/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3933 - accuracy: 0.0508\n",
      "Epoch 89/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3792 - accuracy: 0.0634\n",
      "Epoch 90/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3269 - accuracy: 0.0562\n",
      "Epoch 91/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3755 - accuracy: 0.0561\n",
      "Epoch 92/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3246 - accuracy: 0.0567\n",
      "Epoch 93/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3462 - accuracy: 0.0641\n",
      "Epoch 94/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2899 - accuracy: 0.0651\n",
      "Epoch 95/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3772 - accuracy: 0.0573\n",
      "Epoch 96/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2810 - accuracy: 0.0684\n",
      "Epoch 97/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2656 - accuracy: 0.0646\n",
      "Epoch 98/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2789 - accuracy: 0.0672\n",
      "Epoch 99/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2559 - accuracy: 0.0601\n",
      "Epoch 100/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2754 - accuracy: 0.0680\n",
      "Epoch 101/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2619 - accuracy: 0.0616\n",
      "Epoch 102/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2777 - accuracy: 0.0658\n",
      "Epoch 103/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2139 - accuracy: 0.0680\n",
      "Epoch 104/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2580 - accuracy: 0.0650\n",
      "Epoch 105/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2352 - accuracy: 0.0624\n",
      "Epoch 106/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1947 - accuracy: 0.0630\n",
      "Epoch 107/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2125 - accuracy: 0.0572\n",
      "Epoch 108/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1977 - accuracy: 0.0579\n",
      "Epoch 109/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1858 - accuracy: 0.0680\n",
      "Epoch 110/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1785 - accuracy: 0.0719\n",
      "Epoch 111/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1677 - accuracy: 0.0642\n",
      "Epoch 112/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1377 - accuracy: 0.0677\n",
      "Epoch 113/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1328 - accuracy: 0.0671\n",
      "Epoch 114/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1146 - accuracy: 0.0697\n",
      "Epoch 115/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1192 - accuracy: 0.0658\n",
      "Epoch 116/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1359 - accuracy: 0.0776\n",
      "Epoch 117/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0278 - accuracy: 0.0713\n",
      "Epoch 118/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0759 - accuracy: 0.0688\n",
      "Epoch 119/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1049 - accuracy: 0.0698\n",
      "Epoch 120/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0720 - accuracy: 0.0699\n",
      "Epoch 121/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0448 - accuracy: 0.0736\n",
      "Epoch 122/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0253 - accuracy: 0.0690\n",
      "Epoch 123/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0571 - accuracy: 0.0717\n",
      "Epoch 124/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0366 - accuracy: 0.0648\n",
      "Epoch 125/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9982 - accuracy: 0.0702\n",
      "Epoch 126/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0043 - accuracy: 0.0769\n",
      "Epoch 127/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0389 - accuracy: 0.0783\n",
      "Epoch 128/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0038 - accuracy: 0.0667\n",
      "Epoch 129/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9989 - accuracy: 0.0696\n",
      "Epoch 130/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9927 - accuracy: 0.0713\n",
      "Epoch 131/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9705 - accuracy: 0.0768\n",
      "Epoch 132/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9780 - accuracy: 0.0700\n",
      "Epoch 133/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.0019 - accuracy: 0.0691\n",
      "Epoch 134/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9749 - accuracy: 0.0720\n",
      "Epoch 135/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9459 - accuracy: 0.0722\n",
      "Epoch 136/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9324 - accuracy: 0.0772\n",
      "Epoch 137/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9121 - accuracy: 0.0761\n",
      "Epoch 138/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9250 - accuracy: 0.0821\n",
      "Epoch 139/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9423 - accuracy: 0.0761\n",
      "Epoch 140/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9118 - accuracy: 0.0808\n",
      "Epoch 141/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8988 - accuracy: 0.0779\n",
      "Epoch 142/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8659 - accuracy: 0.0720\n",
      "Epoch 143/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8748 - accuracy: 0.0689\n",
      "Epoch 144/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9077 - accuracy: 0.0759\n",
      "Epoch 145/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8910 - accuracy: 0.0755\n",
      "Epoch 146/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9129 - accuracy: 0.0812\n",
      "Epoch 147/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8479 - accuracy: 0.0714\n",
      "Epoch 148/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8453 - accuracy: 0.0743\n",
      "Epoch 149/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8379 - accuracy: 0.0855\n",
      "Epoch 150/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8020 - accuracy: 0.0759\n",
      "Epoch 151/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8226 - accuracy: 0.0696\n",
      "Epoch 152/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8185 - accuracy: 0.0722\n",
      "Epoch 153/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8095 - accuracy: 0.0812\n",
      "Epoch 154/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.8211 - accuracy: 0.0792\n",
      "Epoch 155/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7747 - accuracy: 0.0765\n",
      "Epoch 156/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7248 - accuracy: 0.0885\n",
      "Epoch 157/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7764 - accuracy: 0.0852\n",
      "Epoch 158/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7793 - accuracy: 0.0750\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7691 - accuracy: 0.0813\n",
      "Epoch 160/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7796 - accuracy: 0.0802\n",
      "Epoch 161/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7549 - accuracy: 0.0823\n",
      "Epoch 162/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7246 - accuracy: 0.0896\n",
      "Epoch 163/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7361 - accuracy: 0.0806\n",
      "Epoch 164/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7173 - accuracy: 0.0828\n",
      "Epoch 165/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7428 - accuracy: 0.0859\n",
      "Epoch 166/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6813 - accuracy: 0.0933\n",
      "Epoch 167/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7254 - accuracy: 0.0770\n",
      "Epoch 168/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6986 - accuracy: 0.0905\n",
      "Epoch 169/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7238 - accuracy: 0.0758\n",
      "Epoch 170/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6569 - accuracy: 0.0846\n",
      "Epoch 171/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6833 - accuracy: 0.0822\n",
      "Epoch 172/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7062 - accuracy: 0.0809\n",
      "Epoch 173/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6907 - accuracy: 0.0891\n",
      "Epoch 174/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6462 - accuracy: 0.0942\n",
      "Epoch 175/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6621 - accuracy: 0.0833\n",
      "Epoch 176/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6313 - accuracy: 0.0852\n",
      "Epoch 177/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6509 - accuracy: 0.0891\n",
      "Epoch 178/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6299 - accuracy: 0.0936\n",
      "Epoch 179/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6295 - accuracy: 0.0837\n",
      "Epoch 180/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6258 - accuracy: 0.0857\n",
      "Epoch 181/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6515 - accuracy: 0.0810\n",
      "Epoch 182/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6443 - accuracy: 0.0901\n",
      "Epoch 183/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6025 - accuracy: 0.0903\n",
      "Epoch 184/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5714 - accuracy: 0.0930\n",
      "Epoch 185/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6138 - accuracy: 0.0912\n",
      "Epoch 186/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5912 - accuracy: 0.0914\n",
      "Epoch 187/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5877 - accuracy: 0.1021\n",
      "Epoch 188/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5572 - accuracy: 0.0887\n",
      "Epoch 189/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5639 - accuracy: 0.0850\n",
      "Epoch 190/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5769 - accuracy: 0.0856\n",
      "Epoch 191/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5725 - accuracy: 0.0868\n",
      "Epoch 192/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5648 - accuracy: 0.0805\n",
      "Epoch 193/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5123 - accuracy: 0.0963\n",
      "Epoch 194/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5825 - accuracy: 0.0875\n",
      "Epoch 195/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5466 - accuracy: 0.0907\n",
      "Epoch 196/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5088 - accuracy: 0.0872\n",
      "Epoch 197/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5274 - accuracy: 0.0906\n",
      "Epoch 198/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5002 - accuracy: 0.0976\n",
      "Epoch 199/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5263 - accuracy: 0.0910\n",
      "Epoch 200/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4828 - accuracy: 0.0965\n",
      "Epoch 201/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.5384 - accuracy: 0.0840\n",
      "Epoch 202/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4759 - accuracy: 0.0976\n",
      "Epoch 203/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4266 - accuracy: 0.1016\n",
      "Epoch 204/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4545 - accuracy: 0.0962\n",
      "Epoch 205/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4679 - accuracy: 0.1026\n",
      "Epoch 206/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4383 - accuracy: 0.0989\n",
      "Epoch 207/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4366 - accuracy: 0.1006\n",
      "Epoch 208/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4478 - accuracy: 0.0952\n",
      "Epoch 209/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3809 - accuracy: 0.1024\n",
      "Epoch 210/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4564 - accuracy: 0.1005\n",
      "Epoch 211/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4569 - accuracy: 0.1027\n",
      "Epoch 212/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4294 - accuracy: 0.0972\n",
      "Epoch 213/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4051 - accuracy: 0.1124\n",
      "Epoch 214/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3633 - accuracy: 0.1087\n",
      "Epoch 215/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4068 - accuracy: 0.1022\n",
      "Epoch 216/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4018 - accuracy: 0.1088\n",
      "Epoch 217/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4005 - accuracy: 0.1007\n",
      "Epoch 218/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3803 - accuracy: 0.1079\n",
      "Epoch 219/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3676 - accuracy: 0.1035\n",
      "Epoch 220/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3503 - accuracy: 0.1066\n",
      "Epoch 221/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3641 - accuracy: 0.1036\n",
      "Epoch 222/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3280 - accuracy: 0.1002\n",
      "Epoch 223/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3648 - accuracy: 0.0994\n",
      "Epoch 224/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3401 - accuracy: 0.1072\n",
      "Epoch 225/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3133 - accuracy: 0.1092\n",
      "Epoch 226/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3027 - accuracy: 0.1034\n",
      "Epoch 227/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3179 - accuracy: 0.1129\n",
      "Epoch 228/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2963 - accuracy: 0.1130\n",
      "Epoch 229/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3224 - accuracy: 0.1059\n",
      "Epoch 230/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2610 - accuracy: 0.1151\n",
      "Epoch 231/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2826 - accuracy: 0.1107\n",
      "Epoch 232/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2894 - accuracy: 0.1148\n",
      "Epoch 233/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2560 - accuracy: 0.1118\n",
      "Epoch 234/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2926 - accuracy: 0.1091\n",
      "Epoch 235/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2361 - accuracy: 0.1072\n",
      "Epoch 236/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2977 - accuracy: 0.1052\n",
      "Epoch 237/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2536 - accuracy: 0.1115\n",
      "Epoch 238/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2680 - accuracy: 0.1229\n",
      "Epoch 239/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2698 - accuracy: 0.1121\n",
      "Epoch 240/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2018 - accuracy: 0.1119\n",
      "Epoch 241/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2746 - accuracy: 0.1134\n",
      "Epoch 242/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2397 - accuracy: 0.1089\n",
      "Epoch 243/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2092 - accuracy: 0.1193\n",
      "Epoch 244/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2496 - accuracy: 0.1056\n",
      "Epoch 245/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1991 - accuracy: 0.1139\n",
      "Epoch 246/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1718 - accuracy: 0.1196\n",
      "Epoch 247/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1841 - accuracy: 0.1223\n",
      "Epoch 248/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2023 - accuracy: 0.1200\n",
      "Epoch 249/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1676 - accuracy: 0.1176\n",
      "Epoch 250/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1347 - accuracy: 0.1245\n",
      "Epoch 251/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1052 - accuracy: 0.1319\n",
      "Epoch 252/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1806 - accuracy: 0.1216\n",
      "Epoch 253/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1573 - accuracy: 0.1224\n",
      "Epoch 254/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1273 - accuracy: 0.1251\n",
      "Epoch 255/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1628 - accuracy: 0.1188\n",
      "Epoch 256/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1225 - accuracy: 0.1289\n",
      "Epoch 257/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1146 - accuracy: 0.1354\n",
      "Epoch 258/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0930 - accuracy: 0.1280\n",
      "Epoch 259/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0981 - accuracy: 0.1242\n",
      "Epoch 260/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1004 - accuracy: 0.1262\n",
      "Epoch 261/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1234 - accuracy: 0.1289\n",
      "Epoch 262/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.1072 - accuracy: 0.1257\n",
      "Epoch 263/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0963 - accuracy: 0.1340\n",
      "Epoch 264/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0462 - accuracy: 0.1251\n",
      "Epoch 265/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0830 - accuracy: 0.1289\n",
      "Epoch 266/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0689 - accuracy: 0.1376\n",
      "Epoch 267/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0569 - accuracy: 0.1332\n",
      "Epoch 268/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0503 - accuracy: 0.1270\n",
      "Epoch 269/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0661 - accuracy: 0.1285\n",
      "Epoch 270/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0489 - accuracy: 0.1426\n",
      "Epoch 271/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0642 - accuracy: 0.1269\n",
      "Epoch 272/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0411 - accuracy: 0.1356\n",
      "Epoch 273/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0294 - accuracy: 0.1351\n",
      "Epoch 274/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0219 - accuracy: 0.1360\n",
      "Epoch 275/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0026 - accuracy: 0.1383\n",
      "Epoch 276/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0259 - accuracy: 0.1342\n",
      "Epoch 277/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0285 - accuracy: 0.1370\n",
      "Epoch 278/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9912 - accuracy: 0.1379\n",
      "Epoch 279/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9724 - accuracy: 0.1359\n",
      "Epoch 280/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9784 - accuracy: 0.1363\n",
      "Epoch 281/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9627 - accuracy: 0.1443\n",
      "Epoch 282/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9518 - accuracy: 0.1440\n",
      "Epoch 283/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9487 - accuracy: 0.1456\n",
      "Epoch 284/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9915 - accuracy: 0.1444\n",
      "Epoch 285/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9688 - accuracy: 0.1373\n",
      "Epoch 286/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9701 - accuracy: 0.1469\n",
      "Epoch 287/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9125 - accuracy: 0.1530\n",
      "Epoch 288/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9432 - accuracy: 0.1401\n",
      "Epoch 289/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9554 - accuracy: 0.1462\n",
      "Epoch 290/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9084 - accuracy: 0.1454\n",
      "Epoch 291/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9247 - accuracy: 0.1398\n",
      "Epoch 292/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9097 - accuracy: 0.1577\n",
      "Epoch 293/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9130 - accuracy: 0.1398\n",
      "Epoch 294/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9053 - accuracy: 0.1425\n",
      "Epoch 295/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8931 - accuracy: 0.1501\n",
      "Epoch 296/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8777 - accuracy: 0.1590\n",
      "Epoch 297/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8511 - accuracy: 0.1533\n",
      "Epoch 298/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8761 - accuracy: 0.1624\n",
      "Epoch 299/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8607 - accuracy: 0.1632\n",
      "Epoch 300/300\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8686 - accuracy: 0.1557\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 23, 128)           259456    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 23, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2027)              520939    \n",
      "=================================================================\n",
      "Total params: 1,043,563\n",
      "Trainable params: 1,043,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_bilstm_smaller_step_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 128, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(128,return_sequences=False, kernel_initializer='random_uniform')),\n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "single_bilstm_smaller_step_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "single_bilstm_smaller_step_model.fit(xs,ys,epochs=300,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "single_bilstm_smaller_step_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-raleigh",
   "metadata": {},
   "source": [
    "#### Single Bidirectional LSTM layer model 1000 epochs 128 units 0.001 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powered-judges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "145/145 [==============================] - 6s 22ms/step - loss: 7.0705 - accuracy: 0.0369\n",
      "Epoch 2/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.4435 - accuracy: 0.0445\n",
      "Epoch 3/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.3419 - accuracy: 0.0441\n",
      "Epoch 4/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.2473 - accuracy: 0.0466\n",
      "Epoch 5/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.1209 - accuracy: 0.0580\n",
      "Epoch 6/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 6.0157 - accuracy: 0.0525\n",
      "Epoch 7/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.8648 - accuracy: 0.0610\n",
      "Epoch 8/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.7227 - accuracy: 0.0681\n",
      "Epoch 9/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.6885 - accuracy: 0.0592\n",
      "Epoch 10/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.5039 - accuracy: 0.0744\n",
      "Epoch 11/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.3636 - accuracy: 0.0733\n",
      "Epoch 12/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.2858 - accuracy: 0.0769\n",
      "Epoch 13/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 5.1117 - accuracy: 0.0864\n",
      "Epoch 14/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9565 - accuracy: 0.0887\n",
      "Epoch 15/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.9322 - accuracy: 0.0948\n",
      "Epoch 16/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.7098 - accuracy: 0.0951\n",
      "Epoch 17/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.6057 - accuracy: 0.1209\n",
      "Epoch 18/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.4749 - accuracy: 0.1271\n",
      "Epoch 19/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.3412 - accuracy: 0.1479\n",
      "Epoch 20/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.2391 - accuracy: 0.1540\n",
      "Epoch 21/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 4.0791 - accuracy: 0.1681\n",
      "Epoch 22/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.9446 - accuracy: 0.1893\n",
      "Epoch 23/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.8867 - accuracy: 0.1874\n",
      "Epoch 24/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.7388 - accuracy: 0.2125\n",
      "Epoch 25/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.6979 - accuracy: 0.2335\n",
      "Epoch 26/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.5213 - accuracy: 0.2475\n",
      "Epoch 27/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.4165 - accuracy: 0.2710\n",
      "Epoch 28/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.3172 - accuracy: 0.2786\n",
      "Epoch 29/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.2500 - accuracy: 0.2846\n",
      "Epoch 30/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1658 - accuracy: 0.3030\n",
      "Epoch 31/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.1339 - accuracy: 0.3094\n",
      "Epoch 32/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 3.0079 - accuracy: 0.3307\n",
      "Epoch 33/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.9078 - accuracy: 0.3562\n",
      "Epoch 34/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8838 - accuracy: 0.3585\n",
      "Epoch 35/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.8317 - accuracy: 0.3831\n",
      "Epoch 36/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.6997 - accuracy: 0.4040\n",
      "Epoch 37/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.6160 - accuracy: 0.4140\n",
      "Epoch 38/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.5828 - accuracy: 0.4132\n",
      "Epoch 39/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 2.5592 - accuracy: 0.4112\n",
      "Epoch 40/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.4868 - accuracy: 0.4340\n",
      "Epoch 41/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.4145 - accuracy: 0.4435\n",
      "Epoch 42/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.3495 - accuracy: 0.4712\n",
      "Epoch 43/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.2974 - accuracy: 0.4778\n",
      "Epoch 44/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.2660 - accuracy: 0.4726\n",
      "Epoch 45/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.2420 - accuracy: 0.4825\n",
      "Epoch 46/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.2054 - accuracy: 0.4829\n",
      "Epoch 47/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.0729 - accuracy: 0.5291\n",
      "Epoch 48/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 2.0628 - accuracy: 0.5240\n",
      "Epoch 49/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 2.0106 - accuracy: 0.5275\n",
      "Epoch 50/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.9397 - accuracy: 0.5408\n",
      "Epoch 51/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.9446 - accuracy: 0.5334\n",
      "Epoch 52/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.9059 - accuracy: 0.5460\n",
      "Epoch 53/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.8627 - accuracy: 0.5477\n",
      "Epoch 54/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.8256 - accuracy: 0.5637\n",
      "Epoch 55/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.7926 - accuracy: 0.5665\n",
      "Epoch 56/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.7676 - accuracy: 0.5681\n",
      "Epoch 57/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.7363 - accuracy: 0.5903\n",
      "Epoch 58/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.6541 - accuracy: 0.6100\n",
      "Epoch 59/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.6487 - accuracy: 0.6093\n",
      "Epoch 60/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.6165 - accuracy: 0.6085\n",
      "Epoch 61/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5625 - accuracy: 0.6149\n",
      "Epoch 62/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5448 - accuracy: 0.6209\n",
      "Epoch 63/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.5137 - accuracy: 0.6346\n",
      "Epoch 64/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.4952 - accuracy: 0.6373\n",
      "Epoch 65/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.4554 - accuracy: 0.6498\n",
      "Epoch 66/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.4581 - accuracy: 0.6445\n",
      "Epoch 67/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.4303 - accuracy: 0.6520\n",
      "Epoch 68/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3731 - accuracy: 0.6616\n",
      "Epoch 69/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3769 - accuracy: 0.6503\n",
      "Epoch 70/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3809 - accuracy: 0.6495\n",
      "Epoch 71/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3523 - accuracy: 0.6613\n",
      "Epoch 72/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2914 - accuracy: 0.6830\n",
      "Epoch 73/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.3234 - accuracy: 0.6670\n",
      "Epoch 74/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2812 - accuracy: 0.6843\n",
      "Epoch 75/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2248 - accuracy: 0.6934\n",
      "Epoch 76/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2213 - accuracy: 0.7086\n",
      "Epoch 77/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2244 - accuracy: 0.6938\n",
      "Epoch 78/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2489 - accuracy: 0.6886\n",
      "Epoch 79/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.2026 - accuracy: 0.6908\n",
      "Epoch 80/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1437 - accuracy: 0.7073\n",
      "Epoch 81/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1636 - accuracy: 0.7061\n",
      "Epoch 82/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1326 - accuracy: 0.7118\n",
      "Epoch 83/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1541 - accuracy: 0.7111\n",
      "Epoch 84/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1324 - accuracy: 0.7087\n",
      "Epoch 85/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.1591 - accuracy: 0.6984\n",
      "Epoch 86/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0848 - accuracy: 0.7230\n",
      "Epoch 87/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0874 - accuracy: 0.7225\n",
      "Epoch 88/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0470 - accuracy: 0.7299\n",
      "Epoch 89/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0809 - accuracy: 0.7201\n",
      "Epoch 90/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0209 - accuracy: 0.7351\n",
      "Epoch 91/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0233 - accuracy: 0.7246\n",
      "Epoch 92/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9919 - accuracy: 0.7381\n",
      "Epoch 93/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0269 - accuracy: 0.7384\n",
      "Epoch 94/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9855 - accuracy: 0.7396\n",
      "Epoch 95/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9673 - accuracy: 0.7449\n",
      "Epoch 96/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9863 - accuracy: 0.7376\n",
      "Epoch 97/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 1.0027 - accuracy: 0.7346\n",
      "Epoch 98/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9286 - accuracy: 0.7561\n",
      "Epoch 99/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9515 - accuracy: 0.7509\n",
      "Epoch 100/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8904 - accuracy: 0.7682\n",
      "Epoch 101/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9092 - accuracy: 0.7605\n",
      "Epoch 102/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9112 - accuracy: 0.7585\n",
      "Epoch 103/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9168 - accuracy: 0.7514\n",
      "Epoch 104/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9294 - accuracy: 0.7518\n",
      "Epoch 105/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8402 - accuracy: 0.7787\n",
      "Epoch 106/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9243 - accuracy: 0.7384\n",
      "Epoch 107/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8476 - accuracy: 0.7684\n",
      "Epoch 108/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8956 - accuracy: 0.7582\n",
      "Epoch 109/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.9252 - accuracy: 0.7502\n",
      "Epoch 110/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8880 - accuracy: 0.7665\n",
      "Epoch 111/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8708 - accuracy: 0.7611\n",
      "Epoch 112/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8541 - accuracy: 0.7660\n",
      "Epoch 113/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8191 - accuracy: 0.7781\n",
      "Epoch 114/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8233 - accuracy: 0.7814\n",
      "Epoch 115/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8150 - accuracy: 0.7819\n",
      "Epoch 116/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8378 - accuracy: 0.7654\n",
      "Epoch 117/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.8019 - accuracy: 0.7901\n",
      "Epoch 118/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7841 - accuracy: 0.7851\n",
      "Epoch 119/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7792 - accuracy: 0.7919\n",
      "Epoch 120/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7858 - accuracy: 0.7854\n",
      "Epoch 121/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7799 - accuracy: 0.7880\n",
      "Epoch 122/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7603 - accuracy: 0.7965\n",
      "Epoch 123/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7548 - accuracy: 0.7878\n",
      "Epoch 124/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7618 - accuracy: 0.7950\n",
      "Epoch 125/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.7484 - accuracy: 0.7944\n",
      "Epoch 126/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7424 - accuracy: 0.7979\n",
      "Epoch 127/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7412 - accuracy: 0.7995\n",
      "Epoch 128/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7379 - accuracy: 0.7930\n",
      "Epoch 129/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7269 - accuracy: 0.7944\n",
      "Epoch 130/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7052 - accuracy: 0.8010\n",
      "Epoch 131/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7002 - accuracy: 0.8068\n",
      "Epoch 132/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7257 - accuracy: 0.7990\n",
      "Epoch 133/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7268 - accuracy: 0.7928\n",
      "Epoch 134/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7216 - accuracy: 0.8016\n",
      "Epoch 135/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7292 - accuracy: 0.7982\n",
      "Epoch 136/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6555 - accuracy: 0.8234\n",
      "Epoch 137/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6918 - accuracy: 0.8131\n",
      "Epoch 138/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6879 - accuracy: 0.8106\n",
      "Epoch 139/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7129 - accuracy: 0.8053\n",
      "Epoch 140/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.7056 - accuracy: 0.8009\n",
      "Epoch 141/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6802 - accuracy: 0.8127\n",
      "Epoch 142/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6883 - accuracy: 0.8045\n",
      "Epoch 143/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6755 - accuracy: 0.8130\n",
      "Epoch 144/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6589 - accuracy: 0.8174\n",
      "Epoch 145/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6498 - accuracy: 0.8201\n",
      "Epoch 146/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6398 - accuracy: 0.8198\n",
      "Epoch 147/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6610 - accuracy: 0.8211\n",
      "Epoch 148/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6501 - accuracy: 0.8266\n",
      "Epoch 149/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6680 - accuracy: 0.8139\n",
      "Epoch 150/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5901 - accuracy: 0.8323\n",
      "Epoch 151/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6079 - accuracy: 0.8281\n",
      "Epoch 152/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6755 - accuracy: 0.8033\n",
      "Epoch 153/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6518 - accuracy: 0.8187\n",
      "Epoch 154/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6282 - accuracy: 0.8244\n",
      "Epoch 155/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6270 - accuracy: 0.8215\n",
      "Epoch 156/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6277 - accuracy: 0.8254\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6160 - accuracy: 0.8296\n",
      "Epoch 158/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6222 - accuracy: 0.8230\n",
      "Epoch 159/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.5925 - accuracy: 0.8327\n",
      "Epoch 160/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6291 - accuracy: 0.8245\n",
      "Epoch 161/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6376 - accuracy: 0.8138\n",
      "Epoch 162/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5847 - accuracy: 0.8281\n",
      "Epoch 163/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6091 - accuracy: 0.8249\n",
      "Epoch 164/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5887 - accuracy: 0.8300\n",
      "Epoch 165/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5920 - accuracy: 0.8246\n",
      "Epoch 166/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6051 - accuracy: 0.8193\n",
      "Epoch 167/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6050 - accuracy: 0.8325\n",
      "Epoch 168/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6098 - accuracy: 0.8205\n",
      "Epoch 169/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5426 - accuracy: 0.8449\n",
      "Epoch 170/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5715 - accuracy: 0.8354\n",
      "Epoch 171/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5539 - accuracy: 0.8409\n",
      "Epoch 172/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5904 - accuracy: 0.8231\n",
      "Epoch 173/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.6094 - accuracy: 0.8249\n",
      "Epoch 174/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5731 - accuracy: 0.8337\n",
      "Epoch 175/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5577 - accuracy: 0.8404\n",
      "Epoch 176/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5728 - accuracy: 0.8381\n",
      "Epoch 177/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5863 - accuracy: 0.8245\n",
      "Epoch 178/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5593 - accuracy: 0.8379\n",
      "Epoch 179/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5551 - accuracy: 0.8437\n",
      "Epoch 180/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5678 - accuracy: 0.8303\n",
      "Epoch 181/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5757 - accuracy: 0.8313\n",
      "Epoch 182/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5489 - accuracy: 0.8416\n",
      "Epoch 183/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5376 - accuracy: 0.8523\n",
      "Epoch 184/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5446 - accuracy: 0.8411\n",
      "Epoch 185/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5589 - accuracy: 0.8421\n",
      "Epoch 186/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5452 - accuracy: 0.8396\n",
      "Epoch 187/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5286 - accuracy: 0.8513\n",
      "Epoch 188/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5721 - accuracy: 0.8284\n",
      "Epoch 189/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5444 - accuracy: 0.8454\n",
      "Epoch 190/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5307 - accuracy: 0.8502\n",
      "Epoch 191/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5160 - accuracy: 0.8580\n",
      "Epoch 192/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5261 - accuracy: 0.8483\n",
      "Epoch 193/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5079 - accuracy: 0.8517\n",
      "Epoch 194/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5833 - accuracy: 0.8299\n",
      "Epoch 195/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5436 - accuracy: 0.8362\n",
      "Epoch 196/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5083 - accuracy: 0.8509\n",
      "Epoch 197/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5357 - accuracy: 0.8382\n",
      "Epoch 198/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5016 - accuracy: 0.8581\n",
      "Epoch 199/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5322 - accuracy: 0.8402\n",
      "Epoch 200/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5499 - accuracy: 0.8353\n",
      "Epoch 201/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5357 - accuracy: 0.8485\n",
      "Epoch 202/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5308 - accuracy: 0.8474\n",
      "Epoch 203/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5057 - accuracy: 0.8488\n",
      "Epoch 204/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5082 - accuracy: 0.8523\n",
      "Epoch 205/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5111 - accuracy: 0.8513\n",
      "Epoch 206/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5392 - accuracy: 0.8376\n",
      "Epoch 207/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.5005 - accuracy: 0.8580\n",
      "Epoch 208/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5368 - accuracy: 0.8441\n",
      "Epoch 209/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5257 - accuracy: 0.8403\n",
      "Epoch 210/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4698 - accuracy: 0.8602\n",
      "Epoch 211/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5079 - accuracy: 0.8510\n",
      "Epoch 212/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4862 - accuracy: 0.8548\n",
      "Epoch 213/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5062 - accuracy: 0.8519\n",
      "Epoch 214/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4915 - accuracy: 0.8556\n",
      "Epoch 215/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5039 - accuracy: 0.8488\n",
      "Epoch 216/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4897 - accuracy: 0.8596\n",
      "Epoch 217/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4917 - accuracy: 0.8518\n",
      "Epoch 218/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4700 - accuracy: 0.8532\n",
      "Epoch 219/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5096 - accuracy: 0.8480\n",
      "Epoch 220/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4513 - accuracy: 0.8588\n",
      "Epoch 221/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4785 - accuracy: 0.8638\n",
      "Epoch 222/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4890 - accuracy: 0.8567\n",
      "Epoch 223/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4806 - accuracy: 0.8597\n",
      "Epoch 224/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.4538 - accuracy: 0.8663\n",
      "Epoch 225/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4838 - accuracy: 0.8528\n",
      "Epoch 226/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4526 - accuracy: 0.8656\n",
      "Epoch 227/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4970 - accuracy: 0.8560\n",
      "Epoch 228/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4845 - accuracy: 0.8555\n",
      "Epoch 229/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4893 - accuracy: 0.8535\n",
      "Epoch 230/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4558 - accuracy: 0.8641\n",
      "Epoch 231/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.5000 - accuracy: 0.8489\n",
      "Epoch 232/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4783 - accuracy: 0.8583\n",
      "Epoch 233/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4961 - accuracy: 0.8522\n",
      "Epoch 234/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4882 - accuracy: 0.8498\n",
      "Epoch 235/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4772 - accuracy: 0.8667\n",
      "Epoch 236/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4647 - accuracy: 0.8662\n",
      "Epoch 237/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4678 - accuracy: 0.8610\n",
      "Epoch 238/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4990 - accuracy: 0.8539\n",
      "Epoch 239/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4480 - accuracy: 0.8614\n",
      "Epoch 240/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4913 - accuracy: 0.8539\n",
      "Epoch 241/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4738 - accuracy: 0.8658\n",
      "Epoch 242/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4569 - accuracy: 0.8648\n",
      "Epoch 243/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4400 - accuracy: 0.8670\n",
      "Epoch 244/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4473 - accuracy: 0.8698\n",
      "Epoch 245/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4675 - accuracy: 0.8616\n",
      "Epoch 246/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4538 - accuracy: 0.8662\n",
      "Epoch 247/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4565 - accuracy: 0.8602\n",
      "Epoch 248/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4827 - accuracy: 0.8544\n",
      "Epoch 249/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4673 - accuracy: 0.8677\n",
      "Epoch 250/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4552 - accuracy: 0.8668\n",
      "Epoch 251/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4413 - accuracy: 0.8665\n",
      "Epoch 252/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4485 - accuracy: 0.8640\n",
      "Epoch 253/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4671 - accuracy: 0.8601\n",
      "Epoch 254/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.4502 - accuracy: 0.8656\n",
      "Epoch 255/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4320 - accuracy: 0.8657\n",
      "Epoch 256/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4572 - accuracy: 0.8598\n",
      "Epoch 257/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4468 - accuracy: 0.8664\n",
      "Epoch 258/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4460 - accuracy: 0.8614\n",
      "Epoch 259/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4549 - accuracy: 0.8612\n",
      "Epoch 260/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4635 - accuracy: 0.8580\n",
      "Epoch 261/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4576 - accuracy: 0.8582\n",
      "Epoch 262/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4445 - accuracy: 0.8628\n",
      "Epoch 263/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4403 - accuracy: 0.8747\n",
      "Epoch 264/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4189 - accuracy: 0.8707\n",
      "Epoch 265/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4369 - accuracy: 0.8689\n",
      "Epoch 266/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4391 - accuracy: 0.8678\n",
      "Epoch 267/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4458 - accuracy: 0.8675\n",
      "Epoch 268/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4356 - accuracy: 0.8672\n",
      "Epoch 269/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4258 - accuracy: 0.8747\n",
      "Epoch 270/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4452 - accuracy: 0.8624\n",
      "Epoch 271/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4373 - accuracy: 0.8712\n",
      "Epoch 272/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4333 - accuracy: 0.8709\n",
      "Epoch 273/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4467 - accuracy: 0.8602\n",
      "Epoch 274/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4472 - accuracy: 0.8628\n",
      "Epoch 275/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4524 - accuracy: 0.8587\n",
      "Epoch 276/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4240 - accuracy: 0.8694\n",
      "Epoch 277/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4618 - accuracy: 0.8633\n",
      "Epoch 278/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4320 - accuracy: 0.8696\n",
      "Epoch 279/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4265 - accuracy: 0.8676\n",
      "Epoch 280/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.4514 - accuracy: 0.8588\n",
      "Epoch 281/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4287 - accuracy: 0.8687\n",
      "Epoch 282/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4447 - accuracy: 0.8685\n",
      "Epoch 283/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3972 - accuracy: 0.8847\n",
      "Epoch 284/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4125 - accuracy: 0.8760\n",
      "Epoch 285/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4294 - accuracy: 0.8657\n",
      "Epoch 286/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4483 - accuracy: 0.8582\n",
      "Epoch 287/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4067 - accuracy: 0.8781\n",
      "Epoch 288/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4361 - accuracy: 0.8684\n",
      "Epoch 289/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4301 - accuracy: 0.8665\n",
      "Epoch 290/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4214 - accuracy: 0.8753\n",
      "Epoch 291/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3956 - accuracy: 0.8759\n",
      "Epoch 292/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4556 - accuracy: 0.8595\n",
      "Epoch 293/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4265 - accuracy: 0.8666\n",
      "Epoch 294/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4295 - accuracy: 0.8696\n",
      "Epoch 295/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4138 - accuracy: 0.8790\n",
      "Epoch 296/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4022 - accuracy: 0.8727\n",
      "Epoch 297/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4281 - accuracy: 0.8701\n",
      "Epoch 298/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4112 - accuracy: 0.8711\n",
      "Epoch 299/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4190 - accuracy: 0.8715\n",
      "Epoch 300/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4243 - accuracy: 0.8718\n",
      "Epoch 301/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4040 - accuracy: 0.8718\n",
      "Epoch 302/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4453 - accuracy: 0.8643\n",
      "Epoch 303/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4327 - accuracy: 0.8655\n",
      "Epoch 304/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4220 - accuracy: 0.8682\n",
      "Epoch 305/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4319 - accuracy: 0.8690\n",
      "Epoch 306/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4308 - accuracy: 0.8690\n",
      "Epoch 307/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4286 - accuracy: 0.8690\n",
      "Epoch 308/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3992 - accuracy: 0.8789\n",
      "Epoch 309/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4481 - accuracy: 0.8623\n",
      "Epoch 310/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4114 - accuracy: 0.8753\n",
      "Epoch 311/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4289 - accuracy: 0.8724\n",
      "Epoch 312/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4251 - accuracy: 0.8657\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4049 - accuracy: 0.8785\n",
      "Epoch 314/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4270 - accuracy: 0.8733\n",
      "Epoch 315/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4223 - accuracy: 0.8717\n",
      "Epoch 316/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4207 - accuracy: 0.8703\n",
      "Epoch 317/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4199 - accuracy: 0.8716\n",
      "Epoch 318/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4249 - accuracy: 0.8637\n",
      "Epoch 319/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4049 - accuracy: 0.8721\n",
      "Epoch 320/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4248 - accuracy: 0.8635\n",
      "Epoch 321/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4031 - accuracy: 0.8691\n",
      "Epoch 322/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4084 - accuracy: 0.8700\n",
      "Epoch 323/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4310 - accuracy: 0.8721\n",
      "Epoch 324/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4089 - accuracy: 0.8790\n",
      "Epoch 325/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4280 - accuracy: 0.8644\n",
      "Epoch 326/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4124 - accuracy: 0.8743\n",
      "Epoch 327/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4002 - accuracy: 0.8791\n",
      "Epoch 328/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4014 - accuracy: 0.8791\n",
      "Epoch 329/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4181 - accuracy: 0.8727\n",
      "Epoch 330/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3886 - accuracy: 0.8829\n",
      "Epoch 331/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4355 - accuracy: 0.8618\n",
      "Epoch 332/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4241 - accuracy: 0.8756\n",
      "Epoch 333/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4116 - accuracy: 0.8714\n",
      "Epoch 334/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4099 - accuracy: 0.8690\n",
      "Epoch 335/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3943 - accuracy: 0.8777\n",
      "Epoch 336/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4054 - accuracy: 0.8732\n",
      "Epoch 337/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3902 - accuracy: 0.8808\n",
      "Epoch 338/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3986 - accuracy: 0.8768\n",
      "Epoch 339/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3790 - accuracy: 0.8784\n",
      "Epoch 340/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3898 - accuracy: 0.8781\n",
      "Epoch 341/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4070 - accuracy: 0.8749\n",
      "Epoch 342/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4124 - accuracy: 0.8702\n",
      "Epoch 343/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4050 - accuracy: 0.8741\n",
      "Epoch 344/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4344 - accuracy: 0.8583\n",
      "Epoch 345/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3807 - accuracy: 0.8750\n",
      "Epoch 346/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3858 - accuracy: 0.8756\n",
      "Epoch 347/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4249 - accuracy: 0.8705\n",
      "Epoch 348/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4048 - accuracy: 0.8764\n",
      "Epoch 349/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4006 - accuracy: 0.8709\n",
      "Epoch 350/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3840 - accuracy: 0.8844\n",
      "Epoch 351/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4383 - accuracy: 0.8660\n",
      "Epoch 352/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3919 - accuracy: 0.8769\n",
      "Epoch 353/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3986 - accuracy: 0.8749\n",
      "Epoch 354/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4012 - accuracy: 0.8757\n",
      "Epoch 355/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3958 - accuracy: 0.8754\n",
      "Epoch 356/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4039 - accuracy: 0.8750\n",
      "Epoch 357/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3815 - accuracy: 0.8794\n",
      "Epoch 358/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3933 - accuracy: 0.8743\n",
      "Epoch 359/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3946 - accuracy: 0.8655\n",
      "Epoch 360/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3779 - accuracy: 0.8806\n",
      "Epoch 361/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4090 - accuracy: 0.8709\n",
      "Epoch 362/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4291 - accuracy: 0.8628\n",
      "Epoch 363/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4005 - accuracy: 0.8762\n",
      "Epoch 364/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3779 - accuracy: 0.8881\n",
      "Epoch 365/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3782 - accuracy: 0.8837\n",
      "Epoch 366/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3802 - accuracy: 0.8761\n",
      "Epoch 367/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4011 - accuracy: 0.8784\n",
      "Epoch 368/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3923 - accuracy: 0.8728\n",
      "Epoch 369/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3713 - accuracy: 0.8796\n",
      "Epoch 370/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3902 - accuracy: 0.8781\n",
      "Epoch 371/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3631 - accuracy: 0.8811\n",
      "Epoch 372/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3765 - accuracy: 0.8807\n",
      "Epoch 373/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4037 - accuracy: 0.8742\n",
      "Epoch 374/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4021 - accuracy: 0.8728\n",
      "Epoch 375/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3816 - accuracy: 0.8740\n",
      "Epoch 376/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4023 - accuracy: 0.8749\n",
      "Epoch 377/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4362 - accuracy: 0.8706\n",
      "Epoch 378/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3861 - accuracy: 0.8812\n",
      "Epoch 379/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3718 - accuracy: 0.8809\n",
      "Epoch 380/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3899 - accuracy: 0.8767\n",
      "Epoch 381/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4016 - accuracy: 0.8682\n",
      "Epoch 382/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4181 - accuracy: 0.8696\n",
      "Epoch 383/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3643 - accuracy: 0.8835\n",
      "Epoch 384/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4086 - accuracy: 0.8717\n",
      "Epoch 385/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3987 - accuracy: 0.8733\n",
      "Epoch 386/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3663 - accuracy: 0.8842\n",
      "Epoch 387/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3626 - accuracy: 0.8856\n",
      "Epoch 388/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3877 - accuracy: 0.8752\n",
      "Epoch 389/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3927 - accuracy: 0.8797\n",
      "Epoch 390/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3975 - accuracy: 0.8754\n",
      "Epoch 391/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3513 - accuracy: 0.8841\n",
      "Epoch 392/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3870 - accuracy: 0.8728\n",
      "Epoch 393/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3872 - accuracy: 0.8732\n",
      "Epoch 394/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3970 - accuracy: 0.8747\n",
      "Epoch 395/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3956 - accuracy: 0.8755\n",
      "Epoch 396/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3973 - accuracy: 0.8698\n",
      "Epoch 397/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3543 - accuracy: 0.8817\n",
      "Epoch 398/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3753 - accuracy: 0.8818\n",
      "Epoch 399/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3797 - accuracy: 0.8772\n",
      "Epoch 400/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3747 - accuracy: 0.8807\n",
      "Epoch 401/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3794 - accuracy: 0.8800\n",
      "Epoch 402/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3781 - accuracy: 0.8771\n",
      "Epoch 403/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3996 - accuracy: 0.8698\n",
      "Epoch 404/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4114 - accuracy: 0.8660\n",
      "Epoch 405/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3874 - accuracy: 0.8799\n",
      "Epoch 406/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3719 - accuracy: 0.8785\n",
      "Epoch 407/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3664 - accuracy: 0.8819\n",
      "Epoch 408/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3805 - accuracy: 0.8723\n",
      "Epoch 409/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3693 - accuracy: 0.8749\n",
      "Epoch 410/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3925 - accuracy: 0.8701\n",
      "Epoch 411/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3837 - accuracy: 0.8803\n",
      "Epoch 412/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3844 - accuracy: 0.8764\n",
      "Epoch 413/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3660 - accuracy: 0.8886\n",
      "Epoch 414/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3677 - accuracy: 0.8751\n",
      "Epoch 415/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3674 - accuracy: 0.8792\n",
      "Epoch 416/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3966 - accuracy: 0.8792\n",
      "Epoch 417/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3767 - accuracy: 0.8745\n",
      "Epoch 418/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3903 - accuracy: 0.8758\n",
      "Epoch 419/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3597 - accuracy: 0.8857\n",
      "Epoch 420/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3651 - accuracy: 0.8748\n",
      "Epoch 421/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3945 - accuracy: 0.8724\n",
      "Epoch 422/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3534 - accuracy: 0.8818\n",
      "Epoch 423/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3679 - accuracy: 0.8769\n",
      "Epoch 424/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3862 - accuracy: 0.8776\n",
      "Epoch 425/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3990 - accuracy: 0.8718\n",
      "Epoch 426/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3632 - accuracy: 0.8840\n",
      "Epoch 427/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3774 - accuracy: 0.8771\n",
      "Epoch 428/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3901 - accuracy: 0.8747\n",
      "Epoch 429/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3356 - accuracy: 0.8927\n",
      "Epoch 430/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3485 - accuracy: 0.8846\n",
      "Epoch 431/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3600 - accuracy: 0.8809\n",
      "Epoch 432/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3672 - accuracy: 0.8802\n",
      "Epoch 433/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3348 - accuracy: 0.8878\n",
      "Epoch 434/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3808 - accuracy: 0.8738\n",
      "Epoch 435/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3652 - accuracy: 0.8768\n",
      "Epoch 436/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4001 - accuracy: 0.8690\n",
      "Epoch 437/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3798 - accuracy: 0.8801\n",
      "Epoch 438/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3756 - accuracy: 0.8724\n",
      "Epoch 439/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3470 - accuracy: 0.8910\n",
      "Epoch 440/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3841 - accuracy: 0.8737\n",
      "Epoch 441/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3322 - accuracy: 0.8953\n",
      "Epoch 442/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3561 - accuracy: 0.8820\n",
      "Epoch 443/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3646 - accuracy: 0.8788\n",
      "Epoch 444/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3720 - accuracy: 0.8815\n",
      "Epoch 445/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3938 - accuracy: 0.8774\n",
      "Epoch 446/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3855 - accuracy: 0.8727\n",
      "Epoch 447/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3771 - accuracy: 0.8788\n",
      "Epoch 448/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3592 - accuracy: 0.8830\n",
      "Epoch 449/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3389 - accuracy: 0.8886\n",
      "Epoch 450/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3739 - accuracy: 0.8857\n",
      "Epoch 451/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3671 - accuracy: 0.8739\n",
      "Epoch 452/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3587 - accuracy: 0.8805\n",
      "Epoch 453/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3696 - accuracy: 0.8821\n",
      "Epoch 454/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3538 - accuracy: 0.8818\n",
      "Epoch 455/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3755 - accuracy: 0.8789\n",
      "Epoch 456/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3968 - accuracy: 0.8703\n",
      "Epoch 457/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3988 - accuracy: 0.8750\n",
      "Epoch 458/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3671 - accuracy: 0.8797\n",
      "Epoch 459/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3465 - accuracy: 0.8865\n",
      "Epoch 460/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3746 - accuracy: 0.8779\n",
      "Epoch 461/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4012 - accuracy: 0.8742\n",
      "Epoch 462/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3628 - accuracy: 0.8842\n",
      "Epoch 463/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3974 - accuracy: 0.8710\n",
      "Epoch 464/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.4050 - accuracy: 0.8637\n",
      "Epoch 465/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3503 - accuracy: 0.8895\n",
      "Epoch 466/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3697 - accuracy: 0.8760\n",
      "Epoch 467/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3571 - accuracy: 0.8831\n",
      "Epoch 468/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3895 - accuracy: 0.8779\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3320 - accuracy: 0.8893\n",
      "Epoch 470/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3610 - accuracy: 0.8780\n",
      "Epoch 471/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3639 - accuracy: 0.8797\n",
      "Epoch 472/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3840 - accuracy: 0.8761\n",
      "Epoch 473/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3663 - accuracy: 0.8751\n",
      "Epoch 474/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3604 - accuracy: 0.8821\n",
      "Epoch 475/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3403 - accuracy: 0.8881\n",
      "Epoch 476/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3740 - accuracy: 0.8798\n",
      "Epoch 477/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3553 - accuracy: 0.8837\n",
      "Epoch 478/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3561 - accuracy: 0.8843\n",
      "Epoch 479/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3696 - accuracy: 0.8847\n",
      "Epoch 480/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3690 - accuracy: 0.8808\n",
      "Epoch 481/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3368 - accuracy: 0.8900\n",
      "Epoch 482/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3687 - accuracy: 0.8833\n",
      "Epoch 483/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3694 - accuracy: 0.8683\n",
      "Epoch 484/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3680 - accuracy: 0.8790\n",
      "Epoch 485/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3674 - accuracy: 0.8776\n",
      "Epoch 486/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3457 - accuracy: 0.8853\n",
      "Epoch 487/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3615 - accuracy: 0.8818\n",
      "Epoch 488/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3556 - accuracy: 0.8846\n",
      "Epoch 489/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3662 - accuracy: 0.8829\n",
      "Epoch 490/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3745 - accuracy: 0.8785\n",
      "Epoch 491/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3537 - accuracy: 0.8857\n",
      "Epoch 492/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3744 - accuracy: 0.8771\n",
      "Epoch 493/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3730 - accuracy: 0.8824\n",
      "Epoch 494/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3640 - accuracy: 0.8768\n",
      "Epoch 495/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3777 - accuracy: 0.8778\n",
      "Epoch 496/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3551 - accuracy: 0.8812\n",
      "Epoch 497/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3525 - accuracy: 0.8785\n",
      "Epoch 498/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3605 - accuracy: 0.8876\n",
      "Epoch 499/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3459 - accuracy: 0.8828\n",
      "Epoch 500/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3386 - accuracy: 0.8884\n",
      "Epoch 501/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3679 - accuracy: 0.8780\n",
      "Epoch 502/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3326 - accuracy: 0.8888\n",
      "Epoch 503/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3548 - accuracy: 0.8841\n",
      "Epoch 504/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3610 - accuracy: 0.8793\n",
      "Epoch 505/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3570 - accuracy: 0.8861\n",
      "Epoch 506/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3534 - accuracy: 0.8834\n",
      "Epoch 507/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3425 - accuracy: 0.8846\n",
      "Epoch 508/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3735 - accuracy: 0.8752\n",
      "Epoch 509/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3715 - accuracy: 0.8728\n",
      "Epoch 510/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3518 - accuracy: 0.8851\n",
      "Epoch 511/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3369 - accuracy: 0.8879\n",
      "Epoch 512/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3559 - accuracy: 0.8795\n",
      "Epoch 513/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3528 - accuracy: 0.8824\n",
      "Epoch 514/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3309 - accuracy: 0.8886\n",
      "Epoch 515/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3485 - accuracy: 0.8771\n",
      "Epoch 516/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3664 - accuracy: 0.8799\n",
      "Epoch 517/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3812 - accuracy: 0.8708\n",
      "Epoch 518/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3605 - accuracy: 0.8848\n",
      "Epoch 519/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3538 - accuracy: 0.8872\n",
      "Epoch 520/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3559 - accuracy: 0.8861\n",
      "Epoch 521/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3296 - accuracy: 0.8858\n",
      "Epoch 522/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3611 - accuracy: 0.8811\n",
      "Epoch 523/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3654 - accuracy: 0.8802\n",
      "Epoch 524/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3479 - accuracy: 0.8867\n",
      "Epoch 525/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3539 - accuracy: 0.8880\n",
      "Epoch 526/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3666 - accuracy: 0.8806\n",
      "Epoch 527/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3369 - accuracy: 0.8922\n",
      "Epoch 528/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3457 - accuracy: 0.8816\n",
      "Epoch 529/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3801 - accuracy: 0.8725\n",
      "Epoch 530/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3426 - accuracy: 0.8861\n",
      "Epoch 531/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3410 - accuracy: 0.8866\n",
      "Epoch 532/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3727 - accuracy: 0.8804\n",
      "Epoch 533/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3237 - accuracy: 0.8920\n",
      "Epoch 534/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3611 - accuracy: 0.8776\n",
      "Epoch 535/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3514 - accuracy: 0.8825\n",
      "Epoch 536/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3958 - accuracy: 0.8680\n",
      "Epoch 537/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3652 - accuracy: 0.8835\n",
      "Epoch 538/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3736 - accuracy: 0.8779\n",
      "Epoch 539/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3479 - accuracy: 0.8857\n",
      "Epoch 540/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3240 - accuracy: 0.8956\n",
      "Epoch 541/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3567 - accuracy: 0.8831\n",
      "Epoch 542/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3540 - accuracy: 0.8814\n",
      "Epoch 543/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3723 - accuracy: 0.8698\n",
      "Epoch 544/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3683 - accuracy: 0.8800\n",
      "Epoch 545/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3623 - accuracy: 0.8822\n",
      "Epoch 546/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3627 - accuracy: 0.8855\n",
      "Epoch 547/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3347 - accuracy: 0.8912\n",
      "Epoch 548/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3379 - accuracy: 0.8909\n",
      "Epoch 549/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3363 - accuracy: 0.8915\n",
      "Epoch 550/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3511 - accuracy: 0.8867\n",
      "Epoch 551/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3577 - accuracy: 0.8861\n",
      "Epoch 552/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3606 - accuracy: 0.8708\n",
      "Epoch 553/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3373 - accuracy: 0.8805\n",
      "Epoch 554/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3549 - accuracy: 0.8796\n",
      "Epoch 555/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3391 - accuracy: 0.8899\n",
      "Epoch 556/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3446 - accuracy: 0.8896\n",
      "Epoch 557/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3525 - accuracy: 0.8808\n",
      "Epoch 558/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3534 - accuracy: 0.8830\n",
      "Epoch 559/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3550 - accuracy: 0.8802\n",
      "Epoch 560/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3579 - accuracy: 0.8821\n",
      "Epoch 561/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3457 - accuracy: 0.8849\n",
      "Epoch 562/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3746 - accuracy: 0.8723\n",
      "Epoch 563/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3513 - accuracy: 0.8852\n",
      "Epoch 564/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3509 - accuracy: 0.8819\n",
      "Epoch 565/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3339 - accuracy: 0.8915\n",
      "Epoch 566/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3320 - accuracy: 0.8870\n",
      "Epoch 567/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3609 - accuracy: 0.8770\n",
      "Epoch 568/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3434 - accuracy: 0.8870\n",
      "Epoch 569/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3236 - accuracy: 0.8925\n",
      "Epoch 570/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3641 - accuracy: 0.8823\n",
      "Epoch 571/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3408 - accuracy: 0.8830\n",
      "Epoch 572/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3242 - accuracy: 0.8872\n",
      "Epoch 573/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3607 - accuracy: 0.8803\n",
      "Epoch 574/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3476 - accuracy: 0.8822\n",
      "Epoch 575/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3428 - accuracy: 0.8860\n",
      "Epoch 576/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3259 - accuracy: 0.8880\n",
      "Epoch 577/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3410 - accuracy: 0.8866\n",
      "Epoch 578/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3249 - accuracy: 0.8876\n",
      "Epoch 579/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3651 - accuracy: 0.8834\n",
      "Epoch 580/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3413 - accuracy: 0.8858\n",
      "Epoch 581/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3459 - accuracy: 0.8775\n",
      "Epoch 582/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3552 - accuracy: 0.8832\n",
      "Epoch 583/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3514 - accuracy: 0.8843\n",
      "Epoch 584/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3297 - accuracy: 0.8901\n",
      "Epoch 585/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3421 - accuracy: 0.8882\n",
      "Epoch 586/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3261 - accuracy: 0.8891\n",
      "Epoch 587/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3517 - accuracy: 0.8816\n",
      "Epoch 588/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3622 - accuracy: 0.8848\n",
      "Epoch 589/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3346 - accuracy: 0.8901\n",
      "Epoch 590/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3373 - accuracy: 0.8877\n",
      "Epoch 591/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3385 - accuracy: 0.8828\n",
      "Epoch 592/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3494 - accuracy: 0.8837\n",
      "Epoch 593/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3648 - accuracy: 0.8765\n",
      "Epoch 594/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3376 - accuracy: 0.8911\n",
      "Epoch 595/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3370 - accuracy: 0.8892\n",
      "Epoch 596/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3372 - accuracy: 0.8842\n",
      "Epoch 597/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3727 - accuracy: 0.8716\n",
      "Epoch 598/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3493 - accuracy: 0.8845\n",
      "Epoch 599/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3284 - accuracy: 0.8945\n",
      "Epoch 600/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3266 - accuracy: 0.8898\n",
      "Epoch 601/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3083 - accuracy: 0.8960\n",
      "Epoch 602/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3554 - accuracy: 0.8813\n",
      "Epoch 603/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3540 - accuracy: 0.8816\n",
      "Epoch 604/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3353 - accuracy: 0.8871\n",
      "Epoch 605/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3255 - accuracy: 0.8885\n",
      "Epoch 606/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3215 - accuracy: 0.8925\n",
      "Epoch 607/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3214 - accuracy: 0.8908\n",
      "Epoch 608/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3216 - accuracy: 0.8920\n",
      "Epoch 609/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3204 - accuracy: 0.8921\n",
      "Epoch 610/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3507 - accuracy: 0.8822\n",
      "Epoch 611/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3622 - accuracy: 0.8781\n",
      "Epoch 612/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3655 - accuracy: 0.8735\n",
      "Epoch 613/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3458 - accuracy: 0.8727\n",
      "Epoch 614/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3697 - accuracy: 0.8744\n",
      "Epoch 615/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3467 - accuracy: 0.8849\n",
      "Epoch 616/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3342 - accuracy: 0.8902\n",
      "Epoch 617/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3303 - accuracy: 0.8872\n",
      "Epoch 618/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3578 - accuracy: 0.8808\n",
      "Epoch 619/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3362 - accuracy: 0.8939\n",
      "Epoch 620/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3195 - accuracy: 0.8953\n",
      "Epoch 621/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3448 - accuracy: 0.8832\n",
      "Epoch 622/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3569 - accuracy: 0.8808\n",
      "Epoch 623/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3369 - accuracy: 0.8860\n",
      "Epoch 624/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3460 - accuracy: 0.8852\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3156 - accuracy: 0.8949\n",
      "Epoch 626/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3637 - accuracy: 0.8736\n",
      "Epoch 627/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3397 - accuracy: 0.8923\n",
      "Epoch 628/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2994 - accuracy: 0.8960\n",
      "Epoch 629/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3639 - accuracy: 0.8777\n",
      "Epoch 630/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3488 - accuracy: 0.8861\n",
      "Epoch 631/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3337 - accuracy: 0.8804\n",
      "Epoch 632/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3500 - accuracy: 0.8820\n",
      "Epoch 633/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3439 - accuracy: 0.8799\n",
      "Epoch 634/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3408 - accuracy: 0.8855\n",
      "Epoch 635/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3257 - accuracy: 0.8954\n",
      "Epoch 636/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3632 - accuracy: 0.8754\n",
      "Epoch 637/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3390 - accuracy: 0.8865\n",
      "Epoch 638/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3426 - accuracy: 0.8815\n",
      "Epoch 639/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3382 - accuracy: 0.8833\n",
      "Epoch 640/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3628 - accuracy: 0.8789\n",
      "Epoch 641/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3289 - accuracy: 0.8864\n",
      "Epoch 642/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3340 - accuracy: 0.8839\n",
      "Epoch 643/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3512 - accuracy: 0.8812\n",
      "Epoch 644/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3413 - accuracy: 0.8837\n",
      "Epoch 645/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3458 - accuracy: 0.8817\n",
      "Epoch 646/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3485 - accuracy: 0.8823\n",
      "Epoch 647/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3414 - accuracy: 0.8826\n",
      "Epoch 648/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3329 - accuracy: 0.8876\n",
      "Epoch 649/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3497 - accuracy: 0.8709\n",
      "Epoch 650/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3537 - accuracy: 0.8831\n",
      "Epoch 651/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3570 - accuracy: 0.8801\n",
      "Epoch 652/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3384 - accuracy: 0.8840\n",
      "Epoch 653/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3537 - accuracy: 0.8874\n",
      "Epoch 654/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3094 - accuracy: 0.8938\n",
      "Epoch 655/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3516 - accuracy: 0.8821\n",
      "Epoch 656/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3404 - accuracy: 0.8852\n",
      "Epoch 657/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3333 - accuracy: 0.8862\n",
      "Epoch 658/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3400 - accuracy: 0.8875\n",
      "Epoch 659/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3169 - accuracy: 0.8928\n",
      "Epoch 660/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3328 - accuracy: 0.8833\n",
      "Epoch 661/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3542 - accuracy: 0.8778\n",
      "Epoch 662/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3262 - accuracy: 0.8858\n",
      "Epoch 663/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3329 - accuracy: 0.8880\n",
      "Epoch 664/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3579 - accuracy: 0.8799\n",
      "Epoch 665/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3225 - accuracy: 0.8950\n",
      "Epoch 666/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3445 - accuracy: 0.8806\n",
      "Epoch 667/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3053 - accuracy: 0.8998\n",
      "Epoch 668/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3269 - accuracy: 0.8874\n",
      "Epoch 669/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3187 - accuracy: 0.8938\n",
      "Epoch 670/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3395 - accuracy: 0.8878\n",
      "Epoch 671/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3037 - accuracy: 0.8985\n",
      "Epoch 672/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3434 - accuracy: 0.8854\n",
      "Epoch 673/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3182 - accuracy: 0.8937\n",
      "Epoch 674/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3116 - accuracy: 0.8939\n",
      "Epoch 675/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3240 - accuracy: 0.8875\n",
      "Epoch 676/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3406 - accuracy: 0.8869\n",
      "Epoch 677/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3323 - accuracy: 0.8876\n",
      "Epoch 678/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3377 - accuracy: 0.8862\n",
      "Epoch 679/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3558 - accuracy: 0.8750\n",
      "Epoch 680/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3174 - accuracy: 0.8913\n",
      "Epoch 681/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3484 - accuracy: 0.8866\n",
      "Epoch 682/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3333 - accuracy: 0.8837\n",
      "Epoch 683/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3521 - accuracy: 0.8703\n",
      "Epoch 684/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3395 - accuracy: 0.8824\n",
      "Epoch 685/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3468 - accuracy: 0.8781\n",
      "Epoch 686/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3364 - accuracy: 0.8841\n",
      "Epoch 687/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3240 - accuracy: 0.8940\n",
      "Epoch 688/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3512 - accuracy: 0.8827\n",
      "Epoch 689/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3228 - accuracy: 0.8871\n",
      "Epoch 690/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3636 - accuracy: 0.8753\n",
      "Epoch 691/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3473 - accuracy: 0.8817\n",
      "Epoch 692/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3198 - accuracy: 0.8925\n",
      "Epoch 693/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3242 - accuracy: 0.8878\n",
      "Epoch 694/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3369 - accuracy: 0.8858\n",
      "Epoch 695/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3481 - accuracy: 0.8808\n",
      "Epoch 696/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3254 - accuracy: 0.8837\n",
      "Epoch 697/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3426 - accuracy: 0.8840\n",
      "Epoch 698/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3309 - accuracy: 0.8843\n",
      "Epoch 699/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3395 - accuracy: 0.8849\n",
      "Epoch 700/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3244 - accuracy: 0.8941\n",
      "Epoch 701/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3108 - accuracy: 0.8931\n",
      "Epoch 702/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3174 - accuracy: 0.8891\n",
      "Epoch 703/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3308 - accuracy: 0.8917\n",
      "Epoch 704/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3162 - accuracy: 0.8884\n",
      "Epoch 705/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3094 - accuracy: 0.8972\n",
      "Epoch 706/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3708 - accuracy: 0.8784\n",
      "Epoch 707/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3313 - accuracy: 0.8843\n",
      "Epoch 708/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3064 - accuracy: 0.8951\n",
      "Epoch 709/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3582 - accuracy: 0.8768\n",
      "Epoch 710/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3271 - accuracy: 0.8867\n",
      "Epoch 711/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3078 - accuracy: 0.8919\n",
      "Epoch 712/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3330 - accuracy: 0.8873\n",
      "Epoch 713/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3099 - accuracy: 0.8921\n",
      "Epoch 714/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3068 - accuracy: 0.9007\n",
      "Epoch 715/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3456 - accuracy: 0.8833\n",
      "Epoch 716/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3224 - accuracy: 0.8846\n",
      "Epoch 717/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3180 - accuracy: 0.8887\n",
      "Epoch 718/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3413 - accuracy: 0.8819\n",
      "Epoch 719/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3347 - accuracy: 0.8923\n",
      "Epoch 720/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3466 - accuracy: 0.8855\n",
      "Epoch 721/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3489 - accuracy: 0.8761\n",
      "Epoch 722/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3366 - accuracy: 0.8876\n",
      "Epoch 723/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3471 - accuracy: 0.8837\n",
      "Epoch 724/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3018 - accuracy: 0.8919\n",
      "Epoch 725/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3550 - accuracy: 0.8786\n",
      "Epoch 726/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3496 - accuracy: 0.8810\n",
      "Epoch 727/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3387 - accuracy: 0.8843\n",
      "Epoch 728/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3239 - accuracy: 0.8910\n",
      "Epoch 729/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3507 - accuracy: 0.8803\n",
      "Epoch 730/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3266 - accuracy: 0.8868\n",
      "Epoch 731/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3323 - accuracy: 0.8880\n",
      "Epoch 732/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3222 - accuracy: 0.8930\n",
      "Epoch 733/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3126 - accuracy: 0.8922\n",
      "Epoch 734/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3384 - accuracy: 0.8836\n",
      "Epoch 735/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3335 - accuracy: 0.8860\n",
      "Epoch 736/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3291 - accuracy: 0.8888\n",
      "Epoch 737/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3537 - accuracy: 0.8813\n",
      "Epoch 738/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3394 - accuracy: 0.8825\n",
      "Epoch 739/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3281 - accuracy: 0.8882\n",
      "Epoch 740/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3347 - accuracy: 0.8909\n",
      "Epoch 741/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3222 - accuracy: 0.8849\n",
      "Epoch 742/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3054 - accuracy: 0.8930\n",
      "Epoch 743/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3268 - accuracy: 0.8893\n",
      "Epoch 744/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3296 - accuracy: 0.8874\n",
      "Epoch 745/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3315 - accuracy: 0.8862\n",
      "Epoch 746/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3259 - accuracy: 0.8869\n",
      "Epoch 747/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3239 - accuracy: 0.8856\n",
      "Epoch 748/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3405 - accuracy: 0.8971\n",
      "Epoch 749/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3160 - accuracy: 0.8910\n",
      "Epoch 750/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3530 - accuracy: 0.8853\n",
      "Epoch 751/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3218 - accuracy: 0.8878\n",
      "Epoch 752/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3400 - accuracy: 0.8895\n",
      "Epoch 753/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3411 - accuracy: 0.8850\n",
      "Epoch 754/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3143 - accuracy: 0.8921\n",
      "Epoch 755/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3172 - accuracy: 0.8920\n",
      "Epoch 756/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3348 - accuracy: 0.8845\n",
      "Epoch 757/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3220 - accuracy: 0.8865\n",
      "Epoch 758/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3062 - accuracy: 0.8921\n",
      "Epoch 759/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3258 - accuracy: 0.8846\n",
      "Epoch 760/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3249 - accuracy: 0.8895\n",
      "Epoch 761/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3460 - accuracy: 0.8766\n",
      "Epoch 762/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3176 - accuracy: 0.8912\n",
      "Epoch 763/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3305 - accuracy: 0.8837\n",
      "Epoch 764/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3209 - accuracy: 0.8870\n",
      "Epoch 765/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2923 - accuracy: 0.8957\n",
      "Epoch 766/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3364 - accuracy: 0.8837\n",
      "Epoch 767/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3258 - accuracy: 0.8864\n",
      "Epoch 768/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2878 - accuracy: 0.8973\n",
      "Epoch 769/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3138 - accuracy: 0.8857\n",
      "Epoch 770/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3446 - accuracy: 0.8828\n",
      "Epoch 771/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3359 - accuracy: 0.8845\n",
      "Epoch 772/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2990 - accuracy: 0.9010\n",
      "Epoch 773/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3180 - accuracy: 0.8943\n",
      "Epoch 774/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3256 - accuracy: 0.8853\n",
      "Epoch 775/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3472 - accuracy: 0.8764\n",
      "Epoch 776/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3235 - accuracy: 0.8881\n",
      "Epoch 777/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3462 - accuracy: 0.8817\n",
      "Epoch 778/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3137 - accuracy: 0.8967\n",
      "Epoch 779/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3246 - accuracy: 0.8903\n",
      "Epoch 780/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3180 - accuracy: 0.8912\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3309 - accuracy: 0.8845\n",
      "Epoch 782/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3394 - accuracy: 0.8889\n",
      "Epoch 783/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3304 - accuracy: 0.8884\n",
      "Epoch 784/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3482 - accuracy: 0.8758\n",
      "Epoch 785/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2925 - accuracy: 0.9045\n",
      "Epoch 786/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3204 - accuracy: 0.8876\n",
      "Epoch 787/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3112 - accuracy: 0.8986\n",
      "Epoch 788/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3362 - accuracy: 0.8828\n",
      "Epoch 789/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3469 - accuracy: 0.8804\n",
      "Epoch 790/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3301 - accuracy: 0.8898\n",
      "Epoch 791/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3472 - accuracy: 0.8839\n",
      "Epoch 792/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3314 - accuracy: 0.8864\n",
      "Epoch 793/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3132 - accuracy: 0.8911\n",
      "Epoch 794/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3281 - accuracy: 0.8880\n",
      "Epoch 795/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3223 - accuracy: 0.8834\n",
      "Epoch 796/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3013 - accuracy: 0.8933\n",
      "Epoch 797/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3239 - accuracy: 0.8919\n",
      "Epoch 798/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3226 - accuracy: 0.8908\n",
      "Epoch 799/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2998 - accuracy: 0.8984\n",
      "Epoch 800/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2874 - accuracy: 0.9029\n",
      "Epoch 801/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3448 - accuracy: 0.8848\n",
      "Epoch 802/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3395 - accuracy: 0.8780\n",
      "Epoch 803/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3145 - accuracy: 0.8895\n",
      "Epoch 804/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3279 - accuracy: 0.8814\n",
      "Epoch 805/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3325 - accuracy: 0.8817\n",
      "Epoch 806/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3213 - accuracy: 0.8903\n",
      "Epoch 807/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3100 - accuracy: 0.8921\n",
      "Epoch 808/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3342 - accuracy: 0.8853\n",
      "Epoch 809/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3253 - accuracy: 0.8855\n",
      "Epoch 810/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3134 - accuracy: 0.8905\n",
      "Epoch 811/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3308 - accuracy: 0.8841\n",
      "Epoch 812/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3324 - accuracy: 0.8877\n",
      "Epoch 813/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3270 - accuracy: 0.8866\n",
      "Epoch 814/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3274 - accuracy: 0.8878\n",
      "Epoch 815/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3076 - accuracy: 0.8917\n",
      "Epoch 816/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3183 - accuracy: 0.8922\n",
      "Epoch 817/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3368 - accuracy: 0.8872\n",
      "Epoch 818/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3144 - accuracy: 0.8942\n",
      "Epoch 819/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3165 - accuracy: 0.8909\n",
      "Epoch 820/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3247 - accuracy: 0.8898\n",
      "Epoch 821/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3547 - accuracy: 0.8826\n",
      "Epoch 822/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3174 - accuracy: 0.8935\n",
      "Epoch 823/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3351 - accuracy: 0.8893\n",
      "Epoch 824/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3010 - accuracy: 0.8980\n",
      "Epoch 825/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3450 - accuracy: 0.8839\n",
      "Epoch 826/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3242 - accuracy: 0.8913\n",
      "Epoch 827/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3190 - accuracy: 0.8848\n",
      "Epoch 828/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3182 - accuracy: 0.8892\n",
      "Epoch 829/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3287 - accuracy: 0.8850\n",
      "Epoch 830/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3327 - accuracy: 0.8856\n",
      "Epoch 831/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3294 - accuracy: 0.8909\n",
      "Epoch 832/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3345 - accuracy: 0.8894\n",
      "Epoch 833/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3250 - accuracy: 0.8820\n",
      "Epoch 834/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3322 - accuracy: 0.8837\n",
      "Epoch 835/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3151 - accuracy: 0.8909\n",
      "Epoch 836/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3280 - accuracy: 0.8906\n",
      "Epoch 837/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3002 - accuracy: 0.8998\n",
      "Epoch 838/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3023 - accuracy: 0.8908\n",
      "Epoch 839/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3126 - accuracy: 0.8914\n",
      "Epoch 840/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3134 - accuracy: 0.8927\n",
      "Epoch 841/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3391 - accuracy: 0.8831\n",
      "Epoch 842/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3069 - accuracy: 0.8955\n",
      "Epoch 843/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3271 - accuracy: 0.8842\n",
      "Epoch 844/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3267 - accuracy: 0.8888\n",
      "Epoch 845/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3267 - accuracy: 0.8885\n",
      "Epoch 846/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3097 - accuracy: 0.8933\n",
      "Epoch 847/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3222 - accuracy: 0.8913\n",
      "Epoch 848/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3066 - accuracy: 0.8987\n",
      "Epoch 849/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3300 - accuracy: 0.8892\n",
      "Epoch 850/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3221 - accuracy: 0.8890\n",
      "Epoch 851/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3319 - accuracy: 0.8852\n",
      "Epoch 852/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3127 - accuracy: 0.8915\n",
      "Epoch 853/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3215 - accuracy: 0.8880\n",
      "Epoch 854/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3267 - accuracy: 0.8873\n",
      "Epoch 855/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3522 - accuracy: 0.8752\n",
      "Epoch 856/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2985 - accuracy: 0.9018\n",
      "Epoch 857/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3024 - accuracy: 0.8988\n",
      "Epoch 858/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3209 - accuracy: 0.8891\n",
      "Epoch 859/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3321 - accuracy: 0.8824\n",
      "Epoch 860/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3149 - accuracy: 0.8909\n",
      "Epoch 861/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3218 - accuracy: 0.8816\n",
      "Epoch 862/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3084 - accuracy: 0.8906\n",
      "Epoch 863/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3180 - accuracy: 0.8904\n",
      "Epoch 864/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3219 - accuracy: 0.8908\n",
      "Epoch 865/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3457 - accuracy: 0.8837\n",
      "Epoch 866/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3221 - accuracy: 0.8875\n",
      "Epoch 867/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3106 - accuracy: 0.8931\n",
      "Epoch 868/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3066 - accuracy: 0.8918\n",
      "Epoch 869/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3217 - accuracy: 0.8858\n",
      "Epoch 870/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3180 - accuracy: 0.8900\n",
      "Epoch 871/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3102 - accuracy: 0.8918\n",
      "Epoch 872/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3185 - accuracy: 0.8836\n",
      "Epoch 873/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3312 - accuracy: 0.8888\n",
      "Epoch 874/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3011 - accuracy: 0.8917\n",
      "Epoch 875/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3398 - accuracy: 0.8861\n",
      "Epoch 876/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3189 - accuracy: 0.8875\n",
      "Epoch 877/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3224 - accuracy: 0.8885\n",
      "Epoch 878/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3119 - accuracy: 0.8970\n",
      "Epoch 879/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3404 - accuracy: 0.8895\n",
      "Epoch 880/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3304 - accuracy: 0.8827\n",
      "Epoch 881/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2934 - accuracy: 0.9004\n",
      "Epoch 882/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3286 - accuracy: 0.8842\n",
      "Epoch 883/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3224 - accuracy: 0.8851\n",
      "Epoch 884/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3147 - accuracy: 0.8894\n",
      "Epoch 885/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3194 - accuracy: 0.8803\n",
      "Epoch 886/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3386 - accuracy: 0.8854\n",
      "Epoch 887/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2988 - accuracy: 0.8956\n",
      "Epoch 888/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3193 - accuracy: 0.8915\n",
      "Epoch 889/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3571 - accuracy: 0.8842\n",
      "Epoch 890/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3055 - accuracy: 0.8914\n",
      "Epoch 891/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3104 - accuracy: 0.8874\n",
      "Epoch 892/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3198 - accuracy: 0.8916\n",
      "Epoch 893/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3752 - accuracy: 0.8769\n",
      "Epoch 894/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2905 - accuracy: 0.8992\n",
      "Epoch 895/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3330 - accuracy: 0.8849\n",
      "Epoch 896/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3130 - accuracy: 0.8924\n",
      "Epoch 897/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3266 - accuracy: 0.8918\n",
      "Epoch 898/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3330 - accuracy: 0.8840\n",
      "Epoch 899/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3154 - accuracy: 0.8929\n",
      "Epoch 900/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3164 - accuracy: 0.8881\n",
      "Epoch 901/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3486 - accuracy: 0.8761\n",
      "Epoch 902/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3312 - accuracy: 0.8827\n",
      "Epoch 903/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3436 - accuracy: 0.8803\n",
      "Epoch 904/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3306 - accuracy: 0.8884\n",
      "Epoch 905/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3452 - accuracy: 0.8793\n",
      "Epoch 906/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3367 - accuracy: 0.8848\n",
      "Epoch 907/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2991 - accuracy: 0.8905\n",
      "Epoch 908/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3222 - accuracy: 0.8865\n",
      "Epoch 909/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3399 - accuracy: 0.8868\n",
      "Epoch 910/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2794 - accuracy: 0.8993\n",
      "Epoch 911/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3147 - accuracy: 0.8852\n",
      "Epoch 912/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3327 - accuracy: 0.8844\n",
      "Epoch 913/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3045 - accuracy: 0.8967\n",
      "Epoch 914/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3337 - accuracy: 0.8920\n",
      "Epoch 915/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3052 - accuracy: 0.8916\n",
      "Epoch 916/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3145 - accuracy: 0.8876\n",
      "Epoch 917/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3055 - accuracy: 0.8913\n",
      "Epoch 918/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3251 - accuracy: 0.8845\n",
      "Epoch 919/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3266 - accuracy: 0.8856\n",
      "Epoch 920/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3220 - accuracy: 0.8875\n",
      "Epoch 921/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3364 - accuracy: 0.8842\n",
      "Epoch 922/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2938 - accuracy: 0.9020\n",
      "Epoch 923/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3176 - accuracy: 0.8909\n",
      "Epoch 924/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3096 - accuracy: 0.8903\n",
      "Epoch 925/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3247 - accuracy: 0.8860\n",
      "Epoch 926/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3197 - accuracy: 0.8908\n",
      "Epoch 927/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3480 - accuracy: 0.8766\n",
      "Epoch 928/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3382 - accuracy: 0.8842\n",
      "Epoch 929/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3194 - accuracy: 0.8817\n",
      "Epoch 930/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3076 - accuracy: 0.8878\n",
      "Epoch 931/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3169 - accuracy: 0.8927\n",
      "Epoch 932/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3096 - accuracy: 0.8889\n",
      "Epoch 933/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3096 - accuracy: 0.8942\n",
      "Epoch 934/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3270 - accuracy: 0.8890\n",
      "Epoch 935/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3127 - accuracy: 0.8930\n",
      "Epoch 936/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3351 - accuracy: 0.8861\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3051 - accuracy: 0.8916\n",
      "Epoch 938/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2979 - accuracy: 0.8972\n",
      "Epoch 939/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3106 - accuracy: 0.8942\n",
      "Epoch 940/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3064 - accuracy: 0.8923\n",
      "Epoch 941/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3084 - accuracy: 0.8943\n",
      "Epoch 942/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3140 - accuracy: 0.8922\n",
      "Epoch 943/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3064 - accuracy: 0.8941\n",
      "Epoch 944/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3260 - accuracy: 0.8824\n",
      "Epoch 945/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3200 - accuracy: 0.8906\n",
      "Epoch 946/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3404 - accuracy: 0.8817\n",
      "Epoch 947/1000\n",
      "145/145 [==============================] - 2s 13ms/step - loss: 0.3346 - accuracy: 0.8881\n",
      "Epoch 948/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3251 - accuracy: 0.8887\n",
      "Epoch 949/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3310 - accuracy: 0.8840\n",
      "Epoch 950/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3464 - accuracy: 0.8766\n",
      "Epoch 951/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3006 - accuracy: 0.8970\n",
      "Epoch 952/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2961 - accuracy: 0.8927\n",
      "Epoch 953/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3244 - accuracy: 0.8831\n",
      "Epoch 954/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3120 - accuracy: 0.8867\n",
      "Epoch 955/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3066 - accuracy: 0.8886\n",
      "Epoch 956/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3334 - accuracy: 0.8894\n",
      "Epoch 957/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3099 - accuracy: 0.8902\n",
      "Epoch 958/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2943 - accuracy: 0.8996\n",
      "Epoch 959/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3091 - accuracy: 0.8848\n",
      "Epoch 960/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3044 - accuracy: 0.8961\n",
      "Epoch 961/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3188 - accuracy: 0.8884\n",
      "Epoch 962/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3185 - accuracy: 0.8906\n",
      "Epoch 963/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3110 - accuracy: 0.8895\n",
      "Epoch 964/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2871 - accuracy: 0.9039\n",
      "Epoch 965/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3230 - accuracy: 0.8894\n",
      "Epoch 966/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3191 - accuracy: 0.8901\n",
      "Epoch 967/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2945 - accuracy: 0.8980\n",
      "Epoch 968/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3115 - accuracy: 0.8931\n",
      "Epoch 969/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3199 - accuracy: 0.8851\n",
      "Epoch 970/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3064 - accuracy: 0.8924\n",
      "Epoch 971/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3066 - accuracy: 0.8929\n",
      "Epoch 972/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3140 - accuracy: 0.8899\n",
      "Epoch 973/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3136 - accuracy: 0.8890\n",
      "Epoch 974/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3040 - accuracy: 0.8899\n",
      "Epoch 975/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3344 - accuracy: 0.8904\n",
      "Epoch 976/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3220 - accuracy: 0.8829\n",
      "Epoch 977/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2997 - accuracy: 0.8967\n",
      "Epoch 978/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3155 - accuracy: 0.8878\n",
      "Epoch 979/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3094 - accuracy: 0.8914\n",
      "Epoch 980/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2981 - accuracy: 0.8947\n",
      "Epoch 981/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3084 - accuracy: 0.8889\n",
      "Epoch 982/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3329 - accuracy: 0.8826\n",
      "Epoch 983/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3287 - accuracy: 0.8878\n",
      "Epoch 984/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3188 - accuracy: 0.8834\n",
      "Epoch 985/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3171 - accuracy: 0.8819\n",
      "Epoch 986/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3115 - accuracy: 0.8920\n",
      "Epoch 987/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2969 - accuracy: 0.8990\n",
      "Epoch 988/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3101 - accuracy: 0.8851\n",
      "Epoch 989/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3039 - accuracy: 0.8899\n",
      "Epoch 990/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3107 - accuracy: 0.8874\n",
      "Epoch 991/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3215 - accuracy: 0.8866\n",
      "Epoch 992/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3307 - accuracy: 0.8811\n",
      "Epoch 993/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3255 - accuracy: 0.8855\n",
      "Epoch 994/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2789 - accuracy: 0.9025\n",
      "Epoch 995/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3084 - accuracy: 0.8882\n",
      "Epoch 996/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.2836 - accuracy: 0.8979\n",
      "Epoch 997/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3091 - accuracy: 0.8979\n",
      "Epoch 998/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3169 - accuracy: 0.8867\n",
      "Epoch 999/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3224 - accuracy: 0.8838\n",
      "Epoch 1000/1000\n",
      "145/145 [==============================] - 2s 14ms/step - loss: 0.3023 - accuracy: 0.8893\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 23, 128)           259456    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 23, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2027)              520939    \n",
      "=================================================================\n",
      "Total params: 1,043,563\n",
      "Trainable params: 1,043,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_bilstm_more_epochs_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 128, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(128,return_sequences=False, kernel_initializer='random_uniform')),\n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "single_bilstm_more_epochs_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "single_bilstm_more_epochs_model.fit(xs,ys,epochs=1000,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "single_bilstm_more_epochs_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-knife",
   "metadata": {},
   "source": [
    "#### Single Bidirectional LSTM layer model 1000 epochs 256 units 0.001 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "funky-grain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "145/145 [==============================] - 6s 26ms/step - loss: 7.0154 - accuracy: 0.0310\n",
      "Epoch 2/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 6.4395 - accuracy: 0.0393\n",
      "Epoch 3/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 6.3182 - accuracy: 0.0452\n",
      "Epoch 4/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 6.2250 - accuracy: 0.0456\n",
      "Epoch 5/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 6.0950 - accuracy: 0.0611\n",
      "Epoch 6/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 5.9496 - accuracy: 0.0599\n",
      "Epoch 7/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 5.7892 - accuracy: 0.0563\n",
      "Epoch 8/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 5.5901 - accuracy: 0.0658\n",
      "Epoch 9/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 5.4750 - accuracy: 0.0676\n",
      "Epoch 10/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 5.2478 - accuracy: 0.0842\n",
      "Epoch 11/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 5.0191 - accuracy: 0.0864\n",
      "Epoch 12/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 4.8311 - accuracy: 0.1090\n",
      "Epoch 13/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 4.5757 - accuracy: 0.1305\n",
      "Epoch 14/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 4.3368 - accuracy: 0.1407\n",
      "Epoch 15/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 4.1893 - accuracy: 0.1648\n",
      "Epoch 16/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 3.8481 - accuracy: 0.2013\n",
      "Epoch 17/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 3.6968 - accuracy: 0.2298\n",
      "Epoch 18/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 3.4297 - accuracy: 0.2695\n",
      "Epoch 19/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 3.2223 - accuracy: 0.2976\n",
      "Epoch 20/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 3.0844 - accuracy: 0.3274\n",
      "Epoch 21/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 2.8437 - accuracy: 0.3610\n",
      "Epoch 22/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 2.6600 - accuracy: 0.4089\n",
      "Epoch 23/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 2.5541 - accuracy: 0.4259\n",
      "Epoch 24/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 2.3788 - accuracy: 0.4603\n",
      "Epoch 25/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 2.3165 - accuracy: 0.4688\n",
      "Epoch 26/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 2.0967 - accuracy: 0.5083\n",
      "Epoch 27/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 2.0276 - accuracy: 0.5183\n",
      "Epoch 28/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.9277 - accuracy: 0.5465\n",
      "Epoch 29/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.8331 - accuracy: 0.5701\n",
      "Epoch 30/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.7927 - accuracy: 0.5601\n",
      "Epoch 31/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.6820 - accuracy: 0.6012\n",
      "Epoch 32/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.6196 - accuracy: 0.6057\n",
      "Epoch 33/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.5234 - accuracy: 0.6327\n",
      "Epoch 34/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.5016 - accuracy: 0.6378\n",
      "Epoch 35/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.4290 - accuracy: 0.6548\n",
      "Epoch 36/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.3140 - accuracy: 0.6755\n",
      "Epoch 37/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.3352 - accuracy: 0.6787\n",
      "Epoch 38/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.2884 - accuracy: 0.6821\n",
      "Epoch 39/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.2475 - accuracy: 0.6812\n",
      "Epoch 40/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.1585 - accuracy: 0.7115\n",
      "Epoch 41/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.1478 - accuracy: 0.7072\n",
      "Epoch 42/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.0833 - accuracy: 0.7272\n",
      "Epoch 43/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.0252 - accuracy: 0.7497\n",
      "Epoch 44/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.0327 - accuracy: 0.7404\n",
      "Epoch 45/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.0357 - accuracy: 0.7399\n",
      "Epoch 46/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 1.0256 - accuracy: 0.7448\n",
      "Epoch 47/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.9416 - accuracy: 0.7527\n",
      "Epoch 48/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.9097 - accuracy: 0.7734\n",
      "Epoch 49/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.8945 - accuracy: 0.7620\n",
      "Epoch 50/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.8546 - accuracy: 0.7836\n",
      "Epoch 51/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.8488 - accuracy: 0.7808\n",
      "Epoch 52/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.8483 - accuracy: 0.7749\n",
      "Epoch 53/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.8254 - accuracy: 0.7796\n",
      "Epoch 54/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.8246 - accuracy: 0.7872\n",
      "Epoch 55/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.7798 - accuracy: 0.7981\n",
      "Epoch 56/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.7601 - accuracy: 0.7908\n",
      "Epoch 57/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.7512 - accuracy: 0.7955\n",
      "Epoch 58/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.7024 - accuracy: 0.8159\n",
      "Epoch 59/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.7261 - accuracy: 0.8052\n",
      "Epoch 60/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.7063 - accuracy: 0.8112\n",
      "Epoch 61/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.7138 - accuracy: 0.8084\n",
      "Epoch 62/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6803 - accuracy: 0.8130\n",
      "Epoch 63/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6871 - accuracy: 0.8081\n",
      "Epoch 64/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6595 - accuracy: 0.8200\n",
      "Epoch 65/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6345 - accuracy: 0.8271\n",
      "Epoch 66/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6686 - accuracy: 0.8184\n",
      "Epoch 67/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6593 - accuracy: 0.8210\n",
      "Epoch 68/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6403 - accuracy: 0.8255\n",
      "Epoch 69/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6077 - accuracy: 0.8341\n",
      "Epoch 70/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6186 - accuracy: 0.8293\n",
      "Epoch 71/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.6026 - accuracy: 0.8384\n",
      "Epoch 72/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5896 - accuracy: 0.8324\n",
      "Epoch 73/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5974 - accuracy: 0.8329\n",
      "Epoch 74/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5769 - accuracy: 0.8403\n",
      "Epoch 75/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5488 - accuracy: 0.8436\n",
      "Epoch 76/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5590 - accuracy: 0.8475\n",
      "Epoch 77/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5773 - accuracy: 0.8353\n",
      "Epoch 78/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5582 - accuracy: 0.8469\n",
      "Epoch 79/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5391 - accuracy: 0.8492\n",
      "Epoch 80/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5378 - accuracy: 0.8560\n",
      "Epoch 81/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5490 - accuracy: 0.8491\n",
      "Epoch 82/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5237 - accuracy: 0.8496\n",
      "Epoch 83/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5438 - accuracy: 0.8425\n",
      "Epoch 84/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5178 - accuracy: 0.8526\n",
      "Epoch 85/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5321 - accuracy: 0.8418\n",
      "Epoch 86/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4826 - accuracy: 0.8683\n",
      "Epoch 87/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5094 - accuracy: 0.8521\n",
      "Epoch 88/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4959 - accuracy: 0.8655\n",
      "Epoch 89/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5014 - accuracy: 0.8486\n",
      "Epoch 90/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.5003 - accuracy: 0.8552\n",
      "Epoch 91/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4972 - accuracy: 0.8547\n",
      "Epoch 92/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4700 - accuracy: 0.8695\n",
      "Epoch 93/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4693 - accuracy: 0.8680\n",
      "Epoch 94/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4736 - accuracy: 0.8587\n",
      "Epoch 95/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4709 - accuracy: 0.8700\n",
      "Epoch 96/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4777 - accuracy: 0.8657\n",
      "Epoch 97/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4541 - accuracy: 0.8688\n",
      "Epoch 98/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4533 - accuracy: 0.8694\n",
      "Epoch 99/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4806 - accuracy: 0.8645\n",
      "Epoch 100/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4475 - accuracy: 0.8755\n",
      "Epoch 101/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4546 - accuracy: 0.8672\n",
      "Epoch 102/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4238 - accuracy: 0.8760\n",
      "Epoch 103/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4405 - accuracy: 0.8650\n",
      "Epoch 104/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4570 - accuracy: 0.8635\n",
      "Epoch 105/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4556 - accuracy: 0.8633\n",
      "Epoch 106/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4742 - accuracy: 0.8628\n",
      "Epoch 107/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4212 - accuracy: 0.8747\n",
      "Epoch 108/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4333 - accuracy: 0.8659\n",
      "Epoch 109/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4281 - accuracy: 0.8750\n",
      "Epoch 110/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4349 - accuracy: 0.8726\n",
      "Epoch 111/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4591 - accuracy: 0.8659\n",
      "Epoch 112/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4356 - accuracy: 0.8705\n",
      "Epoch 113/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3952 - accuracy: 0.8827\n",
      "Epoch 114/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4184 - accuracy: 0.8788\n",
      "Epoch 115/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3862 - accuracy: 0.8805\n",
      "Epoch 116/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4593 - accuracy: 0.8685\n",
      "Epoch 117/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4048 - accuracy: 0.8743\n",
      "Epoch 118/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4045 - accuracy: 0.8799\n",
      "Epoch 119/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4041 - accuracy: 0.8797\n",
      "Epoch 120/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4134 - accuracy: 0.8802\n",
      "Epoch 121/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4187 - accuracy: 0.8770\n",
      "Epoch 122/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3961 - accuracy: 0.8816\n",
      "Epoch 123/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3918 - accuracy: 0.8816\n",
      "Epoch 124/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4112 - accuracy: 0.8776\n",
      "Epoch 125/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3921 - accuracy: 0.8795\n",
      "Epoch 126/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4104 - accuracy: 0.8710\n",
      "Epoch 127/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4227 - accuracy: 0.8722\n",
      "Epoch 128/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3820 - accuracy: 0.8877\n",
      "Epoch 129/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3812 - accuracy: 0.8819\n",
      "Epoch 130/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3965 - accuracy: 0.8830\n",
      "Epoch 131/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3941 - accuracy: 0.8769\n",
      "Epoch 132/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3796 - accuracy: 0.8857\n",
      "Epoch 133/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4068 - accuracy: 0.8729\n",
      "Epoch 134/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4206 - accuracy: 0.8654\n",
      "Epoch 135/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.4015 - accuracy: 0.8728\n",
      "Epoch 136/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3800 - accuracy: 0.8876\n",
      "Epoch 137/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3651 - accuracy: 0.8912\n",
      "Epoch 138/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3690 - accuracy: 0.8865\n",
      "Epoch 139/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3918 - accuracy: 0.8831\n",
      "Epoch 140/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3656 - accuracy: 0.8918\n",
      "Epoch 141/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3738 - accuracy: 0.8866\n",
      "Epoch 142/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3796 - accuracy: 0.8889\n",
      "Epoch 143/1000\n",
      "145/145 [==============================] - 3s 17ms/step - loss: 0.3600 - accuracy: 0.8912\n",
      "Epoch 144/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3807 - accuracy: 0.8861\n",
      "Epoch 145/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3688 - accuracy: 0.8863\n",
      "Epoch 146/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3923 - accuracy: 0.8801\n",
      "Epoch 147/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3856 - accuracy: 0.8853\n",
      "Epoch 148/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3661 - accuracy: 0.8844\n",
      "Epoch 149/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3915 - accuracy: 0.8866\n",
      "Epoch 150/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3583 - accuracy: 0.8889\n",
      "Epoch 151/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3807 - accuracy: 0.8856\n",
      "Epoch 152/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3988 - accuracy: 0.8768\n",
      "Epoch 153/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3882 - accuracy: 0.8839\n",
      "Epoch 154/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3266 - accuracy: 0.8995\n",
      "Epoch 155/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3687 - accuracy: 0.8831\n",
      "Epoch 156/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3754 - accuracy: 0.8825\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3494 - accuracy: 0.8866\n",
      "Epoch 158/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3768 - accuracy: 0.8850\n",
      "Epoch 159/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3522 - accuracy: 0.8826\n",
      "Epoch 160/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3515 - accuracy: 0.8907\n",
      "Epoch 161/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3738 - accuracy: 0.8756\n",
      "Epoch 162/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3533 - accuracy: 0.8919\n",
      "Epoch 163/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3742 - accuracy: 0.8821\n",
      "Epoch 164/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3247 - accuracy: 0.8983\n",
      "Epoch 165/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3649 - accuracy: 0.8839\n",
      "Epoch 166/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3710 - accuracy: 0.8846\n",
      "Epoch 167/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3636 - accuracy: 0.8869\n",
      "Epoch 168/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3791 - accuracy: 0.8848\n",
      "Epoch 169/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3232 - accuracy: 0.9006\n",
      "Epoch 170/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3476 - accuracy: 0.8899\n",
      "Epoch 171/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3547 - accuracy: 0.8863\n",
      "Epoch 172/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3509 - accuracy: 0.8910\n",
      "Epoch 173/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3798 - accuracy: 0.8819\n",
      "Epoch 174/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3491 - accuracy: 0.8874\n",
      "Epoch 175/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3632 - accuracy: 0.8820\n",
      "Epoch 176/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3580 - accuracy: 0.8879\n",
      "Epoch 177/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3833 - accuracy: 0.8776\n",
      "Epoch 178/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3477 - accuracy: 0.8888\n",
      "Epoch 179/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3485 - accuracy: 0.8907\n",
      "Epoch 180/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3367 - accuracy: 0.8950\n",
      "Epoch 181/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3580 - accuracy: 0.8813\n",
      "Epoch 182/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3522 - accuracy: 0.8874\n",
      "Epoch 183/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3379 - accuracy: 0.8950\n",
      "Epoch 184/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3375 - accuracy: 0.8928\n",
      "Epoch 185/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3466 - accuracy: 0.8852\n",
      "Epoch 186/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3665 - accuracy: 0.8856\n",
      "Epoch 187/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3507 - accuracy: 0.8857\n",
      "Epoch 188/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3670 - accuracy: 0.8812\n",
      "Epoch 189/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3483 - accuracy: 0.8927\n",
      "Epoch 190/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3307 - accuracy: 0.8944\n",
      "Epoch 191/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3493 - accuracy: 0.8897\n",
      "Epoch 192/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3482 - accuracy: 0.8867\n",
      "Epoch 193/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3414 - accuracy: 0.8887\n",
      "Epoch 194/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3646 - accuracy: 0.8825\n",
      "Epoch 195/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3345 - accuracy: 0.8904\n",
      "Epoch 196/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3223 - accuracy: 0.8932\n",
      "Epoch 197/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3348 - accuracy: 0.8861\n",
      "Epoch 198/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3195 - accuracy: 0.9010\n",
      "Epoch 199/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3381 - accuracy: 0.8868\n",
      "Epoch 200/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3670 - accuracy: 0.8863\n",
      "Epoch 201/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3605 - accuracy: 0.8830\n",
      "Epoch 202/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3251 - accuracy: 0.8956\n",
      "Epoch 203/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3408 - accuracy: 0.8937\n",
      "Epoch 204/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3386 - accuracy: 0.8940\n",
      "Epoch 205/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3172 - accuracy: 0.8960\n",
      "Epoch 206/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3518 - accuracy: 0.8904\n",
      "Epoch 207/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3175 - accuracy: 0.8981\n",
      "Epoch 208/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3341 - accuracy: 0.8887\n",
      "Epoch 209/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3190 - accuracy: 0.8957\n",
      "Epoch 210/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2948 - accuracy: 0.9005\n",
      "Epoch 211/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3204 - accuracy: 0.9006\n",
      "Epoch 212/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3314 - accuracy: 0.8904\n",
      "Epoch 213/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3498 - accuracy: 0.8874\n",
      "Epoch 214/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3182 - accuracy: 0.8997\n",
      "Epoch 215/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3297 - accuracy: 0.8857\n",
      "Epoch 216/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3258 - accuracy: 0.8954\n",
      "Epoch 217/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3204 - accuracy: 0.8965\n",
      "Epoch 218/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2888 - accuracy: 0.9026\n",
      "Epoch 219/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3322 - accuracy: 0.8907\n",
      "Epoch 220/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2929 - accuracy: 0.8996\n",
      "Epoch 221/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3376 - accuracy: 0.8856\n",
      "Epoch 222/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3171 - accuracy: 0.8982\n",
      "Epoch 223/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3214 - accuracy: 0.8960\n",
      "Epoch 224/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3032 - accuracy: 0.8999\n",
      "Epoch 225/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3057 - accuracy: 0.8991\n",
      "Epoch 226/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3238 - accuracy: 0.8948\n",
      "Epoch 227/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3589 - accuracy: 0.8742\n",
      "Epoch 228/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3196 - accuracy: 0.8970\n",
      "Epoch 229/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3143 - accuracy: 0.8986\n",
      "Epoch 230/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3073 - accuracy: 0.8994\n",
      "Epoch 231/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3260 - accuracy: 0.8874\n",
      "Epoch 232/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3315 - accuracy: 0.8883\n",
      "Epoch 233/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3219 - accuracy: 0.8970\n",
      "Epoch 234/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3205 - accuracy: 0.8943\n",
      "Epoch 235/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3438 - accuracy: 0.8905\n",
      "Epoch 236/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2972 - accuracy: 0.8959\n",
      "Epoch 237/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3236 - accuracy: 0.8943\n",
      "Epoch 238/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3522 - accuracy: 0.8836\n",
      "Epoch 239/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3222 - accuracy: 0.8927\n",
      "Epoch 240/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3280 - accuracy: 0.8832\n",
      "Epoch 241/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3241 - accuracy: 0.8949\n",
      "Epoch 242/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3110 - accuracy: 0.8947\n",
      "Epoch 243/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3061 - accuracy: 0.9011\n",
      "Epoch 244/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2930 - accuracy: 0.9011\n",
      "Epoch 245/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3199 - accuracy: 0.8935\n",
      "Epoch 246/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3010 - accuracy: 0.8969\n",
      "Epoch 247/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3155 - accuracy: 0.8927\n",
      "Epoch 248/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3105 - accuracy: 0.8980\n",
      "Epoch 249/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3189 - accuracy: 0.8967\n",
      "Epoch 250/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3089 - accuracy: 0.8984\n",
      "Epoch 251/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2999 - accuracy: 0.8955\n",
      "Epoch 252/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3387 - accuracy: 0.8900\n",
      "Epoch 253/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3129 - accuracy: 0.8933\n",
      "Epoch 254/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3128 - accuracy: 0.9012\n",
      "Epoch 255/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3089 - accuracy: 0.8949\n",
      "Epoch 256/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3199 - accuracy: 0.8924\n",
      "Epoch 257/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3027 - accuracy: 0.8970\n",
      "Epoch 258/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2962 - accuracy: 0.8998\n",
      "Epoch 259/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3174 - accuracy: 0.9034\n",
      "Epoch 260/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3330 - accuracy: 0.8932\n",
      "Epoch 261/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3130 - accuracy: 0.8995\n",
      "Epoch 262/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3083 - accuracy: 0.8907\n",
      "Epoch 263/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3080 - accuracy: 0.8898\n",
      "Epoch 264/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3037 - accuracy: 0.8995\n",
      "Epoch 265/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3049 - accuracy: 0.8955\n",
      "Epoch 266/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2975 - accuracy: 0.8996\n",
      "Epoch 267/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3095 - accuracy: 0.8941\n",
      "Epoch 268/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3160 - accuracy: 0.8934\n",
      "Epoch 269/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2883 - accuracy: 0.8969\n",
      "Epoch 270/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3125 - accuracy: 0.8959\n",
      "Epoch 271/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3050 - accuracy: 0.9008\n",
      "Epoch 272/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2901 - accuracy: 0.8992\n",
      "Epoch 273/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3002 - accuracy: 0.8964\n",
      "Epoch 274/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3147 - accuracy: 0.8951\n",
      "Epoch 275/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3044 - accuracy: 0.8971\n",
      "Epoch 276/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2900 - accuracy: 0.9021\n",
      "Epoch 277/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3184 - accuracy: 0.8886\n",
      "Epoch 278/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3013 - accuracy: 0.8959\n",
      "Epoch 279/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3044 - accuracy: 0.9007\n",
      "Epoch 280/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3306 - accuracy: 0.8851\n",
      "Epoch 281/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3307 - accuracy: 0.8843\n",
      "Epoch 282/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3173 - accuracy: 0.8891\n",
      "Epoch 283/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2946 - accuracy: 0.9027\n",
      "Epoch 284/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2955 - accuracy: 0.8976\n",
      "Epoch 285/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3136 - accuracy: 0.8925\n",
      "Epoch 286/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3017 - accuracy: 0.8926\n",
      "Epoch 287/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3101 - accuracy: 0.8963\n",
      "Epoch 288/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3321 - accuracy: 0.8872\n",
      "Epoch 289/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3158 - accuracy: 0.8959\n",
      "Epoch 290/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3049 - accuracy: 0.8950\n",
      "Epoch 291/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3056 - accuracy: 0.8971\n",
      "Epoch 292/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3166 - accuracy: 0.8981\n",
      "Epoch 293/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3071 - accuracy: 0.8910\n",
      "Epoch 294/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3260 - accuracy: 0.8927\n",
      "Epoch 295/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2999 - accuracy: 0.9003\n",
      "Epoch 296/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2751 - accuracy: 0.9058\n",
      "Epoch 297/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2900 - accuracy: 0.9021\n",
      "Epoch 298/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2990 - accuracy: 0.8988\n",
      "Epoch 299/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3115 - accuracy: 0.8948\n",
      "Epoch 300/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2814 - accuracy: 0.9001\n",
      "Epoch 301/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2876 - accuracy: 0.8999\n",
      "Epoch 302/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3154 - accuracy: 0.8959\n",
      "Epoch 303/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3196 - accuracy: 0.8944\n",
      "Epoch 304/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3113 - accuracy: 0.8898\n",
      "Epoch 305/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3117 - accuracy: 0.9000\n",
      "Epoch 306/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3012 - accuracy: 0.8988\n",
      "Epoch 307/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3419 - accuracy: 0.8870\n",
      "Epoch 308/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2678 - accuracy: 0.9074\n",
      "Epoch 309/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3043 - accuracy: 0.8984\n",
      "Epoch 310/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3112 - accuracy: 0.8944\n",
      "Epoch 311/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3056 - accuracy: 0.8930\n",
      "Epoch 312/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3073 - accuracy: 0.8934\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2776 - accuracy: 0.9027\n",
      "Epoch 314/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2947 - accuracy: 0.8978\n",
      "Epoch 315/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3050 - accuracy: 0.8938\n",
      "Epoch 316/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3128 - accuracy: 0.8903\n",
      "Epoch 317/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2889 - accuracy: 0.8979\n",
      "Epoch 318/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2939 - accuracy: 0.8979\n",
      "Epoch 319/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3116 - accuracy: 0.8971\n",
      "Epoch 320/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3179 - accuracy: 0.8911\n",
      "Epoch 321/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2845 - accuracy: 0.9000\n",
      "Epoch 322/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2833 - accuracy: 0.9009\n",
      "Epoch 323/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3166 - accuracy: 0.8944\n",
      "Epoch 324/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3116 - accuracy: 0.8947\n",
      "Epoch 325/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2971 - accuracy: 0.9060\n",
      "Epoch 326/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3160 - accuracy: 0.8961\n",
      "Epoch 327/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3027 - accuracy: 0.8952\n",
      "Epoch 328/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2957 - accuracy: 0.8962\n",
      "Epoch 329/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2982 - accuracy: 0.9007\n",
      "Epoch 330/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2915 - accuracy: 0.9028\n",
      "Epoch 331/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3029 - accuracy: 0.8927\n",
      "Epoch 332/1000\n",
      "145/145 [==============================] - 3s 17ms/step - loss: 0.3158 - accuracy: 0.8885\n",
      "Epoch 333/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2772 - accuracy: 0.9042\n",
      "Epoch 334/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3159 - accuracy: 0.8924\n",
      "Epoch 335/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3033 - accuracy: 0.8973\n",
      "Epoch 336/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2753 - accuracy: 0.9053\n",
      "Epoch 337/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2799 - accuracy: 0.9015\n",
      "Epoch 338/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2898 - accuracy: 0.8978\n",
      "Epoch 339/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2588 - accuracy: 0.9112\n",
      "Epoch 340/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3014 - accuracy: 0.8954\n",
      "Epoch 341/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2842 - accuracy: 0.8996\n",
      "Epoch 342/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3124 - accuracy: 0.8957\n",
      "Epoch 343/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2987 - accuracy: 0.8950\n",
      "Epoch 344/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3009 - accuracy: 0.8945\n",
      "Epoch 345/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2836 - accuracy: 0.8982\n",
      "Epoch 346/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2922 - accuracy: 0.8989\n",
      "Epoch 347/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2992 - accuracy: 0.8968\n",
      "Epoch 348/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3065 - accuracy: 0.8948\n",
      "Epoch 349/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3080 - accuracy: 0.8912\n",
      "Epoch 350/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2836 - accuracy: 0.8936\n",
      "Epoch 351/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3052 - accuracy: 0.8914\n",
      "Epoch 352/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2741 - accuracy: 0.9038\n",
      "Epoch 353/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3031 - accuracy: 0.8921\n",
      "Epoch 354/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2880 - accuracy: 0.9022\n",
      "Epoch 355/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3056 - accuracy: 0.8955\n",
      "Epoch 356/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2844 - accuracy: 0.8993\n",
      "Epoch 357/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2934 - accuracy: 0.8992\n",
      "Epoch 358/1000\n",
      "145/145 [==============================] - 3s 17ms/step - loss: 0.2672 - accuracy: 0.9060\n",
      "Epoch 359/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2528 - accuracy: 0.9074\n",
      "Epoch 360/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2951 - accuracy: 0.8941\n",
      "Epoch 361/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2999 - accuracy: 0.9000\n",
      "Epoch 362/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3061 - accuracy: 0.8903\n",
      "Epoch 363/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3149 - accuracy: 0.8875\n",
      "Epoch 364/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3033 - accuracy: 0.8909\n",
      "Epoch 365/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2747 - accuracy: 0.9051\n",
      "Epoch 366/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2916 - accuracy: 0.9016\n",
      "Epoch 367/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3155 - accuracy: 0.8909\n",
      "Epoch 368/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2899 - accuracy: 0.9004\n",
      "Epoch 369/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2752 - accuracy: 0.8988\n",
      "Epoch 370/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2781 - accuracy: 0.8993\n",
      "Epoch 371/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2766 - accuracy: 0.9030\n",
      "Epoch 372/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2903 - accuracy: 0.8963\n",
      "Epoch 373/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3093 - accuracy: 0.8865\n",
      "Epoch 374/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2809 - accuracy: 0.8984\n",
      "Epoch 375/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2764 - accuracy: 0.8991\n",
      "Epoch 376/1000\n",
      "145/145 [==============================] - 3s 18ms/step - loss: 0.3023 - accuracy: 0.8913\n",
      "Epoch 377/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3090 - accuracy: 0.8844\n",
      "Epoch 378/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2908 - accuracy: 0.9008\n",
      "Epoch 379/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2669 - accuracy: 0.9069\n",
      "Epoch 380/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2949 - accuracy: 0.8979\n",
      "Epoch 381/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2971 - accuracy: 0.8954\n",
      "Epoch 382/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3031 - accuracy: 0.8933\n",
      "Epoch 383/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2799 - accuracy: 0.8997\n",
      "Epoch 384/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3114 - accuracy: 0.8924\n",
      "Epoch 385/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2914 - accuracy: 0.8946\n",
      "Epoch 386/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2856 - accuracy: 0.9004\n",
      "Epoch 387/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2882 - accuracy: 0.9007\n",
      "Epoch 388/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2866 - accuracy: 0.8983\n",
      "Epoch 389/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2913 - accuracy: 0.9013\n",
      "Epoch 390/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2793 - accuracy: 0.9035\n",
      "Epoch 391/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2841 - accuracy: 0.8999\n",
      "Epoch 392/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2955 - accuracy: 0.8910\n",
      "Epoch 393/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2789 - accuracy: 0.9010\n",
      "Epoch 394/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2943 - accuracy: 0.8946\n",
      "Epoch 395/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2837 - accuracy: 0.8979\n",
      "Epoch 396/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2825 - accuracy: 0.8968\n",
      "Epoch 397/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2642 - accuracy: 0.9035\n",
      "Epoch 398/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2936 - accuracy: 0.8962\n",
      "Epoch 399/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2946 - accuracy: 0.8953\n",
      "Epoch 400/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2816 - accuracy: 0.9004\n",
      "Epoch 401/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2781 - accuracy: 0.9036\n",
      "Epoch 402/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2834 - accuracy: 0.8974\n",
      "Epoch 403/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2951 - accuracy: 0.9006\n",
      "Epoch 404/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3050 - accuracy: 0.8918\n",
      "Epoch 405/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2670 - accuracy: 0.9034\n",
      "Epoch 406/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2919 - accuracy: 0.8999\n",
      "Epoch 407/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2623 - accuracy: 0.9107\n",
      "Epoch 408/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2912 - accuracy: 0.8933\n",
      "Epoch 409/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3118 - accuracy: 0.8892\n",
      "Epoch 410/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2915 - accuracy: 0.8945\n",
      "Epoch 411/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2667 - accuracy: 0.8978\n",
      "Epoch 412/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2748 - accuracy: 0.9020\n",
      "Epoch 413/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2653 - accuracy: 0.9057\n",
      "Epoch 414/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2937 - accuracy: 0.8950\n",
      "Epoch 415/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2748 - accuracy: 0.9009\n",
      "Epoch 416/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2831 - accuracy: 0.8983\n",
      "Epoch 417/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2683 - accuracy: 0.9017\n",
      "Epoch 418/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2715 - accuracy: 0.9015\n",
      "Epoch 419/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2925 - accuracy: 0.8923\n",
      "Epoch 420/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2668 - accuracy: 0.9011\n",
      "Epoch 421/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2866 - accuracy: 0.9017\n",
      "Epoch 422/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2782 - accuracy: 0.8994\n",
      "Epoch 423/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3027 - accuracy: 0.8898\n",
      "Epoch 424/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2804 - accuracy: 0.9025\n",
      "Epoch 425/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2798 - accuracy: 0.8997\n",
      "Epoch 426/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2862 - accuracy: 0.9008\n",
      "Epoch 427/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2678 - accuracy: 0.9062\n",
      "Epoch 428/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2864 - accuracy: 0.9008\n",
      "Epoch 429/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2788 - accuracy: 0.9014\n",
      "Epoch 430/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2786 - accuracy: 0.8995\n",
      "Epoch 431/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2968 - accuracy: 0.8903\n",
      "Epoch 432/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2915 - accuracy: 0.8936\n",
      "Epoch 433/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2809 - accuracy: 0.8967\n",
      "Epoch 434/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2838 - accuracy: 0.8973\n",
      "Epoch 435/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2725 - accuracy: 0.9024\n",
      "Epoch 436/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3029 - accuracy: 0.8915\n",
      "Epoch 437/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2724 - accuracy: 0.9019\n",
      "Epoch 438/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2970 - accuracy: 0.8958\n",
      "Epoch 439/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2878 - accuracy: 0.8977\n",
      "Epoch 440/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3066 - accuracy: 0.8945\n",
      "Epoch 441/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2648 - accuracy: 0.9050\n",
      "Epoch 442/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2625 - accuracy: 0.9076\n",
      "Epoch 443/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2925 - accuracy: 0.8970\n",
      "Epoch 444/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2886 - accuracy: 0.8997\n",
      "Epoch 445/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2840 - accuracy: 0.8956\n",
      "Epoch 446/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2831 - accuracy: 0.8956\n",
      "Epoch 447/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3006 - accuracy: 0.8940\n",
      "Epoch 448/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2898 - accuracy: 0.8949\n",
      "Epoch 449/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2805 - accuracy: 0.9030\n",
      "Epoch 450/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2807 - accuracy: 0.8993\n",
      "Epoch 451/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2947 - accuracy: 0.8939\n",
      "Epoch 452/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2896 - accuracy: 0.8962\n",
      "Epoch 453/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2770 - accuracy: 0.9029\n",
      "Epoch 454/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2820 - accuracy: 0.9017\n",
      "Epoch 455/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2904 - accuracy: 0.8933\n",
      "Epoch 456/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2909 - accuracy: 0.8901\n",
      "Epoch 457/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3000 - accuracy: 0.8911\n",
      "Epoch 458/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2712 - accuracy: 0.8998\n",
      "Epoch 459/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2788 - accuracy: 0.9004\n",
      "Epoch 460/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2855 - accuracy: 0.8937\n",
      "Epoch 461/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2791 - accuracy: 0.8979\n",
      "Epoch 462/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2834 - accuracy: 0.8980\n",
      "Epoch 463/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3020 - accuracy: 0.8910\n",
      "Epoch 464/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2965 - accuracy: 0.8897\n",
      "Epoch 465/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2680 - accuracy: 0.9014\n",
      "Epoch 466/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2831 - accuracy: 0.8975\n",
      "Epoch 467/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2746 - accuracy: 0.9002\n",
      "Epoch 468/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3001 - accuracy: 0.8944\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2551 - accuracy: 0.9070\n",
      "Epoch 470/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2688 - accuracy: 0.9033\n",
      "Epoch 471/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2653 - accuracy: 0.9061\n",
      "Epoch 472/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2899 - accuracy: 0.8998\n",
      "Epoch 473/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2914 - accuracy: 0.8970\n",
      "Epoch 474/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2690 - accuracy: 0.9023\n",
      "Epoch 475/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2714 - accuracy: 0.9071\n",
      "Epoch 476/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3044 - accuracy: 0.8921\n",
      "Epoch 477/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2792 - accuracy: 0.9019\n",
      "Epoch 478/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2944 - accuracy: 0.8893\n",
      "Epoch 479/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3001 - accuracy: 0.8916\n",
      "Epoch 480/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2828 - accuracy: 0.8975\n",
      "Epoch 481/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2633 - accuracy: 0.8993\n",
      "Epoch 482/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2954 - accuracy: 0.8997\n",
      "Epoch 483/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3090 - accuracy: 0.8864\n",
      "Epoch 484/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2923 - accuracy: 0.8958\n",
      "Epoch 485/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2967 - accuracy: 0.8932\n",
      "Epoch 486/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2704 - accuracy: 0.8989\n",
      "Epoch 487/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2802 - accuracy: 0.9047\n",
      "Epoch 488/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2702 - accuracy: 0.9022\n",
      "Epoch 489/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2826 - accuracy: 0.9003\n",
      "Epoch 490/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2921 - accuracy: 0.8910\n",
      "Epoch 491/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2857 - accuracy: 0.8965\n",
      "Epoch 492/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2900 - accuracy: 0.8937\n",
      "Epoch 493/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2894 - accuracy: 0.8925\n",
      "Epoch 494/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2717 - accuracy: 0.9042\n",
      "Epoch 495/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3106 - accuracy: 0.8858\n",
      "Epoch 496/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2789 - accuracy: 0.8994\n",
      "Epoch 497/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2851 - accuracy: 0.9009\n",
      "Epoch 498/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2869 - accuracy: 0.8953\n",
      "Epoch 499/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2577 - accuracy: 0.9046\n",
      "Epoch 500/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2732 - accuracy: 0.9018\n",
      "Epoch 501/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3074 - accuracy: 0.8864\n",
      "Epoch 502/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2823 - accuracy: 0.8973\n",
      "Epoch 503/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2752 - accuracy: 0.8999\n",
      "Epoch 504/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2951 - accuracy: 0.8974\n",
      "Epoch 505/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2785 - accuracy: 0.9009\n",
      "Epoch 506/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2919 - accuracy: 0.8978\n",
      "Epoch 507/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2892 - accuracy: 0.9007\n",
      "Epoch 508/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2721 - accuracy: 0.8986\n",
      "Epoch 509/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2661 - accuracy: 0.9025\n",
      "Epoch 510/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2822 - accuracy: 0.8959\n",
      "Epoch 511/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2761 - accuracy: 0.8994\n",
      "Epoch 512/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2861 - accuracy: 0.8962\n",
      "Epoch 513/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2776 - accuracy: 0.8954\n",
      "Epoch 514/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2778 - accuracy: 0.8997\n",
      "Epoch 515/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2678 - accuracy: 0.9005\n",
      "Epoch 516/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2725 - accuracy: 0.8985\n",
      "Epoch 517/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2989 - accuracy: 0.8956\n",
      "Epoch 518/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2731 - accuracy: 0.9019\n",
      "Epoch 519/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2750 - accuracy: 0.8942\n",
      "Epoch 520/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2876 - accuracy: 0.8987\n",
      "Epoch 521/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2654 - accuracy: 0.8991\n",
      "Epoch 522/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2877 - accuracy: 0.8932\n",
      "Epoch 523/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2972 - accuracy: 0.8908\n",
      "Epoch 524/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2780 - accuracy: 0.8938\n",
      "Epoch 525/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2829 - accuracy: 0.8983\n",
      "Epoch 526/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2747 - accuracy: 0.9023\n",
      "Epoch 527/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2695 - accuracy: 0.8950\n",
      "Epoch 528/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2835 - accuracy: 0.8966\n",
      "Epoch 529/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2907 - accuracy: 0.8965\n",
      "Epoch 530/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2669 - accuracy: 0.9071\n",
      "Epoch 531/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2798 - accuracy: 0.9043\n",
      "Epoch 532/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2962 - accuracy: 0.8865\n",
      "Epoch 533/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2597 - accuracy: 0.9089\n",
      "Epoch 534/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2834 - accuracy: 0.8984\n",
      "Epoch 535/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2844 - accuracy: 0.8939\n",
      "Epoch 536/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2926 - accuracy: 0.8986\n",
      "Epoch 537/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2907 - accuracy: 0.8952\n",
      "Epoch 538/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2889 - accuracy: 0.8983\n",
      "Epoch 539/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2786 - accuracy: 0.8974\n",
      "Epoch 540/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2896 - accuracy: 0.8940\n",
      "Epoch 541/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2824 - accuracy: 0.8976\n",
      "Epoch 542/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2853 - accuracy: 0.8992\n",
      "Epoch 543/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2971 - accuracy: 0.8922\n",
      "Epoch 544/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2972 - accuracy: 0.8932\n",
      "Epoch 545/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2675 - accuracy: 0.9074\n",
      "Epoch 546/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2786 - accuracy: 0.8960\n",
      "Epoch 547/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2732 - accuracy: 0.9013\n",
      "Epoch 548/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2660 - accuracy: 0.9028\n",
      "Epoch 549/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2770 - accuracy: 0.9019\n",
      "Epoch 550/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2921 - accuracy: 0.8981\n",
      "Epoch 551/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2883 - accuracy: 0.8959\n",
      "Epoch 552/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2965 - accuracy: 0.8902\n",
      "Epoch 553/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2720 - accuracy: 0.9014\n",
      "Epoch 554/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2741 - accuracy: 0.8981\n",
      "Epoch 555/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2825 - accuracy: 0.8992\n",
      "Epoch 556/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2661 - accuracy: 0.9049\n",
      "Epoch 557/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2735 - accuracy: 0.9028\n",
      "Epoch 558/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2756 - accuracy: 0.8941\n",
      "Epoch 559/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2588 - accuracy: 0.9056\n",
      "Epoch 560/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2866 - accuracy: 0.8925\n",
      "Epoch 561/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2554 - accuracy: 0.9061\n",
      "Epoch 562/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2780 - accuracy: 0.8984\n",
      "Epoch 563/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2896 - accuracy: 0.8947\n",
      "Epoch 564/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2912 - accuracy: 0.8924\n",
      "Epoch 565/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2473 - accuracy: 0.9135\n",
      "Epoch 566/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2608 - accuracy: 0.9058\n",
      "Epoch 567/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2939 - accuracy: 0.8942\n",
      "Epoch 568/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2754 - accuracy: 0.8982\n",
      "Epoch 569/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2709 - accuracy: 0.9003\n",
      "Epoch 570/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2925 - accuracy: 0.8980\n",
      "Epoch 571/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2794 - accuracy: 0.9002\n",
      "Epoch 572/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2794 - accuracy: 0.9001\n",
      "Epoch 573/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2734 - accuracy: 0.9010\n",
      "Epoch 574/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2725 - accuracy: 0.8995\n",
      "Epoch 575/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2700 - accuracy: 0.9010\n",
      "Epoch 576/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2674 - accuracy: 0.8998\n",
      "Epoch 577/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2711 - accuracy: 0.8995\n",
      "Epoch 578/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2585 - accuracy: 0.9068\n",
      "Epoch 579/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2609 - accuracy: 0.9045\n",
      "Epoch 580/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2802 - accuracy: 0.9003\n",
      "Epoch 581/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2727 - accuracy: 0.9024\n",
      "Epoch 582/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3065 - accuracy: 0.8921\n",
      "Epoch 583/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2852 - accuracy: 0.8930\n",
      "Epoch 584/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2701 - accuracy: 0.9036\n",
      "Epoch 585/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2827 - accuracy: 0.8936\n",
      "Epoch 586/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2687 - accuracy: 0.9032\n",
      "Epoch 587/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2852 - accuracy: 0.9007\n",
      "Epoch 588/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3056 - accuracy: 0.8921\n",
      "Epoch 589/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2705 - accuracy: 0.9032\n",
      "Epoch 590/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2701 - accuracy: 0.9057\n",
      "Epoch 591/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2705 - accuracy: 0.9013\n",
      "Epoch 592/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2867 - accuracy: 0.8902\n",
      "Epoch 593/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2810 - accuracy: 0.8976\n",
      "Epoch 594/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2798 - accuracy: 0.8997\n",
      "Epoch 595/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2755 - accuracy: 0.8989\n",
      "Epoch 596/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2732 - accuracy: 0.8971\n",
      "Epoch 597/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2815 - accuracy: 0.8942\n",
      "Epoch 598/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2871 - accuracy: 0.8948\n",
      "Epoch 599/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2630 - accuracy: 0.9024\n",
      "Epoch 600/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2804 - accuracy: 0.8966\n",
      "Epoch 601/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2524 - accuracy: 0.9033\n",
      "Epoch 602/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2812 - accuracy: 0.8957\n",
      "Epoch 603/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2898 - accuracy: 0.8917\n",
      "Epoch 604/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2594 - accuracy: 0.9049\n",
      "Epoch 605/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2628 - accuracy: 0.9057\n",
      "Epoch 606/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2718 - accuracy: 0.8976\n",
      "Epoch 607/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2756 - accuracy: 0.8991\n",
      "Epoch 608/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2543 - accuracy: 0.9027\n",
      "Epoch 609/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2580 - accuracy: 0.9028\n",
      "Epoch 610/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2817 - accuracy: 0.8969\n",
      "Epoch 611/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2836 - accuracy: 0.8972\n",
      "Epoch 612/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2947 - accuracy: 0.8921\n",
      "Epoch 613/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2702 - accuracy: 0.9022\n",
      "Epoch 614/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2903 - accuracy: 0.8936\n",
      "Epoch 615/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2620 - accuracy: 0.9041\n",
      "Epoch 616/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2589 - accuracy: 0.9036\n",
      "Epoch 617/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2767 - accuracy: 0.9007\n",
      "Epoch 618/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2755 - accuracy: 0.8988\n",
      "Epoch 619/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2823 - accuracy: 0.8950\n",
      "Epoch 620/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2699 - accuracy: 0.9008\n",
      "Epoch 621/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2672 - accuracy: 0.9016\n",
      "Epoch 622/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2653 - accuracy: 0.9017\n",
      "Epoch 623/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2579 - accuracy: 0.9048\n",
      "Epoch 624/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2867 - accuracy: 0.8993\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2690 - accuracy: 0.8995\n",
      "Epoch 626/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2758 - accuracy: 0.9040\n",
      "Epoch 627/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2870 - accuracy: 0.8993\n",
      "Epoch 628/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2583 - accuracy: 0.9026\n",
      "Epoch 629/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2872 - accuracy: 0.8940\n",
      "Epoch 630/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2806 - accuracy: 0.9009\n",
      "Epoch 631/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2849 - accuracy: 0.8913\n",
      "Epoch 632/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2807 - accuracy: 0.8963\n",
      "Epoch 633/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2770 - accuracy: 0.9004\n",
      "Epoch 634/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2883 - accuracy: 0.8951\n",
      "Epoch 635/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2651 - accuracy: 0.8999\n",
      "Epoch 636/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2769 - accuracy: 0.8984\n",
      "Epoch 637/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2692 - accuracy: 0.9007\n",
      "Epoch 638/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2724 - accuracy: 0.8967\n",
      "Epoch 639/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2820 - accuracy: 0.8994\n",
      "Epoch 640/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2884 - accuracy: 0.8927\n",
      "Epoch 641/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2718 - accuracy: 0.8968\n",
      "Epoch 642/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2776 - accuracy: 0.8980\n",
      "Epoch 643/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2911 - accuracy: 0.8945\n",
      "Epoch 644/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2525 - accuracy: 0.9074\n",
      "Epoch 645/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2783 - accuracy: 0.8953\n",
      "Epoch 646/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2928 - accuracy: 0.8946\n",
      "Epoch 647/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2723 - accuracy: 0.8979\n",
      "Epoch 648/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2970 - accuracy: 0.8891\n",
      "Epoch 649/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2931 - accuracy: 0.8946\n",
      "Epoch 650/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2771 - accuracy: 0.8980\n",
      "Epoch 651/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2691 - accuracy: 0.8987\n",
      "Epoch 652/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2837 - accuracy: 0.8973\n",
      "Epoch 653/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2844 - accuracy: 0.8930\n",
      "Epoch 654/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2690 - accuracy: 0.9038\n",
      "Epoch 655/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2770 - accuracy: 0.8938\n",
      "Epoch 656/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2782 - accuracy: 0.8935\n",
      "Epoch 657/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2965 - accuracy: 0.8931\n",
      "Epoch 658/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2752 - accuracy: 0.9020\n",
      "Epoch 659/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2650 - accuracy: 0.9005\n",
      "Epoch 660/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2845 - accuracy: 0.8963\n",
      "Epoch 661/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3040 - accuracy: 0.8906\n",
      "Epoch 662/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2556 - accuracy: 0.9081\n",
      "Epoch 663/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2846 - accuracy: 0.8904\n",
      "Epoch 664/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2870 - accuracy: 0.8965\n",
      "Epoch 665/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2680 - accuracy: 0.8981\n",
      "Epoch 666/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2711 - accuracy: 0.9009\n",
      "Epoch 667/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2446 - accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2699 - accuracy: 0.9040\n",
      "Epoch 669/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2643 - accuracy: 0.9043\n",
      "Epoch 670/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2908 - accuracy: 0.8944\n",
      "Epoch 671/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2427 - accuracy: 0.9049\n",
      "Epoch 672/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2759 - accuracy: 0.8984\n",
      "Epoch 673/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2547 - accuracy: 0.9079\n",
      "Epoch 674/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2466 - accuracy: 0.9094\n",
      "Epoch 675/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2696 - accuracy: 0.8988\n",
      "Epoch 676/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2757 - accuracy: 0.8957\n",
      "Epoch 677/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2618 - accuracy: 0.9088\n",
      "Epoch 678/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2611 - accuracy: 0.9030\n",
      "Epoch 679/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2957 - accuracy: 0.8928\n",
      "Epoch 680/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2763 - accuracy: 0.8991\n",
      "Epoch 681/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2800 - accuracy: 0.8976\n",
      "Epoch 682/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2878 - accuracy: 0.8952\n",
      "Epoch 683/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2860 - accuracy: 0.8904\n",
      "Epoch 684/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2749 - accuracy: 0.8972\n",
      "Epoch 685/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2776 - accuracy: 0.8957\n",
      "Epoch 686/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2862 - accuracy: 0.8992\n",
      "Epoch 687/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2688 - accuracy: 0.9013\n",
      "Epoch 688/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2803 - accuracy: 0.8974\n",
      "Epoch 689/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2714 - accuracy: 0.8971\n",
      "Epoch 690/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2679 - accuracy: 0.8988\n",
      "Epoch 691/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2857 - accuracy: 0.8984\n",
      "Epoch 692/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2654 - accuracy: 0.9022\n",
      "Epoch 693/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2659 - accuracy: 0.9014 0s - loss: 0.2647 - accuracy\n",
      "Epoch 694/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2717 - accuracy: 0.8940\n",
      "Epoch 695/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2949 - accuracy: 0.8940\n",
      "Epoch 696/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2607 - accuracy: 0.8994\n",
      "Epoch 697/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2724 - accuracy: 0.9010\n",
      "Epoch 698/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2766 - accuracy: 0.8982\n",
      "Epoch 699/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2658 - accuracy: 0.8997\n",
      "Epoch 700/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2834 - accuracy: 0.8974\n",
      "Epoch 701/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2678 - accuracy: 0.8968\n",
      "Epoch 702/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2558 - accuracy: 0.9088\n",
      "Epoch 703/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2452 - accuracy: 0.9108\n",
      "Epoch 704/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2556 - accuracy: 0.8998\n",
      "Epoch 705/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2392 - accuracy: 0.9117\n",
      "Epoch 706/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3057 - accuracy: 0.8874\n",
      "Epoch 707/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2699 - accuracy: 0.8989\n",
      "Epoch 708/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2506 - accuracy: 0.9019\n",
      "Epoch 709/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3023 - accuracy: 0.8896\n",
      "Epoch 710/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2671 - accuracy: 0.8988\n",
      "Epoch 711/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2580 - accuracy: 0.8980\n",
      "Epoch 712/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2769 - accuracy: 0.8962\n",
      "Epoch 713/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2500 - accuracy: 0.9061\n",
      "Epoch 714/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2402 - accuracy: 0.9066\n",
      "Epoch 715/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2665 - accuracy: 0.9014\n",
      "Epoch 716/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2598 - accuracy: 0.9008\n",
      "Epoch 717/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2615 - accuracy: 0.9032\n",
      "Epoch 718/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2879 - accuracy: 0.8990\n",
      "Epoch 719/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2750 - accuracy: 0.8996\n",
      "Epoch 720/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2807 - accuracy: 0.8972\n",
      "Epoch 721/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2740 - accuracy: 0.9042\n",
      "Epoch 722/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2840 - accuracy: 0.8913\n",
      "Epoch 723/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2725 - accuracy: 0.8999\n",
      "Epoch 724/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2530 - accuracy: 0.9073\n",
      "Epoch 725/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2724 - accuracy: 0.9008\n",
      "Epoch 726/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2788 - accuracy: 0.8943\n",
      "Epoch 727/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2721 - accuracy: 0.8961\n",
      "Epoch 728/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2699 - accuracy: 0.8960\n",
      "Epoch 729/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3075 - accuracy: 0.8873\n",
      "Epoch 730/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2828 - accuracy: 0.8986\n",
      "Epoch 731/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2718 - accuracy: 0.9000\n",
      "Epoch 732/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2620 - accuracy: 0.9023\n",
      "Epoch 733/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2687 - accuracy: 0.9020\n",
      "Epoch 734/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2882 - accuracy: 0.8907\n",
      "Epoch 735/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2675 - accuracy: 0.9006\n",
      "Epoch 736/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2678 - accuracy: 0.9038\n",
      "Epoch 737/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2785 - accuracy: 0.8961\n",
      "Epoch 738/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2753 - accuracy: 0.9025\n",
      "Epoch 739/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2713 - accuracy: 0.8982\n",
      "Epoch 740/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2763 - accuracy: 0.8959\n",
      "Epoch 741/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2596 - accuracy: 0.9033\n",
      "Epoch 742/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2554 - accuracy: 0.9079\n",
      "Epoch 743/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2867 - accuracy: 0.8944\n",
      "Epoch 744/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2610 - accuracy: 0.9000\n",
      "Epoch 745/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2891 - accuracy: 0.8915\n",
      "Epoch 746/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2767 - accuracy: 0.8950\n",
      "Epoch 747/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2632 - accuracy: 0.9024\n",
      "Epoch 748/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2729 - accuracy: 0.8950\n",
      "Epoch 749/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2547 - accuracy: 0.9020\n",
      "Epoch 750/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2925 - accuracy: 0.8913\n",
      "Epoch 751/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2747 - accuracy: 0.8975\n",
      "Epoch 752/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2865 - accuracy: 0.8917\n",
      "Epoch 753/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2758 - accuracy: 0.8982\n",
      "Epoch 754/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2670 - accuracy: 0.9051\n",
      "Epoch 755/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2653 - accuracy: 0.9037\n",
      "Epoch 756/1000\n",
      "145/145 [==============================] - 3s 18ms/step - loss: 0.2764 - accuracy: 0.9031\n",
      "Epoch 757/1000\n",
      "145/145 [==============================] - 3s 17ms/step - loss: 0.2557 - accuracy: 0.9101\n",
      "Epoch 758/1000\n",
      "145/145 [==============================] - 3s 18ms/step - loss: 0.2804 - accuracy: 0.8915\n",
      "Epoch 759/1000\n",
      "145/145 [==============================] - 3s 17ms/step - loss: 0.2688 - accuracy: 0.9005\n",
      "Epoch 760/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2751 - accuracy: 0.8976\n",
      "Epoch 761/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2920 - accuracy: 0.8883\n",
      "Epoch 762/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2499 - accuracy: 0.9048\n",
      "Epoch 763/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2750 - accuracy: 0.8986\n",
      "Epoch 764/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2747 - accuracy: 0.8982\n",
      "Epoch 765/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2638 - accuracy: 0.9015\n",
      "Epoch 766/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2854 - accuracy: 0.8977\n",
      "Epoch 767/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2745 - accuracy: 0.8957\n",
      "Epoch 768/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2523 - accuracy: 0.9060\n",
      "Epoch 769/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2709 - accuracy: 0.9018\n",
      "Epoch 770/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2967 - accuracy: 0.8904\n",
      "Epoch 771/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2658 - accuracy: 0.9005\n",
      "Epoch 772/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2546 - accuracy: 0.9037\n",
      "Epoch 773/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2565 - accuracy: 0.9071\n",
      "Epoch 774/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2660 - accuracy: 0.9041\n",
      "Epoch 775/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2768 - accuracy: 0.8935\n",
      "Epoch 776/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2591 - accuracy: 0.9044\n",
      "Epoch 777/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2736 - accuracy: 0.8974\n",
      "Epoch 778/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2540 - accuracy: 0.9032\n",
      "Epoch 779/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2681 - accuracy: 0.8963\n",
      "Epoch 780/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2613 - accuracy: 0.8998\n",
      "Epoch 781/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2683 - accuracy: 0.8984\n",
      "Epoch 782/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2766 - accuracy: 0.8984\n",
      "Epoch 783/1000\n",
      "145/145 [==============================] - 3s 18ms/step - loss: 0.2912 - accuracy: 0.8886\n",
      "Epoch 784/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2927 - accuracy: 0.8895\n",
      "Epoch 785/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2473 - accuracy: 0.9074\n",
      "Epoch 786/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2691 - accuracy: 0.8993\n",
      "Epoch 787/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2683 - accuracy: 0.9016\n",
      "Epoch 788/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2774 - accuracy: 0.8957\n",
      "Epoch 789/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2879 - accuracy: 0.8932\n",
      "Epoch 790/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2638 - accuracy: 0.8973\n",
      "Epoch 791/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2755 - accuracy: 0.8953\n",
      "Epoch 792/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2587 - accuracy: 0.9034\n",
      "Epoch 793/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2492 - accuracy: 0.9068\n",
      "Epoch 794/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2687 - accuracy: 0.9023\n",
      "Epoch 795/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2601 - accuracy: 0.9051\n",
      "Epoch 796/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2585 - accuracy: 0.9038\n",
      "Epoch 797/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2678 - accuracy: 0.9037\n",
      "Epoch 798/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2518 - accuracy: 0.9050\n",
      "Epoch 799/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2746 - accuracy: 0.8971\n",
      "Epoch 800/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2407 - accuracy: 0.9077\n",
      "Epoch 801/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2609 - accuracy: 0.9003\n",
      "Epoch 802/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2607 - accuracy: 0.8989\n",
      "Epoch 803/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2453 - accuracy: 0.9100\n",
      "Epoch 804/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2701 - accuracy: 0.8961\n",
      "Epoch 805/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2691 - accuracy: 0.8969\n",
      "Epoch 806/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2652 - accuracy: 0.9063\n",
      "Epoch 807/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2677 - accuracy: 0.9022\n",
      "Epoch 808/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2574 - accuracy: 0.9001\n",
      "Epoch 809/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2894 - accuracy: 0.8899\n",
      "Epoch 810/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2858 - accuracy: 0.8920\n",
      "Epoch 811/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2764 - accuracy: 0.9003\n",
      "Epoch 812/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2808 - accuracy: 0.8997\n",
      "Epoch 813/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2725 - accuracy: 0.8973\n",
      "Epoch 814/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2627 - accuracy: 0.8986\n",
      "Epoch 815/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2729 - accuracy: 0.8996\n",
      "Epoch 816/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2708 - accuracy: 0.8973\n",
      "Epoch 817/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2689 - accuracy: 0.9002\n",
      "Epoch 818/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2709 - accuracy: 0.8985\n",
      "Epoch 819/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2919 - accuracy: 0.8923\n",
      "Epoch 820/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2683 - accuracy: 0.8957\n",
      "Epoch 821/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3007 - accuracy: 0.8869\n",
      "Epoch 822/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2744 - accuracy: 0.8961\n",
      "Epoch 823/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2935 - accuracy: 0.8964\n",
      "Epoch 824/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2479 - accuracy: 0.9035\n",
      "Epoch 825/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2771 - accuracy: 0.9017\n",
      "Epoch 826/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2599 - accuracy: 0.9044\n",
      "Epoch 827/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2686 - accuracy: 0.8965\n",
      "Epoch 828/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2787 - accuracy: 0.8941\n",
      "Epoch 829/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2767 - accuracy: 0.8974\n",
      "Epoch 830/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2653 - accuracy: 0.9034\n",
      "Epoch 831/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2749 - accuracy: 0.8943\n",
      "Epoch 832/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2742 - accuracy: 0.8996\n",
      "Epoch 833/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2797 - accuracy: 0.8946\n",
      "Epoch 834/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2610 - accuracy: 0.9001\n",
      "Epoch 835/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2674 - accuracy: 0.9050\n",
      "Epoch 836/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2730 - accuracy: 0.8949\n",
      "Epoch 837/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2592 - accuracy: 0.9018\n",
      "Epoch 838/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2565 - accuracy: 0.9025\n",
      "Epoch 839/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2541 - accuracy: 0.9043\n",
      "Epoch 840/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2706 - accuracy: 0.8964\n",
      "Epoch 841/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2988 - accuracy: 0.8889\n",
      "Epoch 842/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2531 - accuracy: 0.9075\n",
      "Epoch 843/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2703 - accuracy: 0.8977\n",
      "Epoch 844/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2791 - accuracy: 0.8930\n",
      "Epoch 845/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2742 - accuracy: 0.8977\n",
      "Epoch 846/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2743 - accuracy: 0.8946\n",
      "Epoch 847/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2676 - accuracy: 0.8997\n",
      "Epoch 848/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2536 - accuracy: 0.9048\n",
      "Epoch 849/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2797 - accuracy: 0.9012\n",
      "Epoch 850/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2599 - accuracy: 0.9062\n",
      "Epoch 851/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2620 - accuracy: 0.9009\n",
      "Epoch 852/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2641 - accuracy: 0.8969\n",
      "Epoch 853/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2668 - accuracy: 0.8985\n",
      "Epoch 854/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2687 - accuracy: 0.9041\n",
      "Epoch 855/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2671 - accuracy: 0.8959\n",
      "Epoch 856/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2549 - accuracy: 0.9044\n",
      "Epoch 857/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2494 - accuracy: 0.9074\n",
      "Epoch 858/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2750 - accuracy: 0.9033\n",
      "Epoch 859/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2713 - accuracy: 0.8944\n",
      "Epoch 860/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2749 - accuracy: 0.8964\n",
      "Epoch 861/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2451 - accuracy: 0.9121\n",
      "Epoch 862/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2659 - accuracy: 0.9049\n",
      "Epoch 863/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2606 - accuracy: 0.9038\n",
      "Epoch 864/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2625 - accuracy: 0.9031\n",
      "Epoch 865/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2772 - accuracy: 0.8967\n",
      "Epoch 866/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2705 - accuracy: 0.8964\n",
      "Epoch 867/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2556 - accuracy: 0.9014\n",
      "Epoch 868/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2629 - accuracy: 0.9028\n",
      "Epoch 869/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2545 - accuracy: 0.9043\n",
      "Epoch 870/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2845 - accuracy: 0.8988\n",
      "Epoch 871/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2602 - accuracy: 0.9000\n",
      "Epoch 872/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2614 - accuracy: 0.9006\n",
      "Epoch 873/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2722 - accuracy: 0.8976\n",
      "Epoch 874/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2618 - accuracy: 0.9040\n",
      "Epoch 875/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2831 - accuracy: 0.8948\n",
      "Epoch 876/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2757 - accuracy: 0.8927\n",
      "Epoch 877/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2613 - accuracy: 0.9052\n",
      "Epoch 878/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2671 - accuracy: 0.9024\n",
      "Epoch 879/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2794 - accuracy: 0.8984\n",
      "Epoch 880/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2676 - accuracy: 0.9006\n",
      "Epoch 881/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2462 - accuracy: 0.9072\n",
      "Epoch 882/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2857 - accuracy: 0.8953\n",
      "Epoch 883/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2943 - accuracy: 0.8942\n",
      "Epoch 884/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2412 - accuracy: 0.9088\n",
      "Epoch 885/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2529 - accuracy: 0.9038\n",
      "Epoch 886/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2752 - accuracy: 0.8932\n",
      "Epoch 887/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2482 - accuracy: 0.9085\n",
      "Epoch 888/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2864 - accuracy: 0.8899\n",
      "Epoch 889/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2710 - accuracy: 0.8990\n",
      "Epoch 890/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2531 - accuracy: 0.9063\n",
      "Epoch 891/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2611 - accuracy: 0.9025\n",
      "Epoch 892/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2709 - accuracy: 0.8973\n",
      "Epoch 893/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2845 - accuracy: 0.8907\n",
      "Epoch 894/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2489 - accuracy: 0.9044\n",
      "Epoch 895/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2541 - accuracy: 0.9054\n",
      "Epoch 896/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2645 - accuracy: 0.9006\n",
      "Epoch 897/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2743 - accuracy: 0.8977\n",
      "Epoch 898/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2696 - accuracy: 0.9017\n",
      "Epoch 899/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2582 - accuracy: 0.9001\n",
      "Epoch 900/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2706 - accuracy: 0.8946\n",
      "Epoch 901/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2656 - accuracy: 0.9003\n",
      "Epoch 902/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2576 - accuracy: 0.9031\n",
      "Epoch 903/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2817 - accuracy: 0.8930\n",
      "Epoch 904/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2697 - accuracy: 0.9008\n",
      "Epoch 905/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2861 - accuracy: 0.8926\n",
      "Epoch 906/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2655 - accuracy: 0.9027 \n",
      "Epoch 907/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2639 - accuracy: 0.9021\n",
      "Epoch 908/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2755 - accuracy: 0.8942\n",
      "Epoch 909/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2625 - accuracy: 0.8962\n",
      "Epoch 910/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2463 - accuracy: 0.9066\n",
      "Epoch 911/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2687 - accuracy: 0.8964\n",
      "Epoch 912/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2705 - accuracy: 0.8991\n",
      "Epoch 913/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2522 - accuracy: 0.9016\n",
      "Epoch 914/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2634 - accuracy: 0.8988\n",
      "Epoch 915/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2632 - accuracy: 0.9026\n",
      "Epoch 916/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2731 - accuracy: 0.8991\n",
      "Epoch 917/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2804 - accuracy: 0.8942\n",
      "Epoch 918/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2713 - accuracy: 0.8968\n",
      "Epoch 919/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2696 - accuracy: 0.8933\n",
      "Epoch 920/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2610 - accuracy: 0.8989\n",
      "Epoch 921/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2785 - accuracy: 0.8936\n",
      "Epoch 922/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2467 - accuracy: 0.9111\n",
      "Epoch 923/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2537 - accuracy: 0.9034\n",
      "Epoch 924/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.3050 - accuracy: 0.8872\n",
      "Epoch 925/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2811 - accuracy: 0.8923\n",
      "Epoch 926/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2732 - accuracy: 0.8994\n",
      "Epoch 927/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2952 - accuracy: 0.8954\n",
      "Epoch 928/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2777 - accuracy: 0.8947\n",
      "Epoch 929/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2636 - accuracy: 0.8979\n",
      "Epoch 930/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2670 - accuracy: 0.9056\n",
      "Epoch 931/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2664 - accuracy: 0.9035\n",
      "Epoch 932/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2533 - accuracy: 0.9054\n",
      "Epoch 933/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2439 - accuracy: 0.9042\n",
      "Epoch 934/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2771 - accuracy: 0.8981\n",
      "Epoch 935/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2629 - accuracy: 0.8976\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2612 - accuracy: 0.9031\n",
      "Epoch 937/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2785 - accuracy: 0.8967\n",
      "Epoch 938/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2779 - accuracy: 0.8931\n",
      "Epoch 939/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2707 - accuracy: 0.9010\n",
      "Epoch 940/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2695 - accuracy: 0.8982\n",
      "Epoch 941/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2781 - accuracy: 0.8953\n",
      "Epoch 942/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2754 - accuracy: 0.9001\n",
      "Epoch 943/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2675 - accuracy: 0.8976\n",
      "Epoch 944/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2820 - accuracy: 0.8941\n",
      "Epoch 945/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2689 - accuracy: 0.8949\n",
      "Epoch 946/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2644 - accuracy: 0.9013\n",
      "Epoch 947/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2674 - accuracy: 0.9036\n",
      "Epoch 948/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2722 - accuracy: 0.8957\n",
      "Epoch 949/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2808 - accuracy: 0.8941\n",
      "Epoch 950/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2859 - accuracy: 0.8946\n",
      "Epoch 951/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2530 - accuracy: 0.9035\n",
      "Epoch 952/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2556 - accuracy: 0.9005\n",
      "Epoch 953/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2814 - accuracy: 0.8915\n",
      "Epoch 954/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2596 - accuracy: 0.9029\n",
      "Epoch 955/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2634 - accuracy: 0.8998\n",
      "Epoch 956/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2868 - accuracy: 0.8922\n",
      "Epoch 957/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2516 - accuracy: 0.9045\n",
      "Epoch 958/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2414 - accuracy: 0.9084\n",
      "Epoch 959/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2645 - accuracy: 0.8953\n",
      "Epoch 960/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2597 - accuracy: 0.9003\n",
      "Epoch 961/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2730 - accuracy: 0.8952\n",
      "Epoch 962/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2704 - accuracy: 0.8972\n",
      "Epoch 963/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2455 - accuracy: 0.9106\n",
      "Epoch 964/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2487 - accuracy: 0.9054\n",
      "Epoch 965/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2480 - accuracy: 0.9082\n",
      "Epoch 966/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2843 - accuracy: 0.8963\n",
      "Epoch 967/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2602 - accuracy: 0.9011\n",
      "Epoch 968/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2757 - accuracy: 0.8960\n",
      "Epoch 969/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2802 - accuracy: 0.8924\n",
      "Epoch 970/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2511 - accuracy: 0.9104\n",
      "Epoch 971/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2502 - accuracy: 0.9071\n",
      "Epoch 972/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2705 - accuracy: 0.8965\n",
      "Epoch 973/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2629 - accuracy: 0.8993\n",
      "Epoch 974/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2610 - accuracy: 0.8995\n",
      "Epoch 975/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2695 - accuracy: 0.8950\n",
      "Epoch 976/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2761 - accuracy: 0.8986\n",
      "Epoch 977/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2486 - accuracy: 0.9056\n",
      "Epoch 978/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2674 - accuracy: 0.8985\n",
      "Epoch 979/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2557 - accuracy: 0.9053\n",
      "Epoch 980/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2606 - accuracy: 0.9035\n",
      "Epoch 981/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2594 - accuracy: 0.8987\n",
      "Epoch 982/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2664 - accuracy: 0.8971\n",
      "Epoch 983/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2706 - accuracy: 0.8951\n",
      "Epoch 984/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2693 - accuracy: 0.8947\n",
      "Epoch 985/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2832 - accuracy: 0.8932\n",
      "Epoch 986/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2639 - accuracy: 0.8946\n",
      "Epoch 987/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2674 - accuracy: 0.8976\n",
      "Epoch 988/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2864 - accuracy: 0.8942\n",
      "Epoch 989/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2575 - accuracy: 0.9059\n",
      "Epoch 990/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2710 - accuracy: 0.8980\n",
      "Epoch 991/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2814 - accuracy: 0.8935\n",
      "Epoch 992/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2748 - accuracy: 0.8924\n",
      "Epoch 993/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2818 - accuracy: 0.8982\n",
      "Epoch 994/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2498 - accuracy: 0.9071\n",
      "Epoch 995/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2620 - accuracy: 0.9013\n",
      "Epoch 996/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2597 - accuracy: 0.9062\n",
      "Epoch 997/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2596 - accuracy: 0.8998\n",
      "Epoch 998/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2400 - accuracy: 0.9143\n",
      "Epoch 999/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2703 - accuracy: 0.8937\n",
      "Epoch 1000/1000\n",
      "145/145 [==============================] - 2s 17ms/step - loss: 0.2689 - accuracy: 0.8931\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 23, 128)           259456    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 23, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 512)               788480    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2027)              1039851   \n",
      "=================================================================\n",
      "Total params: 2,087,787\n",
      "Trainable params: 2,087,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_bilstm_more_epochs_and_units_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 128, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(256,return_sequences=False, kernel_initializer='random_uniform')),\n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "single_bilstm_more_epochs_and_units_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "single_bilstm_more_epochs_and_units_model.fit(xs,ys,epochs=1000,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "single_bilstm_more_epochs_and_units_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-earthquake",
   "metadata": {},
   "source": [
    "#### Double Bidirectional LSTM layer model 500 epochs 256 units 0.001 LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-medicine",
   "metadata": {},
   "source": [
    "Source: https://machinelearningmastery.com/stacked-long-short-term-memory-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dutch-paradise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "145/145 [==============================] - 11s 41ms/step - loss: 6.9563 - accuracy: 0.0354\n",
      "Epoch 2/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 6.4144 - accuracy: 0.0434\n",
      "Epoch 3/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 6.2684 - accuracy: 0.0471\n",
      "Epoch 4/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 6.1909 - accuracy: 0.0478\n",
      "Epoch 5/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 6.1076 - accuracy: 0.0505\n",
      "Epoch 6/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 6.0520 - accuracy: 0.0513\n",
      "Epoch 7/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.9570 - accuracy: 0.0538\n",
      "Epoch 8/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.8550 - accuracy: 0.0505\n",
      "Epoch 9/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.8921 - accuracy: 0.0478\n",
      "Epoch 10/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.7866 - accuracy: 0.0569\n",
      "Epoch 11/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.6807 - accuracy: 0.0604\n",
      "Epoch 12/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.6700 - accuracy: 0.0604\n",
      "Epoch 13/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.5348 - accuracy: 0.0681\n",
      "Epoch 14/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.3983 - accuracy: 0.0775\n",
      "Epoch 15/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.4218 - accuracy: 0.0789\n",
      "Epoch 16/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.2488 - accuracy: 0.0865\n",
      "Epoch 17/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.2258 - accuracy: 0.0814\n",
      "Epoch 18/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 5.0901 - accuracy: 0.0914\n",
      "Epoch 19/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.9883 - accuracy: 0.0930\n",
      "Epoch 20/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.9445 - accuracy: 0.0926\n",
      "Epoch 21/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.8320 - accuracy: 0.1029\n",
      "Epoch 22/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.7406 - accuracy: 0.1089\n",
      "Epoch 23/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.7045 - accuracy: 0.1057\n",
      "Epoch 24/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.5354 - accuracy: 0.1207\n",
      "Epoch 25/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.4731 - accuracy: 0.1301\n",
      "Epoch 26/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.4042 - accuracy: 0.1259\n",
      "Epoch 27/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.3063 - accuracy: 0.1347\n",
      "Epoch 28/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.2339 - accuracy: 0.1415\n",
      "Epoch 29/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.1835 - accuracy: 0.1495\n",
      "Epoch 30/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.0698 - accuracy: 0.1562\n",
      "Epoch 31/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 4.0268 - accuracy: 0.1680\n",
      "Epoch 32/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.9577 - accuracy: 0.1668\n",
      "Epoch 33/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.8502 - accuracy: 0.1740\n",
      "Epoch 34/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.8035 - accuracy: 0.1832\n",
      "Epoch 35/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.7254 - accuracy: 0.1920\n",
      "Epoch 36/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.6533 - accuracy: 0.2117\n",
      "Epoch 37/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.5708 - accuracy: 0.2211\n",
      "Epoch 38/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.5096 - accuracy: 0.2195\n",
      "Epoch 39/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.4085 - accuracy: 0.2332\n",
      "Epoch 40/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.3387 - accuracy: 0.2439\n",
      "Epoch 41/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.3242 - accuracy: 0.2535\n",
      "Epoch 42/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.2701 - accuracy: 0.2578\n",
      "Epoch 43/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.1464 - accuracy: 0.2869\n",
      "Epoch 44/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.1261 - accuracy: 0.2860\n",
      "Epoch 45/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.0169 - accuracy: 0.2960\n",
      "Epoch 46/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 3.0364 - accuracy: 0.2936\n",
      "Epoch 47/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.9150 - accuracy: 0.3113\n",
      "Epoch 48/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.8728 - accuracy: 0.3274\n",
      "Epoch 49/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.7477 - accuracy: 0.3456\n",
      "Epoch 50/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.7122 - accuracy: 0.3597\n",
      "Epoch 51/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.6476 - accuracy: 0.3539\n",
      "Epoch 52/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.5648 - accuracy: 0.3856\n",
      "Epoch 53/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.5822 - accuracy: 0.3813\n",
      "Epoch 54/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.4732 - accuracy: 0.4025\n",
      "Epoch 55/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.4465 - accuracy: 0.4148\n",
      "Epoch 56/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.3622 - accuracy: 0.4289\n",
      "Epoch 57/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.3502 - accuracy: 0.4301\n",
      "Epoch 58/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.2787 - accuracy: 0.4337\n",
      "Epoch 59/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.2457 - accuracy: 0.4426\n",
      "Epoch 60/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.1765 - accuracy: 0.4723\n",
      "Epoch 61/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.1405 - accuracy: 0.4661\n",
      "Epoch 62/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 2.0934 - accuracy: 0.4776\n",
      "Epoch 63/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.9944 - accuracy: 0.4832\n",
      "Epoch 64/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.9665 - accuracy: 0.5042\n",
      "Epoch 65/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.8830 - accuracy: 0.5333\n",
      "Epoch 66/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.8935 - accuracy: 0.5195\n",
      "Epoch 67/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.8774 - accuracy: 0.5318\n",
      "Epoch 68/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.7845 - accuracy: 0.5448\n",
      "Epoch 69/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.7621 - accuracy: 0.5552\n",
      "Epoch 70/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.7502 - accuracy: 0.5598\n",
      "Epoch 71/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.7194 - accuracy: 0.5685\n",
      "Epoch 72/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.6309 - accuracy: 0.5897\n",
      "Epoch 73/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.6001 - accuracy: 0.5922\n",
      "Epoch 74/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.5893 - accuracy: 0.5814\n",
      "Epoch 75/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.5349 - accuracy: 0.6045\n",
      "Epoch 76/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.5435 - accuracy: 0.5939\n",
      "Epoch 77/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.4507 - accuracy: 0.6333\n",
      "Epoch 78/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.4015 - accuracy: 0.6397\n",
      "Epoch 79/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.4230 - accuracy: 0.6359\n",
      "Epoch 80/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.3651 - accuracy: 0.6397\n",
      "Epoch 81/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.3797 - accuracy: 0.6382\n",
      "Epoch 82/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 1.2887 - accuracy: 0.6621\n",
      "Epoch 83/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.3097 - accuracy: 0.6653\n",
      "Epoch 84/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.2390 - accuracy: 0.6726\n",
      "Epoch 85/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.2464 - accuracy: 0.6656\n",
      "Epoch 86/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.2065 - accuracy: 0.6849\n",
      "Epoch 87/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1921 - accuracy: 0.6874\n",
      "Epoch 88/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1680 - accuracy: 0.6967\n",
      "Epoch 89/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1579 - accuracy: 0.6937\n",
      "Epoch 90/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1227 - accuracy: 0.7054\n",
      "Epoch 91/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1302 - accuracy: 0.6993\n",
      "Epoch 92/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0820 - accuracy: 0.7151\n",
      "Epoch 93/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0741 - accuracy: 0.7145\n",
      "Epoch 94/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0197 - accuracy: 0.7340\n",
      "Epoch 95/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0657 - accuracy: 0.7176\n",
      "Epoch 96/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9928 - accuracy: 0.7311\n",
      "Epoch 97/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9981 - accuracy: 0.7358\n",
      "Epoch 98/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9872 - accuracy: 0.7336\n",
      "Epoch 99/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0226 - accuracy: 0.7166\n",
      "Epoch 100/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9026 - accuracy: 0.7550\n",
      "Epoch 101/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9077 - accuracy: 0.7576\n",
      "Epoch 102/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8732 - accuracy: 0.7688\n",
      "Epoch 103/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8665 - accuracy: 0.7703\n",
      "Epoch 104/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9020 - accuracy: 0.7575\n",
      "Epoch 105/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8222 - accuracy: 0.7760\n",
      "Epoch 106/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8684 - accuracy: 0.7576\n",
      "Epoch 107/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8184 - accuracy: 0.7760\n",
      "Epoch 108/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7946 - accuracy: 0.7840\n",
      "Epoch 109/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8060 - accuracy: 0.7753\n",
      "Epoch 110/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7981 - accuracy: 0.7830\n",
      "Epoch 111/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7888 - accuracy: 0.7914\n",
      "Epoch 112/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7813 - accuracy: 0.7911\n",
      "Epoch 113/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7424 - accuracy: 0.8038\n",
      "Epoch 114/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7262 - accuracy: 0.7984\n",
      "Epoch 115/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7308 - accuracy: 0.7924\n",
      "Epoch 116/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7481 - accuracy: 0.7893\n",
      "Epoch 117/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7005 - accuracy: 0.8090\n",
      "Epoch 118/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6886 - accuracy: 0.8096\n",
      "Epoch 119/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6948 - accuracy: 0.7986\n",
      "Epoch 120/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6820 - accuracy: 0.8133\n",
      "Epoch 121/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6751 - accuracy: 0.8166\n",
      "Epoch 122/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6593 - accuracy: 0.8074 0s - loss: 0.6582 - accu\n",
      "Epoch 123/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6504 - accuracy: 0.8116\n",
      "Epoch 124/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6545 - accuracy: 0.8143\n",
      "Epoch 125/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6294 - accuracy: 0.8245\n",
      "Epoch 126/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6453 - accuracy: 0.8234\n",
      "Epoch 127/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6342 - accuracy: 0.8118\n",
      "Epoch 128/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5847 - accuracy: 0.8291\n",
      "Epoch 129/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6014 - accuracy: 0.8326\n",
      "Epoch 130/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6339 - accuracy: 0.8191\n",
      "Epoch 131/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5809 - accuracy: 0.8253\n",
      "Epoch 132/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.6057 - accuracy: 0.8274\n",
      "Epoch 133/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5801 - accuracy: 0.8242\n",
      "Epoch 134/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.6071 - accuracy: 0.8234\n",
      "Epoch 135/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5747 - accuracy: 0.8365\n",
      "Epoch 136/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5515 - accuracy: 0.8426\n",
      "Epoch 137/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5448 - accuracy: 0.8373\n",
      "Epoch 138/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5376 - accuracy: 0.8415\n",
      "Epoch 139/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5659 - accuracy: 0.8395\n",
      "Epoch 140/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5517 - accuracy: 0.8413\n",
      "Epoch 141/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5378 - accuracy: 0.8426\n",
      "Epoch 142/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5602 - accuracy: 0.8378\n",
      "Epoch 143/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5235 - accuracy: 0.8514\n",
      "Epoch 144/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5255 - accuracy: 0.8467\n",
      "Epoch 145/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5192 - accuracy: 0.8432\n",
      "Epoch 146/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5419 - accuracy: 0.8449\n",
      "Epoch 147/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5188 - accuracy: 0.8405\n",
      "Epoch 148/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5493 - accuracy: 0.8289\n",
      "Epoch 149/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5118 - accuracy: 0.8464\n",
      "Epoch 150/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4888 - accuracy: 0.8555\n",
      "Epoch 151/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4935 - accuracy: 0.8473\n",
      "Epoch 152/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5190 - accuracy: 0.8378\n",
      "Epoch 153/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5127 - accuracy: 0.8475\n",
      "Epoch 154/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4883 - accuracy: 0.8563\n",
      "Epoch 155/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5293 - accuracy: 0.8403\n",
      "Epoch 156/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4644 - accuracy: 0.8659\n",
      "Epoch 157/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4723 - accuracy: 0.8592\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 5s 33ms/step - loss: 0.5099 - accuracy: 0.8455\n",
      "Epoch 159/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4757 - accuracy: 0.8579\n",
      "Epoch 160/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4645 - accuracy: 0.8635\n",
      "Epoch 161/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4824 - accuracy: 0.8522\n",
      "Epoch 162/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4513 - accuracy: 0.8610\n",
      "Epoch 163/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4703 - accuracy: 0.8590\n",
      "Epoch 164/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4337 - accuracy: 0.8705\n",
      "Epoch 165/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4553 - accuracy: 0.8546\n",
      "Epoch 166/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4533 - accuracy: 0.8551\n",
      "Epoch 167/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4765 - accuracy: 0.8606\n",
      "Epoch 168/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4654 - accuracy: 0.8568\n",
      "Epoch 169/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4206 - accuracy: 0.8730\n",
      "Epoch 170/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4355 - accuracy: 0.8695\n",
      "Epoch 171/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4321 - accuracy: 0.8714\n",
      "Epoch 172/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4352 - accuracy: 0.8707\n",
      "Epoch 173/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4498 - accuracy: 0.8562\n",
      "Epoch 174/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4532 - accuracy: 0.8590\n",
      "Epoch 175/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4698 - accuracy: 0.8590\n",
      "Epoch 176/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4555 - accuracy: 0.8580\n",
      "Epoch 177/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4548 - accuracy: 0.8552\n",
      "Epoch 178/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4084 - accuracy: 0.8685\n",
      "Epoch 179/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4042 - accuracy: 0.8747\n",
      "Epoch 180/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4195 - accuracy: 0.8696\n",
      "Epoch 181/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4196 - accuracy: 0.8668\n",
      "Epoch 182/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4235 - accuracy: 0.8741\n",
      "Epoch 183/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4219 - accuracy: 0.8735\n",
      "Epoch 184/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3996 - accuracy: 0.8747\n",
      "Epoch 185/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4001 - accuracy: 0.8688\n",
      "Epoch 186/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4337 - accuracy: 0.8636\n",
      "Epoch 187/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4167 - accuracy: 0.8639\n",
      "Epoch 188/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4274 - accuracy: 0.8709\n",
      "Epoch 189/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3946 - accuracy: 0.8801\n",
      "Epoch 190/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3808 - accuracy: 0.8820\n",
      "Epoch 191/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4033 - accuracy: 0.8716\n",
      "Epoch 192/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4074 - accuracy: 0.8674\n",
      "Epoch 193/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3898 - accuracy: 0.8808\n",
      "Epoch 194/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4212 - accuracy: 0.8716\n",
      "Epoch 195/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3855 - accuracy: 0.8821\n",
      "Epoch 196/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3723 - accuracy: 0.8832\n",
      "Epoch 197/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3931 - accuracy: 0.8755\n",
      "Epoch 198/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3820 - accuracy: 0.8751\n",
      "Epoch 199/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3977 - accuracy: 0.8744\n",
      "Epoch 200/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3971 - accuracy: 0.8692\n",
      "Epoch 201/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4078 - accuracy: 0.8713\n",
      "Epoch 202/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3967 - accuracy: 0.8742\n",
      "Epoch 203/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3844 - accuracy: 0.8779\n",
      "Epoch 204/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3665 - accuracy: 0.8837\n",
      "Epoch 205/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3873 - accuracy: 0.8714\n",
      "Epoch 206/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.4045 - accuracy: 0.8696\n",
      "Epoch 207/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3733 - accuracy: 0.8820\n",
      "Epoch 208/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3543 - accuracy: 0.8891\n",
      "Epoch 209/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3712 - accuracy: 0.8782\n",
      "Epoch 210/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3528 - accuracy: 0.8825\n",
      "Epoch 211/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3632 - accuracy: 0.8838\n",
      "Epoch 212/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3553 - accuracy: 0.8854\n",
      "Epoch 213/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3789 - accuracy: 0.8735\n",
      "Epoch 214/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3733 - accuracy: 0.8768\n",
      "Epoch 215/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3608 - accuracy: 0.8817\n",
      "Epoch 216/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3497 - accuracy: 0.8819\n",
      "Epoch 217/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3596 - accuracy: 0.8776\n",
      "Epoch 218/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3487 - accuracy: 0.8824\n",
      "Epoch 219/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3860 - accuracy: 0.8669\n",
      "Epoch 220/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3402 - accuracy: 0.8849\n",
      "Epoch 221/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3790 - accuracy: 0.8811\n",
      "Epoch 222/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3639 - accuracy: 0.8780\n",
      "Epoch 223/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3639 - accuracy: 0.8795\n",
      "Epoch 224/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3545 - accuracy: 0.8839\n",
      "Epoch 225/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3555 - accuracy: 0.8829\n",
      "Epoch 226/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3560 - accuracy: 0.8825\n",
      "Epoch 227/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3604 - accuracy: 0.8811\n",
      "Epoch 228/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3473 - accuracy: 0.8854\n",
      "Epoch 229/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3669 - accuracy: 0.8757\n",
      "Epoch 230/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3419 - accuracy: 0.8854\n",
      "Epoch 231/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3335 - accuracy: 0.8867\n",
      "Epoch 232/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3632 - accuracy: 0.8829\n",
      "Epoch 233/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3643 - accuracy: 0.8747\n",
      "Epoch 234/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3503 - accuracy: 0.8803\n",
      "Epoch 235/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3601 - accuracy: 0.8776\n",
      "Epoch 236/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3217 - accuracy: 0.8959\n",
      "Epoch 237/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3453 - accuracy: 0.8834\n",
      "Epoch 238/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3668 - accuracy: 0.8812\n",
      "Epoch 239/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3390 - accuracy: 0.8889\n",
      "Epoch 240/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3624 - accuracy: 0.8775\n",
      "Epoch 241/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3504 - accuracy: 0.8804\n",
      "Epoch 242/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3426 - accuracy: 0.8832\n",
      "Epoch 243/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3180 - accuracy: 0.8880\n",
      "Epoch 244/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3339 - accuracy: 0.8881\n",
      "Epoch 245/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3467 - accuracy: 0.8832\n",
      "Epoch 246/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3202 - accuracy: 0.8913\n",
      "Epoch 247/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3328 - accuracy: 0.8875\n",
      "Epoch 248/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3406 - accuracy: 0.8832\n",
      "Epoch 249/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3620 - accuracy: 0.8773\n",
      "Epoch 250/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3304 - accuracy: 0.8892\n",
      "Epoch 251/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3355 - accuracy: 0.8875\n",
      "Epoch 252/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3301 - accuracy: 0.8815\n",
      "Epoch 253/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3416 - accuracy: 0.8836\n",
      "Epoch 254/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3361 - accuracy: 0.8934\n",
      "Epoch 255/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3350 - accuracy: 0.8907 0s -\n",
      "Epoch 256/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3297 - accuracy: 0.8814\n",
      "Epoch 257/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3318 - accuracy: 0.8818\n",
      "Epoch 258/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3179 - accuracy: 0.8913\n",
      "Epoch 259/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3148 - accuracy: 0.8983\n",
      "Epoch 260/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3270 - accuracy: 0.8922\n",
      "Epoch 261/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3319 - accuracy: 0.8855\n",
      "Epoch 262/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3166 - accuracy: 0.8899\n",
      "Epoch 263/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3289 - accuracy: 0.8874\n",
      "Epoch 264/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3129 - accuracy: 0.8940\n",
      "Epoch 265/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3110 - accuracy: 0.8928\n",
      "Epoch 266/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3250 - accuracy: 0.8883\n",
      "Epoch 267/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3114 - accuracy: 0.8961\n",
      "Epoch 268/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3101 - accuracy: 0.8927\n",
      "Epoch 269/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3278 - accuracy: 0.8903\n",
      "Epoch 270/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3198 - accuracy: 0.8917\n",
      "Epoch 271/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3160 - accuracy: 0.8911\n",
      "Epoch 272/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2970 - accuracy: 0.8973\n",
      "Epoch 273/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3344 - accuracy: 0.8873\n",
      "Epoch 274/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3304 - accuracy: 0.8811\n",
      "Epoch 275/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3356 - accuracy: 0.8849\n",
      "Epoch 276/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3174 - accuracy: 0.8907\n",
      "Epoch 277/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3380 - accuracy: 0.8814\n",
      "Epoch 278/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3112 - accuracy: 0.8948\n",
      "Epoch 279/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3031 - accuracy: 0.8895\n",
      "Epoch 280/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3275 - accuracy: 0.8911\n",
      "Epoch 281/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3428 - accuracy: 0.8770\n",
      "Epoch 282/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3265 - accuracy: 0.8873\n",
      "Epoch 283/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3214 - accuracy: 0.8871\n",
      "Epoch 284/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3167 - accuracy: 0.8877\n",
      "Epoch 285/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3082 - accuracy: 0.8896\n",
      "Epoch 286/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3031 - accuracy: 0.8913\n",
      "Epoch 287/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3057 - accuracy: 0.8845\n",
      "Epoch 288/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3323 - accuracy: 0.8833\n",
      "Epoch 289/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3127 - accuracy: 0.8974\n",
      "Epoch 290/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2886 - accuracy: 0.8997\n",
      "Epoch 291/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3080 - accuracy: 0.8942\n",
      "Epoch 292/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3060 - accuracy: 0.8878\n",
      "Epoch 293/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3258 - accuracy: 0.8872\n",
      "Epoch 294/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3139 - accuracy: 0.8950\n",
      "Epoch 295/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3302 - accuracy: 0.8881\n",
      "Epoch 296/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3025 - accuracy: 0.8933\n",
      "Epoch 297/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3060 - accuracy: 0.8927\n",
      "Epoch 298/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2909 - accuracy: 0.8984\n",
      "Epoch 299/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3235 - accuracy: 0.8865\n",
      "Epoch 300/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3102 - accuracy: 0.8931\n",
      "Epoch 301/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2939 - accuracy: 0.8933\n",
      "Epoch 302/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3158 - accuracy: 0.8894\n",
      "Epoch 303/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3235 - accuracy: 0.8910\n",
      "Epoch 304/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3157 - accuracy: 0.8893\n",
      "Epoch 305/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3200 - accuracy: 0.8888\n",
      "Epoch 306/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3030 - accuracy: 0.8859\n",
      "Epoch 307/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3211 - accuracy: 0.8873\n",
      "Epoch 308/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2649 - accuracy: 0.9046\n",
      "Epoch 309/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3247 - accuracy: 0.8874\n",
      "Epoch 310/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3204 - accuracy: 0.8899\n",
      "Epoch 311/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3110 - accuracy: 0.8904\n",
      "Epoch 312/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2945 - accuracy: 0.8961\n",
      "Epoch 313/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2958 - accuracy: 0.9006\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3092 - accuracy: 0.8940\n",
      "Epoch 315/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2974 - accuracy: 0.8936\n",
      "Epoch 316/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2968 - accuracy: 0.9000\n",
      "Epoch 317/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2909 - accuracy: 0.8928\n",
      "Epoch 318/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3068 - accuracy: 0.8910\n",
      "Epoch 319/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2902 - accuracy: 0.8991\n",
      "Epoch 320/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3078 - accuracy: 0.8901\n",
      "Epoch 321/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2957 - accuracy: 0.8938\n",
      "Epoch 322/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2948 - accuracy: 0.8923\n",
      "Epoch 323/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3229 - accuracy: 0.8825\n",
      "Epoch 324/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3200 - accuracy: 0.8893\n",
      "Epoch 325/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3181 - accuracy: 0.8838\n",
      "Epoch 326/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3013 - accuracy: 0.8908\n",
      "Epoch 327/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2863 - accuracy: 0.9009\n",
      "Epoch 328/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2951 - accuracy: 0.8941\n",
      "Epoch 329/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2970 - accuracy: 0.8921\n",
      "Epoch 330/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2821 - accuracy: 0.8953\n",
      "Epoch 331/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3145 - accuracy: 0.8921\n",
      "Epoch 332/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3317 - accuracy: 0.8842\n",
      "Epoch 333/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3009 - accuracy: 0.8888\n",
      "Epoch 334/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3216 - accuracy: 0.8871\n",
      "Epoch 335/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2890 - accuracy: 0.8997\n",
      "Epoch 336/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2911 - accuracy: 0.8980\n",
      "Epoch 337/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2920 - accuracy: 0.8953\n",
      "Epoch 338/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2999 - accuracy: 0.8971\n",
      "Epoch 339/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2880 - accuracy: 0.8954\n",
      "Epoch 340/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2867 - accuracy: 0.8977\n",
      "Epoch 341/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3133 - accuracy: 0.8899\n",
      "Epoch 342/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3146 - accuracy: 0.8874\n",
      "Epoch 343/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2920 - accuracy: 0.8900\n",
      "Epoch 344/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2976 - accuracy: 0.8891\n",
      "Epoch 345/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2834 - accuracy: 0.9018\n",
      "Epoch 346/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2762 - accuracy: 0.9053\n",
      "Epoch 347/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3011 - accuracy: 0.8851\n",
      "Epoch 348/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3052 - accuracy: 0.8917\n",
      "Epoch 349/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3035 - accuracy: 0.8873\n",
      "Epoch 350/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2816 - accuracy: 0.8943\n",
      "Epoch 351/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2974 - accuracy: 0.8950\n",
      "Epoch 352/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2991 - accuracy: 0.8879\n",
      "Epoch 353/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2883 - accuracy: 0.8946\n",
      "Epoch 354/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2805 - accuracy: 0.8975\n",
      "Epoch 355/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2999 - accuracy: 0.8974\n",
      "Epoch 356/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2937 - accuracy: 0.8964\n",
      "Epoch 357/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2878 - accuracy: 0.8976\n",
      "Epoch 358/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2886 - accuracy: 0.8999\n",
      "Epoch 359/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2775 - accuracy: 0.8989\n",
      "Epoch 360/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2791 - accuracy: 0.9040\n",
      "Epoch 361/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3179 - accuracy: 0.8894\n",
      "Epoch 362/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3054 - accuracy: 0.8948\n",
      "Epoch 363/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2987 - accuracy: 0.8963\n",
      "Epoch 364/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2945 - accuracy: 0.8962\n",
      "Epoch 365/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2867 - accuracy: 0.8934\n",
      "Epoch 366/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3003 - accuracy: 0.8886\n",
      "Epoch 367/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3022 - accuracy: 0.8948\n",
      "Epoch 368/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3041 - accuracy: 0.8862\n",
      "Epoch 369/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2720 - accuracy: 0.9017\n",
      "Epoch 370/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2838 - accuracy: 0.8958\n",
      "Epoch 371/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2803 - accuracy: 0.8895\n",
      "Epoch 372/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2854 - accuracy: 0.8958\n",
      "Epoch 373/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2938 - accuracy: 0.8950\n",
      "Epoch 374/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2799 - accuracy: 0.8987\n",
      "Epoch 375/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2993 - accuracy: 0.8973\n",
      "Epoch 376/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3068 - accuracy: 0.8855\n",
      "Epoch 377/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3007 - accuracy: 0.8908\n",
      "Epoch 378/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2918 - accuracy: 0.8920\n",
      "Epoch 379/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2861 - accuracy: 0.8939\n",
      "Epoch 380/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2921 - accuracy: 0.8915\n",
      "Epoch 381/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2940 - accuracy: 0.8956\n",
      "Epoch 382/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2921 - accuracy: 0.8918\n",
      "Epoch 383/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2725 - accuracy: 0.8994\n",
      "Epoch 384/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3084 - accuracy: 0.8900\n",
      "Epoch 385/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2944 - accuracy: 0.8940\n",
      "Epoch 386/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2756 - accuracy: 0.8938\n",
      "Epoch 387/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2715 - accuracy: 0.9010\n",
      "Epoch 388/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2791 - accuracy: 0.8968\n",
      "Epoch 389/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2834 - accuracy: 0.8944\n",
      "Epoch 390/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2796 - accuracy: 0.8951\n",
      "Epoch 391/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2748 - accuracy: 0.9036\n",
      "Epoch 392/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2824 - accuracy: 0.8986\n",
      "Epoch 393/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2751 - accuracy: 0.9000\n",
      "Epoch 394/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2769 - accuracy: 0.8976\n",
      "Epoch 395/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2704 - accuracy: 0.8971\n",
      "Epoch 396/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2848 - accuracy: 0.8909\n",
      "Epoch 397/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2671 - accuracy: 0.9026\n",
      "Epoch 398/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2823 - accuracy: 0.8947\n",
      "Epoch 399/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2884 - accuracy: 0.8957\n",
      "Epoch 400/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2708 - accuracy: 0.9004\n",
      "Epoch 401/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2789 - accuracy: 0.8935\n",
      "Epoch 402/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2794 - accuracy: 0.8954\n",
      "Epoch 403/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2924 - accuracy: 0.8922\n",
      "Epoch 404/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2838 - accuracy: 0.8966\n",
      "Epoch 405/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2760 - accuracy: 0.8935\n",
      "Epoch 406/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2582 - accuracy: 0.9067\n",
      "Epoch 407/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2613 - accuracy: 0.8997\n",
      "Epoch 408/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2961 - accuracy: 0.8956\n",
      "Epoch 409/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3067 - accuracy: 0.8852\n",
      "Epoch 410/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2918 - accuracy: 0.8845\n",
      "Epoch 411/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2845 - accuracy: 0.8916\n",
      "Epoch 412/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2789 - accuracy: 0.8984\n",
      "Epoch 413/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2793 - accuracy: 0.8995\n",
      "Epoch 414/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2929 - accuracy: 0.8913\n",
      "Epoch 415/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2679 - accuracy: 0.8999\n",
      "Epoch 416/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2925 - accuracy: 0.8893\n",
      "Epoch 417/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2625 - accuracy: 0.9055\n",
      "Epoch 418/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2837 - accuracy: 0.8973\n",
      "Epoch 419/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2769 - accuracy: 0.8949\n",
      "Epoch 420/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2640 - accuracy: 0.8983\n",
      "Epoch 421/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3081 - accuracy: 0.8883\n",
      "Epoch 422/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2804 - accuracy: 0.8938\n",
      "Epoch 423/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3089 - accuracy: 0.8872\n",
      "Epoch 424/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2812 - accuracy: 0.8995\n",
      "Epoch 425/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2900 - accuracy: 0.8971\n",
      "Epoch 426/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2641 - accuracy: 0.8981\n",
      "Epoch 427/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2689 - accuracy: 0.9011\n",
      "Epoch 428/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2785 - accuracy: 0.9001\n",
      "Epoch 429/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2589 - accuracy: 0.9045\n",
      "Epoch 430/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2638 - accuracy: 0.8995\n",
      "Epoch 431/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2753 - accuracy: 0.8979\n",
      "Epoch 432/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2749 - accuracy: 0.8999\n",
      "Epoch 433/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2662 - accuracy: 0.9027\n",
      "Epoch 434/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2722 - accuracy: 0.9012\n",
      "Epoch 435/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2600 - accuracy: 0.9039\n",
      "Epoch 436/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3082 - accuracy: 0.8875\n",
      "Epoch 437/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2489 - accuracy: 0.9110\n",
      "Epoch 438/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2905 - accuracy: 0.8901\n",
      "Epoch 439/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2926 - accuracy: 0.8977\n",
      "Epoch 440/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2864 - accuracy: 0.8937\n",
      "Epoch 441/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2559 - accuracy: 0.9070\n",
      "Epoch 442/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2725 - accuracy: 0.9004\n",
      "Epoch 443/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2842 - accuracy: 0.8918\n",
      "Epoch 444/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2875 - accuracy: 0.8933\n",
      "Epoch 445/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2752 - accuracy: 0.8958\n",
      "Epoch 446/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2697 - accuracy: 0.9017\n",
      "Epoch 447/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2871 - accuracy: 0.8931\n",
      "Epoch 448/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2846 - accuracy: 0.8926\n",
      "Epoch 449/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2724 - accuracy: 0.8977\n",
      "Epoch 450/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2769 - accuracy: 0.8969\n",
      "Epoch 451/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2751 - accuracy: 0.8969\n",
      "Epoch 452/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2840 - accuracy: 0.8933\n",
      "Epoch 453/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2904 - accuracy: 0.8915\n",
      "Epoch 454/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2608 - accuracy: 0.9017\n",
      "Epoch 455/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2592 - accuracy: 0.9056\n",
      "Epoch 456/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2901 - accuracy: 0.8910\n",
      "Epoch 457/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.3000 - accuracy: 0.8901\n",
      "Epoch 458/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2549 - accuracy: 0.9017\n",
      "Epoch 459/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2633 - accuracy: 0.8955\n",
      "Epoch 460/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2721 - accuracy: 0.8869\n",
      "Epoch 461/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2745 - accuracy: 0.8967\n",
      "Epoch 462/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2731 - accuracy: 0.8999\n",
      "Epoch 463/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2923 - accuracy: 0.8856\n",
      "Epoch 464/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2977 - accuracy: 0.8868\n",
      "Epoch 465/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2666 - accuracy: 0.8968\n",
      "Epoch 466/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2801 - accuracy: 0.8877\n",
      "Epoch 467/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2634 - accuracy: 0.9006\n",
      "Epoch 468/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2906 - accuracy: 0.8857\n",
      "Epoch 469/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2428 - accuracy: 0.9087\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2820 - accuracy: 0.8940\n",
      "Epoch 471/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2711 - accuracy: 0.8974\n",
      "Epoch 472/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2696 - accuracy: 0.8996\n",
      "Epoch 473/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2869 - accuracy: 0.8893\n",
      "Epoch 474/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2687 - accuracy: 0.9001\n",
      "Epoch 475/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2645 - accuracy: 0.8986\n",
      "Epoch 476/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2809 - accuracy: 0.8995\n",
      "Epoch 477/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2652 - accuracy: 0.8980\n",
      "Epoch 478/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2637 - accuracy: 0.9014\n",
      "Epoch 479/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2717 - accuracy: 0.8937\n",
      "Epoch 480/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2700 - accuracy: 0.8988\n",
      "Epoch 481/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2415 - accuracy: 0.9098\n",
      "Epoch 482/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2611 - accuracy: 0.9049\n",
      "Epoch 483/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2648 - accuracy: 0.8986\n",
      "Epoch 484/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2734 - accuracy: 0.8910\n",
      "Epoch 485/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2877 - accuracy: 0.8875\n",
      "Epoch 486/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2520 - accuracy: 0.9048\n",
      "Epoch 487/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2737 - accuracy: 0.8991\n",
      "Epoch 488/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2518 - accuracy: 0.9023\n",
      "Epoch 489/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2851 - accuracy: 0.8942\n",
      "Epoch 490/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2886 - accuracy: 0.8922\n",
      "Epoch 491/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2721 - accuracy: 0.8936\n",
      "Epoch 492/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2942 - accuracy: 0.8913\n",
      "Epoch 493/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2904 - accuracy: 0.8930\n",
      "Epoch 494/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2658 - accuracy: 0.8999\n",
      "Epoch 495/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2858 - accuracy: 0.8970\n",
      "Epoch 496/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2738 - accuracy: 0.8994\n",
      "Epoch 497/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2824 - accuracy: 0.8920\n",
      "Epoch 498/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2757 - accuracy: 0.9029\n",
      "Epoch 499/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2522 - accuracy: 0.9048\n",
      "Epoch 500/500\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.2530 - accuracy: 0.8976\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 23, 128)           259456    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 23, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 23, 512)           788480    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2027)              1039851   \n",
      "=================================================================\n",
      "Total params: 3,662,699\n",
      "Trainable params: 3,662,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "double_bilstm_more_epochs_and_units_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 128, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(256,return_sequences=True, kernel_initializer='random_uniform')),\n",
    "    Bidirectional(LSTM(256,return_sequences=False, kernel_initializer='random_uniform')),  \n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "double_bilstm_more_epochs_and_units_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "double_bilstm_more_epochs_and_units_model.fit(xs,ys,epochs=500,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "double_bilstm_more_epochs_and_units_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-plenty",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-witness",
   "metadata": {},
   "source": [
    "### Generated proverbs comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-berkeley",
   "metadata": {},
   "source": [
    "#### Increase the width of pandas columns in order to view the full results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "natural-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-purpose",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mineral-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(seedText, textLength, modelArg):\n",
    "    for _ in range(textLength):\n",
    "        token_list = tokenizer.texts_to_sequences([seedText])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=MAX_SEQ_LEN-1,padding='pre')\n",
    "        pred = modelArg.predict_classes(token_list,verbose=0)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == pred:\n",
    "                output_word = word\n",
    "                break\n",
    "        seedText += \" \" + output_word\n",
    "    return seedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alternate-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "predWords = ['голяма', 'кърпиш', 'магаре', 'жена', 'мъж', 'бълха', 'кучето', \n",
    "             'бавно', 'работа', 'учи', 'зло', 'добро', 'котка', 'агнето', 'пешеходец', 'програмиране']\n",
    "def getPredArray(modelArg):\n",
    "    result = []\n",
    "    \n",
    "    for w in predWords:\n",
    "        result.append(generateText(w,MAX_SEQ_LEN-1, modelArg))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-tract",
   "metadata": {},
   "source": [
    "#### Generate proverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "moderate-performer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "single_bilstm_model_result = getPredArray(single_bilstm_model)\n",
    "single_bilstm_smaller_step_model_result = getPredArray(single_bilstm_smaller_step_model)\n",
    "single_bilstm_larger_step_model_result = getPredArray(single_bilstm_larger_step_model)\n",
    "\n",
    "single_bilstm_more_epochs_model_result = getPredArray(single_bilstm_more_epochs_model)\n",
    "single_bilstm_more_epochs_and_units_model_result = getPredArray(single_bilstm_more_epochs_and_units_model)\n",
    "double_bilstm_more_epochs_and_units_model_result = getPredArray(double_bilstm_more_epochs_and_units_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-direction",
   "metadata": {},
   "source": [
    "#### View generated proverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "large-preview",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Single Bidirectional LSTM layer model 300 epochs 128 units 0.001 LR</th>\n",
       "      <th>Single Bidirectional LSTM layer model 300 epochs 128 units 0.0001 LR</th>\n",
       "      <th>Single Bidirectional LSTM layer model 300 epochs 128 units 0.01 LR</th>\n",
       "      <th>Single Bidirectional LSTM layer model 1000 epochs 128 units 0.001 LR</th>\n",
       "      <th>Single Bidirectional LSTM layer model 1000 epochs 256 units 0.001 LR</th>\n",
       "      <th>Double Bidirectional LSTM layer model 500 epochs 256 units 0.001 LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>голяма</td>\n",
       "      <td>голяма рана заздравява но лоша дума не се забравя хора излезе ли се емоции роднините му а не раче да го отричаш предварително предварително</td>\n",
       "      <td>голяма като теле не ти не яде се се върши работата работата му го неразбран го умреш утре утре утре жени цялото село хваща</td>\n",
       "      <td>голяма работа не става гърбав се става гърбав се става гърбав се става гърбав се става гърбав се става гърбав се става гърбав се</td>\n",
       "      <td>голяма две и две — четири се тегли към гората ще вдигне или преувеличава раче да вникне в положението на другиго на другиго другиго</td>\n",
       "      <td>голяма труд почивката не е сладка сладка за да ти не го хвали в село насред мегдана да не деца жал кой го чернят</td>\n",
       "      <td>голяма лае за да опази не селото а себе си се не се казва се или преувеличава или не раче да вникне в положението</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>кърпиш</td>\n",
       "      <td>кърпиш камъчето няма да яде нищо не го та да се препънеш негодувание възмущение за друг от 30 нагоре го жени цялото село на</td>\n",
       "      <td>кърпиш пъти железни добро не ще ти да ти — прав не ще разбира не го неразбран го умреш село умреш утре утре утре</td>\n",
       "      <td>кърпиш момата тъпан тупа у момчето хабер нямат чорбаджия то са намича търси вълка не се борят цялото пари да се борят предварително другиго</td>\n",
       "      <td>кърпиш рана заздравява но лоша дума не се забравя един в праха насред мегдана или или раче не вникне в положението на другиго другиго</td>\n",
       "      <td>кърпиш магарета през девет земи се подушват през прозореца хабер няма не разбира или не раче да вникне в положението на другиго ще другиго</td>\n",
       "      <td>кърпиш петко празна му торбата трябва да яде яде и сам се да не ти пука да ти пука долния не раче да вникне</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>магаре</td>\n",
       "      <td>магаре от срам не разбира е най много се мислят за по умни един от друг от друг нагоре го жени цялото село другиго</td>\n",
       "      <td>магаре го ти не мъчно не да яде се се самара се го неразбран човек се неразбран човек цялото жени цялото село яде не</td>\n",
       "      <td>магаре мътна вода не гази жаден ходи да пикае става гърбав се жени цялото село трева не разбира или не раче да вникне в</td>\n",
       "      <td>магаре от срам не разбира е по майстора си се плаши ти се мислят да се пазя от друг от всички го за жени</td>\n",
       "      <td>магаре от срам не разбира а на познаеш години а живей така като че ли ще умреш утре през велики кога по висок от</td>\n",
       "      <td>магаре от прякор не умира по горите и скалите а по хората в ръката му парите в положението на всички го червена в другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>жена</td>\n",
       "      <td>жена огън и море да не срещаш по добре не я туряй в нея парите от всички нагоре го жени цялото село село другиго</td>\n",
       "      <td>жена се най кладенец ще става мома добре да живей работата работата от пазя счупим неразбран го умреш утре утре утре жени цялото зиме</td>\n",
       "      <td>жена огън и море глава и калугерка да надробя попара ама кости троши троши сложа да го купим та да пипаш — тежко ти</td>\n",
       "      <td>жена и кокошка синор нямат нямат така вретеното вретеното вретеното много много много зад много зад твоя гръб възмущение за положението на другиго другиго</td>\n",
       "      <td>жена и кокошка синор нямат чорбаджия да го дадеш не се за предварително парите в ръката му не е лош длъжник и несериозно по</td>\n",
       "      <td>жена и съдран калпак лесно се добиват но ще знай видяло не го за опак и неразбран човек го или от хайвера кога другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>мъж</td>\n",
       "      <td>мъж под чехъл тъпан малкият се не чува видяло струва на просещия дават съвсем малко гръб а нещо несъществено несериозно цялото село село другиго</td>\n",
       "      <td>мъж се кон не като котка като дума го дадеш щеше и от 30 30 30 30 30 нагоре го жени цялото село умреш</td>\n",
       "      <td>мъж се да го жени цялото село трева не разбира или не раче да вникне в положението на село трева не разбира или зелена</td>\n",
       "      <td>мъж под чехъл гледай и а у тия си е чиста не е от нея парите в положението несъществено несериозно на положението на другиго</td>\n",
       "      <td>мъж под чехъл — по седенки блъснат по седенки тояга по края тояга ще вдигне и или не раче да вникне в положението на</td>\n",
       "      <td>мъж под чехъл камък що да закачиш е без бълхата години ли оттам големи поразии прави да го счупим не раче да вникне на</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>бълха</td>\n",
       "      <td>бълха в овча кожа пришиват лисича лисича не пасем туряй не не вино не не раче да вникне в положението на село село другиго</td>\n",
       "      <td>бълха се като че го крият познава да ходи по нея не ти не разбира не не разбира не го отричаш предварително село не</td>\n",
       "      <td>бълха не се връща само бой върху бой върху бой върху бой върху бой върху бой върху бой върху бой върху бой върху бой</td>\n",
       "      <td>бълха не е до колене а не мисли не пия не пия а не вино си има нагоре го го за предварително на другиго</td>\n",
       "      <td>бълха излъгват жената а жената — мъжа си има ти и мъжа си ти с кокошките ама става с петлите ходи в старостта ум</td>\n",
       "      <td>бълха е най скъпата покъщнина баща да е съжаляват — тежко ти ти да не ти с нея парите по висок а върху другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>кучето</td>\n",
       "      <td>кучето скача според тоягата виновната котка ще избяга кой кой е прав кой е крив или не раче да вникне в положението на другиго</td>\n",
       "      <td>кучето като език не камък не умира се да ти се колко малко малко малко малко малко малко възмущение не ще разбира не ще</td>\n",
       "      <td>кучето лае за да опази господ слушаше магаретата нямаше да ти е як гърбът жени цялото село или не раче да вникне в другиго</td>\n",
       "      <td>кучето скача според тоягата виновната котка ще избяга кой ще работата той и и или или или за положението от положението на другиго другиго</td>\n",
       "      <td>кучето лае за да опази не селото а себе си е мре ама току здраве да е и в краката ли да ти да</td>\n",
       "      <td>кучето скача според тоягата с пари не се купуват а се за опак и неразбран човек в положението на всички го червена в извара</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>бавно</td>\n",
       "      <td>бавно мъки вижда хурката дор напълни вретеното вретеното най вратата тарикатите цепят да ходиш или не раче да вникне в положението на другиго другиго</td>\n",
       "      <td>бавно ти не ти не никне ти да ти — прав не ще разбира не го неразбран го умреш утре утре утре хиляда развалили</td>\n",
       "      <td>бавно работа не оставяй за утре сто гюрултия ще вдигне предварително го отричаш предварително цялото село предварително раче да е умрял го да другиго</td>\n",
       "      <td>бавно пръчка пиеш вино вино не сто години а живей така като че ли ще умреш утре нагоре го жени цялото село цялото другиго</td>\n",
       "      <td>бавно като режа и все е късо ходи без работа не се за тропане мегдана за към пари един струва с куче от щеш</td>\n",
       "      <td>бавно заек си езика в мозъка тогава акъл давай гащи да е умно — по голямата тояга негодувание твоя гръб и неразбран емоции негодувание</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>работа</td>\n",
       "      <td>работа се учи от що му се случи гърбът в стария ще се пазя един от 30 нагоре го жени цялото село село другиго</td>\n",
       "      <td>работа се ти не мъчно се го намерят я касапин самара се работата от утре жени цялото село умреш село умреш утре меда не</td>\n",
       "      <td>работа си хвали симидите няма да го живеем да го живеем да го отричаш предварително предварително предварително отричаш предварително предварително отричаш предварително предварително другиго</td>\n",
       "      <td>работа се от мал кога остарееш да не ти е жал струва да кой е крив или много е да е хвали за предварително</td>\n",
       "      <td>работа се научил да вдява и надминал майстора си е приятелство ама не е знае как се е въргаляло в праха насред мегдана мегдана</td>\n",
       "      <td>работа при пари отиват да е умрял как се е въргаляло в праха насред мегдана кога друг го или не раче да вникне накрай</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>учи</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал не е когато ти не ти не раче да вникне в положението на</td>\n",
       "      <td>учи се като на бито миришат томува вратът защото се работата му ли го неразбран човек цялото жени цялото село умреш село умреш виното</td>\n",
       "      <td>учи се от мал кога някой да вникне в положението на село да го отричаш предварително го чернят не бързай да го отричаш другиго</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал струва да кой е крив е малко гръб и от две цялото село</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал в праха дават съвсем малко по гръб ще по роднините му по гроб</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал без ръката му парите в 30 нагоре го жени цялото село свършил направя</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>зло</td>\n",
       "      <td>зло не е само за калпак умира и в нея прави пред другите зад твоя гръб несъществено несериозно несъществено несериозно цялото село село другиго</td>\n",
       "      <td>зло се като на свинче звънче вратът защото се пикае живей работата работата го умреш жени го жени цялото село несъществено предварително другиго напред</td>\n",
       "      <td>зло не се насища от 30 нагоре го жени цялото село предварително го жени цялото село предварително го отричаш предварително цялото село предварително другиго</td>\n",
       "      <td>зло не живее само с хляб — вика фефел на тия в друг от твоя гръб гръб в всички гръб ще несериозно на другиго</td>\n",
       "      <td>зло за смях на кокошките ама му е случи сам се върши работата като работи на хорото му го от всички не го жени</td>\n",
       "      <td>зло не бие мъжа си но лесно го надвива което му трябва да ги продаде често да го счупим не раче да мъжа власт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>добро</td>\n",
       "      <td>добро на теб заповядвам а ти на комуто мож' мож' не не а а от 30 нагоре го жени цялото село село село другиго</td>\n",
       "      <td>добро се ти не мъчно се го намерят я касапин самара се работата от утре жени цялото село умреш село умреш село яде не</td>\n",
       "      <td>добро пари за черни дни някой да вникне в положението на 30 нагоре го жени цялото село го жени цялото село предварително бързай другиго</td>\n",
       "      <td>добро лае за да си пази кома̀та нищо да ги продаде не го често утре го го за го цялото село цялото село другиго</td>\n",
       "      <td>добро толкова и море да не срещаш по добре го го играеш му му в опашката един ще ти с лош гръб да съм</td>\n",
       "      <td>добро лозе копа юнак вино пие сляп с едното око да тегли счупим не се крив за нещо несъществено несериозно чернят не бързай да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>котка</td>\n",
       "      <td>котка по гърб не пада — добре не е и и вода не умреш утре или не го чернят да вникне в положението на</td>\n",
       "      <td>котка го всичко по горите не стига нищо не ще ти не ти не разбира не го отричаш предварително село цялото село умреш село</td>\n",
       "      <td>котка не вижда хурката дор напълни вретеното алабаш брюкселско зеле няма да яде гроздето да го отричаш предварително предварително предварително предварително предварително предварително другиго</td>\n",
       "      <td>котка по гърб не пада е пада по баиря и по голямата един от другите от другите зад твоя гръб го малко цялото другиго</td>\n",
       "      <td>котка по гърб не пада по далеч да пада се стига ти да я с 30 нагоре го жени цялото село насред един лъжа</td>\n",
       "      <td>котка по гърб не пада по далеч не стига е без жълтък стиснат сам си върша работата не го или не раче да гнездо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>агнето</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите по гърдите а нещо от 30 нагоре го жени цялото село село село село другиго</td>\n",
       "      <td>агнето го всичко ще яде се да го касапин самара се работата се неразбран го умреш утре утре жени цялото село кради железни започнат</td>\n",
       "      <td>агнето го гледай по гърдите не е трудно се гощава хващат го чернят не бързай да го отричаш предварително предварително отричаш предварително предварително другиго</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите по гърдите а не разбира не разбира или не раче да вникне в положението на</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите мож' по гърдите му по малко един един ще вдигне деца имам кога ще чужда</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите на другите ще сам ще ти е жал гърбът не раче да вникне в положението</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>пешеходец</td>\n",
       "      <td>пешеходец се като ялова крава без две не се хвали обещава или преувеличава преувеличава е крив от 30 нагоре го жени цялото село село</td>\n",
       "      <td>пешеходец като кон се камък не като прошка ти се дадеш касапин самара се от 30 нагоре работата човек цялото жени цялото село умреш</td>\n",
       "      <td>пешеходец му се от сърцето гърне боб да го отричаш предварително го чернят не бързай да го отричаш предварително предварително предварително цялото село предварително</td>\n",
       "      <td>пешеходец се царската дъщеря на работа та й се изприщили ръцете се ръцете да се препънеш от клечка си от смее струва струва два</td>\n",
       "      <td>пешеходец се като ахиевски читак ще се сила — за към гората някой не е или не раче да вникне в положението на другиго</td>\n",
       "      <td>пешеходец заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>програмиране</td>\n",
       "      <td>програмиране се като ялова крава без две не се хвали обещава или преувеличава преувеличава е крив от 30 нагоре го жени цялото село село</td>\n",
       "      <td>програмиране като кон се камък не като прошка ти се дадеш касапин самара се от 30 нагоре работата човек цялото жени цялото село умреш</td>\n",
       "      <td>програмиране му се от сърцето гърне боб да го отричаш предварително го чернят не бързай да го отричаш предварително предварително предварително цялото село предварително</td>\n",
       "      <td>програмиране се царската дъщеря на работа та й се изприщили ръцете се ръцете да се препънеш от клечка си от смее струва струва два</td>\n",
       "      <td>програмиране се като ахиевски читак ще се сила — за към гората някой не е или не раче да вникне в положението на другиго</td>\n",
       "      <td>програмиране заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  \\\n",
       "0         голяма   \n",
       "1         кърпиш   \n",
       "2         магаре   \n",
       "3           жена   \n",
       "4            мъж   \n",
       "5          бълха   \n",
       "6         кучето   \n",
       "7          бавно   \n",
       "8         работа   \n",
       "9            учи   \n",
       "10           зло   \n",
       "11         добро   \n",
       "12         котка   \n",
       "13        агнето   \n",
       "14     пешеходец   \n",
       "15  програмиране   \n",
       "\n",
       "                                                                                      Single Bidirectional LSTM layer model 300 epochs 128 units 0.001 LR  \\\n",
       "0             голяма рана заздравява но лоша дума не се забравя хора излезе ли се емоции роднините му а не раче да го отричаш предварително предварително   \n",
       "1                             кърпиш камъчето няма да яде нищо не го та да се препънеш негодувание възмущение за друг от 30 нагоре го жени цялото село на   \n",
       "2                                      магаре от срам не разбира е най много се мислят за по умни един от друг от друг нагоре го жени цялото село другиго   \n",
       "3                                        жена огън и море да не срещаш по добре не я туряй в нея парите от всички нагоре го жени цялото село село другиго   \n",
       "4        мъж под чехъл тъпан малкият се не чува видяло струва на просещия дават съвсем малко гръб а нещо несъществено несериозно цялото село село другиго   \n",
       "5                              бълха в овча кожа пришиват лисича лисича не пасем туряй не не вино не не раче да вникне в положението на село село другиго   \n",
       "6                          кучето скача според тоягата виновната котка ще избяга кой кой е прав кой е крив или не раче да вникне в положението на другиго   \n",
       "7   бавно мъки вижда хурката дор напълни вретеното вретеното най вратата тарикатите цепят да ходиш или не раче да вникне в положението на другиго другиго   \n",
       "8                                           работа се учи от що му се случи гърбът в стария ще се пазя един от 30 нагоре го жени цялото село село другиго   \n",
       "9                                                      учи се от мал кога остарееш да не ти е жал не е когато ти не ти не раче да вникне в положението на   \n",
       "10        зло не е само за калпак умира и в нея прави пред другите зад твоя гръб несъществено несериозно несъществено несериозно цялото село село другиго   \n",
       "11                                          добро на теб заповядвам а ти на комуто мож' мож' не не а а от 30 нагоре го жени цялото село село село другиго   \n",
       "12                                                  котка по гърб не пада — добре не е и и вода не умреш утре или не го чернят да вникне в положението на   \n",
       "13                              агнето го гледай по опашката а ярето по гърдите по гърдите а нещо от 30 нагоре го жени цялото село село село село другиго   \n",
       "14                   пешеходец се като ялова крава без две не се хвали обещава или преувеличава преувеличава е крив от 30 нагоре го жени цялото село село   \n",
       "15                програмиране се като ялова крава без две не се хвали обещава или преувеличава преувеличава е крив от 30 нагоре го жени цялото село село   \n",
       "\n",
       "                                                                                       Single Bidirectional LSTM layer model 300 epochs 128 units 0.0001 LR  \\\n",
       "0                                голяма като теле не ти не яде се се върши работата работата му го неразбран го умреш утре утре утре жени цялото село хваща   \n",
       "1                                          кърпиш пъти железни добро не ще ти да ти — прав не ще разбира не го неразбран го умреш село умреш утре утре утре   \n",
       "2                                      магаре го ти не мъчно не да яде се се самара се го неразбран човек се неразбран човек цялото жени цялото село яде не   \n",
       "3                     жена се най кладенец ще става мома добре да живей работата работата от пазя счупим неразбран го умреш утре утре утре жени цялото зиме   \n",
       "4                                                     мъж се кон не като котка като дума го дадеш щеше и от 30 30 30 30 30 нагоре го жени цялото село умреш   \n",
       "5                                       бълха се като че го крият познава да ходи по нея не ти не разбира не не разбира не го отричаш предварително село не   \n",
       "6                                   кучето като език не камък не умира се да ти се колко малко малко малко малко малко малко възмущение не ще разбира не ще   \n",
       "7                                            бавно ти не ти не никне ти да ти — прав не ще разбира не го неразбран го умреш утре утре утре хиляда развалили   \n",
       "8                                   работа се ти не мъчно се го намерят я касапин самара се работата от утре жени цялото село умреш село умреш утре меда не   \n",
       "9                     учи се като на бито миришат томува вратът защото се работата му ли го неразбран човек цялото жени цялото село умреш село умреш виното   \n",
       "10  зло се като на свинче звънче вратът защото се пикае живей работата работата го умреш жени го жени цялото село несъществено предварително другиго напред   \n",
       "11                                    добро се ти не мъчно се го намерят я касапин самара се работата от утре жени цялото село умреш село умреш село яде не   \n",
       "12                                котка го всичко по горите не стига нищо не ще ти не ти не разбира не го отричаш предварително село цялото село умреш село   \n",
       "13                      агнето го всичко ще яде се да го касапин самара се работата се неразбран го умреш утре утре жени цялото село кради железни започнат   \n",
       "14                       пешеходец като кон се камък не като прошка ти се дадеш касапин самара се от 30 нагоре работата човек цялото жени цялото село умреш   \n",
       "15                    програмиране като кон се камък не като прошка ти се дадеш касапин самара се от 30 нагоре работата човек цялото жени цялото село умреш   \n",
       "\n",
       "                                                                                                                                    Single Bidirectional LSTM layer model 300 epochs 128 units 0.01 LR  \\\n",
       "0                                                                     голяма работа не става гърбав се става гърбав се става гърбав се става гърбав се става гърбав се става гърбав се става гърбав се   \n",
       "1                                                          кърпиш момата тъпан тупа у момчето хабер нямат чорбаджия то са намича търси вълка не се борят цялото пари да се борят предварително другиго   \n",
       "2                                                                              магаре мътна вода не гази жаден ходи да пикае става гърбав се жени цялото село трева не разбира или не раче да вникне в   \n",
       "3                                                                                  жена огън и море глава и калугерка да надробя попара ама кости троши троши сложа да го купим та да пипаш — тежко ти   \n",
       "4                                                                               мъж се да го жени цялото село трева не разбира или не раче да вникне в положението на село трева не разбира или зелена   \n",
       "5                                                                                 бълха не се връща само бой върху бой върху бой върху бой върху бой върху бой върху бой върху бой върху бой върху бой   \n",
       "6                                                                           кучето лае за да опази господ слушаше магаретата нямаше да ти е як гърбът жени цялото село или не раче да вникне в другиго   \n",
       "7                                                бавно работа не оставяй за утре сто гюрултия ще вдигне предварително го отричаш предварително цялото село предварително раче да е умрял го да другиго   \n",
       "8      работа си хвали симидите няма да го живеем да го живеем да го отричаш предварително предварително предварително отричаш предварително предварително отричаш предварително предварително другиго   \n",
       "9                                                                       учи се от мал кога някой да вникне в положението на село да го отричаш предварително го чернят не бързай да го отричаш другиго   \n",
       "10                                        зло не се насища от 30 нагоре го жени цялото село предварително го жени цялото село предварително го отричаш предварително цялото село предварително другиго   \n",
       "11                                                             добро пари за черни дни някой да вникне в положението на 30 нагоре го жени цялото село го жени цялото село предварително бързай другиго   \n",
       "12  котка не вижда хурката дор напълни вретеното алабаш брюкселско зеле няма да яде гроздето да го отричаш предварително предварително предварително предварително предварително предварително другиго   \n",
       "13                                  агнето го гледай по гърдите не е трудно се гощава хващат го чернят не бързай да го отричаш предварително предварително отричаш предварително предварително другиго   \n",
       "14                              пешеходец му се от сърцето гърне боб да го отричаш предварително го чернят не бързай да го отричаш предварително предварително предварително цялото село предварително   \n",
       "15                           програмиране му се от сърцето гърне боб да го отричаш предварително го чернят не бързай да го отричаш предварително предварително предварително цялото село предварително   \n",
       "\n",
       "                                                                                          Single Bidirectional LSTM layer model 1000 epochs 128 units 0.001 LR  \\\n",
       "0                          голяма две и две — четири се тегли към гората ще вдигне или преувеличава раче да вникне в положението на другиго на другиго другиго   \n",
       "1                        кърпиш рана заздравява но лоша дума не се забравя един в праха насред мегдана или или раче не вникне в положението на другиго другиго   \n",
       "2                                                     магаре от срам не разбира е по майстора си се плаши ти се мислят да се пазя от друг от всички го за жени   \n",
       "3   жена и кокошка синор нямат нямат така вретеното вретеното вретеното много много много зад много зад твоя гръб възмущение за положението на другиго другиго   \n",
       "4                                 мъж под чехъл гледай и а у тия си е чиста не е от нея парите в положението несъществено несериозно на положението на другиго   \n",
       "5                                                      бълха не е до колене а не мисли не пия не пия а не вино си има нагоре го го за предварително на другиго   \n",
       "6                   кучето скача според тоягата виновната котка ще избяга кой ще работата той и и или или или за положението от положението на другиго другиго   \n",
       "7                                    бавно пръчка пиеш вино вино не сто години а живей така като че ли ще умреш утре нагоре го жени цялото село цялото другиго   \n",
       "8                                                   работа се от мал кога остарееш да не ти е жал струва да кой е крив или много е да е хвали за предварително   \n",
       "9                                                            учи се от мал кога остарееш да не ти е жал струва да кой е крив е малко гръб и от две цялото село   \n",
       "10                                                зло не живее само с хляб — вика фефел на тия в друг от твоя гръб гръб в всички гръб ще несериозно на другиго   \n",
       "11                                             добро лае за да си пази кома̀та нищо да ги продаде не го често утре го го за го цялото село цялото село другиго   \n",
       "12                                        котка по гърб не пада е пада по баиря и по голямата един от другите от другите зад твоя гръб го малко цялото другиго   \n",
       "13                                   агнето го гледай по опашката а ярето по гърдите по гърдите а не разбира не разбира или не раче да вникне в положението на   \n",
       "14                             пешеходец се царската дъщеря на работа та й се изприщили ръцете се ръцете да се препънеш от клечка си от смее струва струва два   \n",
       "15                          програмиране се царската дъщеря на работа та й се изприщили ръцете се ръцете да се препънеш от клечка си от смее струва струва два   \n",
       "\n",
       "                                                                          Single Bidirectional LSTM layer model 1000 epochs 256 units 0.001 LR  \\\n",
       "0                             голяма труд почивката не е сладка сладка за да ти не го хвали в село насред мегдана да не деца жал кой го чернят   \n",
       "1   кърпиш магарета през девет земи се подушват през прозореца хабер няма не разбира или не раче да вникне в положението на другиго ще другиго   \n",
       "2                             магаре от срам не разбира а на познаеш години а живей така като че ли ще умреш утре през велики кога по висок от   \n",
       "3                  жена и кокошка синор нямат чорбаджия да го дадеш не се за предварително парите в ръката му не е лош длъжник и несериозно по   \n",
       "4                         мъж под чехъл — по седенки блъснат по седенки тояга по края тояга ще вдигне и или не раче да вникне в положението на   \n",
       "5                             бълха излъгват жената а жената — мъжа си има ти и мъжа си ти с кокошките ама става с петлите ходи в старостта ум   \n",
       "6                                                кучето лае за да опази не селото а себе си е мре ама току здраве да е и в краката ли да ти да   \n",
       "7                                  бавно като режа и все е късо ходи без работа не се за тропане мегдана за към пари един струва с куче от щеш   \n",
       "8               работа се научил да вдява и надминал майстора си е приятелство ама не е знае как се е въргаляло в праха насред мегдана мегдана   \n",
       "9                                     учи се от мал кога остарееш да не ти е жал в праха дават съвсем малко по гръб ще по роднините му по гроб   \n",
       "10                              зло за смях на кокошките ама му е случи сам се върши работата като работи на хорото му го от всички не го жени   \n",
       "11                                       добро толкова и море да не срещаш по добре го го играеш му му в опашката един ще ти с лош гръб да съм   \n",
       "12                                    котка по гърб не пада по далеч да пада се стига ти да я с 30 нагоре го жени цялото село насред един лъжа   \n",
       "13                     агнето го гледай по опашката а ярето по гърдите мож' по гърдите му по малко един един ще вдигне деца имам кога ще чужда   \n",
       "14                       пешеходец се като ахиевски читак ще се сила — за към гората някой не е или не раче да вникне в положението на другиго   \n",
       "15                    програмиране се като ахиевски читак ще се сила — за към гората някой не е или не раче да вникне в положението на другиго   \n",
       "\n",
       "                                                                           Double Bidirectional LSTM layer model 500 epochs 256 units 0.001 LR  \n",
       "0                            голяма лае за да опази не селото а себе си се не се казва се или преувеличава или не раче да вникне в положението  \n",
       "1                                  кърпиш петко празна му торбата трябва да яде яде и сам се да не ти пука да ти пука долния не раче да вникне  \n",
       "2                    магаре от прякор не умира по горите и скалите а по хората в ръката му парите в положението на всички го червена в другиго  \n",
       "3                       жена и съдран калпак лесно се добиват но ще знай видяло не го за опак и неразбран човек го или от хайвера кога другиго  \n",
       "4                       мъж под чехъл камък що да закачиш е без бълхата години ли оттам големи поразии прави да го счупим не раче да вникне на  \n",
       "5                               бълха е най скъпата покъщнина баща да е съжаляват — тежко ти ти да не ти с нея парите по висок а върху другиго  \n",
       "6                  кучето скача според тоягата с пари не се купуват а се за опак и неразбран човек в положението на всички го червена в извара  \n",
       "7       бавно заек си езика в мозъка тогава акъл давай гащи да е умно — по голямата тояга негодувание твоя гръб и неразбран емоции негодувание  \n",
       "8                        работа при пари отиват да е умрял как се е въргаляло в праха насред мегдана кога друг го или не раче да вникне накрай  \n",
       "9                              учи се от мал кога остарееш да не ти е жал без ръката му парите в 30 нагоре го жени цялото село свършил направя  \n",
       "10                               зло не бие мъжа си но лесно го надвива което му трябва да ги продаде често да го счупим не раче да мъжа власт  \n",
       "11              добро лозе копа юнак вино пие сляп с едното око да тегли счупим не се крив за нещо несъществено несериозно чернят не бързай да  \n",
       "12                              котка по гърб не пада по далеч не стига е без жълтък стиснат сам си върша работата не го или не раче да гнездо  \n",
       "13                        агнето го гледай по опашката а ярето по гърдите на другите ще сам ще ти е жал гърбът не раче да вникне в положението  \n",
       "14     пешеходец заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго  \n",
       "15  програмиране заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDf = pd.DataFrame(index = predWords) \n",
    "resultDf.index.name = 'Word'\n",
    "resultDf['Word']=resultDf.index\n",
    "resultDf = resultDf.reset_index(drop=True)\n",
    "resultDf['Single Bidirectional LSTM layer model 300 epochs 128 units 0.001 LR'] = single_bilstm_model_result\n",
    "resultDf['Single Bidirectional LSTM layer model 300 epochs 128 units 0.0001 LR'] = single_bilstm_smaller_step_model_result\n",
    "resultDf['Single Bidirectional LSTM layer model 300 epochs 128 units 0.01 LR'] = single_bilstm_larger_step_model_result\n",
    "resultDf['Single Bidirectional LSTM layer model 1000 epochs 128 units 0.001 LR'] = single_bilstm_more_epochs_model_result\n",
    "resultDf['Single Bidirectional LSTM layer model 1000 epochs 256 units 0.001 LR'] = single_bilstm_more_epochs_and_units_model_result\n",
    "resultDf['Double Bidirectional LSTM layer model 500 epochs 256 units 0.001 LR'] = double_bilstm_more_epochs_and_units_model_result\n",
    "resultDf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-sunday",
   "metadata": {},
   "source": [
    "We can see that some outputs make some sense (sort of), however we probably need more data in order to further improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-crossing",
   "metadata": {},
   "source": [
    "I went through the generated proverbs and picked a winner based on the one that made the most sense to me. You can view the results below."
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAHcCAYAAADIs1JOAAAgAElEQVR4Aeydi3E0u5F0rwuy4XdBPqwJsmFdkAfrgTzYWANkgRxYB9YD+aA/ztw+vPmV0I8hOcNXIoJEA/XKSvQAxeZw+Nu/2spAGSgDZaAMlIEyUAbKwBdn4Lcvjr/wy0AZKANloAyUgTJQBsrAv1rU9iYoA2WgDJSBMlAGykAZ+PIM/Pbbb7/9q1/loPdA74HeA70Heg/0Hug90Hvgi98DfVj75X80aQJloAx8agY4JNrKQBkoA2XgcQxsxXg328dRXM9loAyUgX/dfhtWHspAGSgDZeBxDLSofRy39VwGykAZeGGgT2pfqOhFGSgDZeAhDLSofQitdVoGykAZ+JWBFrW/8tFRGSgDZeC9GWhR+96M1l8ZKANlYMFAi9oFKZ0qA2WgDLwjAy1q35HMuioDZaAM7DHQonaPmc6XgTJQBt6HgRa178NjvZSBMlAGDhloUXtIz6uE//Ef/3H7A7w//elPd9n/7//+78vHWP7Xf/3XXbZVLgNl4PMy8COLWjZAEv/zn//8eVemyMpAGfhWDHxkUfuPf/zjX+57f/nLX74Fr1mY/ud//ufdOcnH//t//+9u2xqUgTLwORm4XNT+7W9/e/nJdm9TZH5z+K+//vWvy4xTh03pI5oYP/KQ+Yi8G7MMlIGPY+DKfvOofZankd9t36OQNae///3vdy/sW+3vDliDMlAGHs7Atiecf04tP+m7gez9qkc5/RWdh2e3EyBx7qh0ugyUgTLwrgyw75y1R+2z+aR274HDGbbPJvdJ6xVeV9gphD0LXvOkd+Wzc2WgDHwsA9tr+nyzBaYbAP18ypqbsXpTJ39dxHuhPqqJj76tDJSBMvAMBq7uN7k/zT30K+2zj+T0vc4Sue5bEB65WvVdBp7HwPaavlbc+aZ8jP77v//7F5Tz11vo8Ku0bPmrtY98c74bGX1bGSgDZeAZDFzdb77LPvtITvO8ectZklz/3//93yMh13cZKANPYGCr764Vd1mUzl/X5OZg0Tjfe3v0flp+8sZn/kqJn575Vdk///nPX6gQB7rIfG8U49yY+PUSfwwmHvSQO6ZvKwNloAw8g4Gr+437G/rvtc/mk83cl3Oe67lnost8Nvdxevdf92327L0ik7137vHsz/MBycSEP/373lkxwBFPr2fDZ+79XK9weXbgR9/TV8dloAx8HQZ4Lf/GtystN5v565rN0UuByZiNKBs2q3k2IO1XPX5yY2VzUi83Lubc4PZ8ujlqn/h6XQbKQBl4FAPsOVfaI/bZfNsCDyBsOT/3UvdI9sx8WOADDPbzuZ9qM9+3S057uthk8X6EycJUDNi655tTng/isT/S1bd+2peBMvD1GNhe69c2W9LLjcmNLjchisnccCxG8wkpP2Xbch7fbjo+AXAzyo34bNPCNnGCicZP4jmP77YyUAbKwDMYuGe/yX3qPfbZ3KNzL8158LE3E489NIvcLPhyfwen++t8kJCc5gMN93jiZAzPionJM4BeHDmXcbiWO2Imd+A2tjb5VHwW4uq0LwNl4OswsO0N14u7/LWPv67JIpNNJMdsGrTc8Jxjno3EDcoNS/pmceoGlf5zU3VTzFhZQOMXzMajbysDZaAMPIOBe/ab995ns1DcK2opMLPlXpk2WdR6BmiXRaoFZO7Hc49PXMpyDs6Y5yxg/6enHe3hyihq1Rff7DNW5jj1Oi4DZeBrMLC9/q8Xd7lB+ZOtmxybCC03CovKLF4tTtHVFiDYzbaSZ1HrRph2Z3I3Pfq2MlAGysAzGLhnv3nvfTb35Cze9ubhY0+22pPlbyXL/Tj33nntWxD24hqDPm1znuvEgB5+Z/GtzZVY6rYvA2Xg8zOw7Q3XizsKUjcUf7J37KZE2v4KiJ7mT/AWvlKTGxAbzGwreW6Sq6I2C+iVXLz0bWWgDJSBZzBwz37z3vvsXvG2Nw8fe7LVnix/K1nu17n3zmt/g7cX1xj0aZvzXPN0NnGoyxk0n9xeiTX9d1wGysDnZWB7vd9X3FGYulHkr6h4umDLX5/lxpGFL7q5+aA320qem+SqaD2Ti52+rQyUgTLwDAbu3W/ec5/NPZg91bY3j3xPttqT9beSne3H2trvxVVOf2UP5+1oPODwAQs28/zpe2qT1V6Xga/PwLY33FfcsTG4qfgElnG+rSA3iyxws/CFvpT5k7q08lO1cehtZ5tkxp6bWP5aL33qu30ZKANl4BEM3LvfvOc+u1co7s2T/55sVbjK10p2tB9rl/1e3NRZxUl5XlPceo7420XlZ2eJeu3LQBn4Ggxsr/U/CsYrsGdhiJP5toLcSNxQ6I9+/cNP1GxoNArkLHh9/y6ys40of3VHTN9PlZurmK7kW50yUAbKwFsZYM+5pz1qn6UgtB0VkHuyo4JyJZv7Mfuw5wAy9nPfpgauvbhips+zwf1dOWcR3Bkjf5uYuaOfPzhMP/prXwbKwNdhYKvt7tts5xNUnMwnolCQv/ZBZ/6ULE25sWyAXn6y1s4NCpuzohadfF9t+gRT/lpPDO3LQBkoA49kgH3onvae++xeobg3D8492apwNa892apAz305udmLawz6ozNg+s0xvrPlbxr99JyU97oMlIGvxcD2er9vsyXF/EkZJ6ufcmdhyU/oe41Nb/pkg2R+tnzieuQTmQUsxSzFM08GLKLn0+UZp+MyUAbKwHsxwD55b5t74mv32fzNGT5te/PI92SJaRaCRzIKSuT5sIOi0n35CqaVznz6CkdZXBOPuLOgzR8a0GkrA2Xg6zPw6qL266feDMpAGSgDz2PgNUXt89B9vUhZHOdv8q5mQvG7HYDL3zRe9VO9MlAGPg8DLWo/z1oUSRkoA9+YgRa177u4/sYNXle/0TuLlvarJ+Bn9pWXgTLw+RhoUfv51qSIykAZ+IYMtKh930Xde3vElSg82fVJb9+GdoWx6pSBr8FAi9qvsU5FWQbKwBdnoEXt+y+g75299z2xWRC/5inv+2dSj2WgDLwHAy1q34PF+igDZaAMnDDQovaEoIrLQBkoA29k4KWo3S5e3jjf8W/l4rdy0NdB74HeA70Heg/0Hug98KXugfs/auaNxXTNy0AZKAM/igEOxbYyUAbKQBl4HAPbDx/dbB9HcT2XgTJQBv51+81PeSgDZaAMlIHHMdCi9nHc1nMZKANl4IWBq09qt035l7c/vfdf6POPCIjDx1qtmv/adv5jg5XunOMPr1Y5MIdfm/8Yx/Hs0Tfvt+CZfq+Mnx3viAv/e9rZH7SpJ/eMaa6187MnV//gDln+k4pcy717Rdtc2yscfzWde++JM17yI+Vck+TEubkm6KTt3rqkr4+4Psv/UZg23vqk9lEE128ZKANlAAbYbK809Czm1F/NKXtNb6GzdyDee4AnBgshiyplM4ejQg6b1H8LHuOf9eC1cHxGvMRzxIXFqtjSzmvXUx2LnixQ0d3zZQEC57lu+mF+717RFs6+c7v3njjjhTVHZ9VS5hqo5xqCZ667Op+hP8v/URi5V3/jW1sZKANloAw8joGr+yx6HGrZLBQtWlL2mmsPw71C5d4DPDGINYsj5B5yqXt0veLhSP8tMguF9+L3XixvLWrFP4vYiUO9madrA46898TFWuzdK9q2qP2V7SNefH2tOFXm68fXqmuG37lGzH22dpT/I7Fyr14uajfl20/QXEu6m5hyyQe4C6TMfi6K8/YutgvKfL5ofLGpRyzn9JH6jySxvstAGSgDZwywL11p6OX+iI37aB5euTdi436Mvnuyc+q6X+bY/TLxreJ5SK3wZV4ztjLsEr/7tXLt0AN3xpl41BWTfrXDlq95BhgzfetLG3zNeGCUM/XkNmXwmzHMjR6ZtvTEtWnjOHtzSv2Uc60OfsG519SbvuRRjOSfHODXe2f61lauJ5/aGTvx4ZfcbcZnnq9s6sqV8dQx7vThvPbq0x+tKXIxY+u19xry9I1O5jZ5ybjTDlvzUUZPEyPxaegmBvhIDm9K8U2+pp1+J19hervEzq+Mi9B7RLlrjcz8M745rGyPcrgBufhtw/LrzbNni/IM7EK7AC6I4E06yUg/Uz+JBodjbKZP5iTRhRE7sozpfPsyUAbKwEcwwJ50paE391nsck872zfP5Lmv4tt92riO3UPdX5mfWG4T8c3Y4J1f2qNOLOQ08RhPH3t4lKuPD+foacj0zxhf+mOMTPt5js389e0ZJF7PH8f6V1+5Y/T2sCXWm9L2bWJLWV5j75c4Us71ni+5Eie919qYy/SpLZzJmzxpS97K9CNnK11irNaL/PCzauKdayoXyo03x+IRn3LH5qJ/9fWHXuJLXiZedfFBAyO2NOPS04wjDvTEgDxtbwbxTQxM7fFvXOX6nmN8oCufysUlTvkwtnk4xo7mmGtt9XVTeOU3MN71pNaEjMf4aM7EJQq7JMYFlIiZnOO08eZibpIgUakv1vZloAyUgY9igD3pStvbu5h3H3WfS385d3Vfzf1Te/bsuW9nbGJix5wHVOKYsZVxTmDDnk5zzLV7ugcgc+h6tkw8qxjivzkfxYHniOeMOvYz/ow3fWOXc/qXT+0dzzjklvwlF+raT2zOr3r96F+u1d3zZS6J2zWeuenLPm2d00Ycriv4XFP9E5OWMsZiNQd8aWuc7Oc9Mcdiwi9N3Okj58RnfLlBh6Zc/Hv+lWeceZ25ilvO9Es8GjyIgTGcMDebeLVDnvlNvynHNjHpO+fyWnn2xjL/yZe4wa5O2r/2Gn9vKmpxMG80wQJKYnMRpo3Jb2BuC+RCSLw6jPEvQerN8YzxWoJqVwbKQBl4DwbYk6601d4199HcY/XpHomuByMHD8191P3SsXJ03EOxn/Fyb85r9GabsZU772GdOawOyORh4tFX4jf/xMc1uit9cdEbX2wzXmLVznjoyqf8Tnvj44eWtoxX/o0zsTm/1xub3MWj7p6vxMO1eLCfuenLPm0zNtcznmN8EkM+8GXMuX7o0phPfePbyzExaHM88zCe9vSZS74ekJkbOjTlE6/x09fN4OCbvIBZ3PQ0ceuXeGJATh4rXsQ78TFe+WXOnLD1Wv6RJ86V/OZ4+zbzn/rmlfjMOf3ce735e/1muyI05yQ2F4GguQgSRW+iEEBz7EJLlPPq4fMoxr3EVL8MlIEy8J4MsEddaXN/xMb9zk3ffTD95Zz7pQeh9u6Xc4wf7dmz574999eMO69nbOXOmwNngJx4BijDJnmYePRlfuiL33jZr/JNuf6MP+OtfOfc9H9mry16tOQicXG94mbqzLHxXW/le74SjzrwDx8zN33Zr2yxoelrxSv+kduybnAu+7wfct5r11CfczzzELf29DkHd8Q0FzlFh6bcNUw/6WtPnvryRCxxzjzkcPIERjGlT/HOe0Ad46Tc/LFNTNrknNfiUsc+fTEnX/KpXsrI5a0NH296UjsT80Yy0RWxBGVhaModT6Id409S1MWPC7IlcvMpBvXeSlLty0AZKANvZYA96krL/VF99rLcz9zj2H9p7pNz7P7o3ulYfTG5D3s4zrH22NFWGG+CxRMy5+chRz578c3PnCce5eZLjDl3FG/moC097Sye/BnfsfxOe7Ggp4zcuaYlF7eJ+EYMdMUWopdL/etv5qPinq+0NxfxOTY3fdmnrf7lxbwSu/r4x7dNW3W1VY6+94Nz2Zuzsed45rEn137qiw/8tCmfrxHzdE0SqzLzJ6/MjWvj6Fd7ceBXDHKmjr1x0OULDvWrLXO0KZ9jdNJ+yvXnfZKxsTUPc57rOTm4gXrFN/y+qaglpjfH5uzlxZfzJoJ+JmPiyicxjvHltaThx+uM5Tw9xLeVgTJQBj6aAfajKw29+ZUHnj7cD9X1MFbu3orcg9D9UlsPGn1oOw8s5tMf+ntt7sX6pieujZzST9qJy7wnHnVnzuZpzIxHXGMqFwu9c+Q54yGXM/UytjL5nfaOtTU/8qCJ6zYY32ZO+qDPpg/liU89fRnXedcWnDR8yP3MTRv7aZs4zFNesHHt9K8fevXNQTzIElPaeK1f857jVR7OGU9bfcoXcrGRr80Y2jO2TV6ct0+eVlzokx6c2cQirpTN67045o4vdc5wZO7Emfd1ymf+Ys5cMkeuc71nHlfHm89fXxxXjatXBspAGSgD1xhgs20rAz+dAQvBWUD+dF6enX8Wtc+O/ch4LWofyW59l4EyUAY2BlrU9lYoA3888c8nduXl+Qy0qH0+541YBspAGfg2DLSo/TZL2URewUD+qppfRbd9LAMtaj+W/0YvA2WgDHxpBlrUfunlK/gyUAa+AAN9+8EXWKRCLANl4Osz0KL2669hMygDZeBzM9Ci9nOvT9GVgTLwTRi4WtT6V8Lb5vzyaTLS4F8qK8+/OEbHefr8a2zt36vH/+qvpV/rP/M6w32km3+xPrkRmxwf/bX1WX7Jc16fYRdD+zJQBt6fge212L/KfX9q67EMlIEy8AcDbLZnbf5luGP/qMb3Je795TgxfL/i/Eids9j3yomVRS1Y93Cd+QarvixK9wrOI93ka4+rLIj3YoB35jdzWMktll2vadNxGSgDj2WA1+Xlz6l9LJR6LwNloAx8XwbYbO9t8485LNroZ1P2EQWVsV9b1MKNxfheMWq+R7oWlepmAaxf7C1s37uofSsP4m5fBsrA6xjg9d2i9nXc1aoMlIEycJkBNtt7m08tLfgs2raN++XpJn6VHRVqxp/FsgUfRSAtx8wZL30zR3GoL3V84mqB57w5iMFeewtiY6/0z3SJbXz8i92clDmf+YjH3vwcz34lN2dzmTYdl4Ey8FgGtv3m/s32sbDqvQyUgTLwvRhgs72nWcBhR7FEoyjTj8WfhahFrQUbevhYNX1bOE5fjo2lvrHwicwicVXMIVff4tw8EpO+LQSNre09uuARE3Zygc9se/Opk/nlvNcr+RW/2rcvA2Xg/Rngddknte/Paz2WgTJQBn5hgM32arOwWxVO6cMiijmLWovDlKUN1xaSZ0UtPmxgmWMLyFnUXsWfWMStbcYSg7j3dJ9d1G4H6MuTbMazgBZ7+zJQBh7PwPaavL7ZPh5SI5SBMlAGvh8DbLZXWxZLR0WShSs6FrXqU/jh5+jp6L1FrUUseeDb8SxqkRv/LJe9QlVsydmZ7l5Rmz64Tt6mzHHm51z2KTd/+Ui9XpeBMvA8Brb95vpm+zxojVQGykAZ+D4MsNleaRZc6FPEHTV10bGw+oiidhabEzPFHvmAdzbwIrOIPfJ1ppt8EGcWucZWT66czx5MR0XqlPtDxSrH9NvrMlAGHscAr8u+/eBx/NZzGSgDZeDGAJvtWbMwRZfr2bYN+zY9CzwmkVscWrhNH4y1tQDzqarjKdd3FnnEcjwLUcdi0Z/jiYm4+hILNjSLRXzSjnTlD11j4m82fIDfGFPOOPO7KseGr9XarXx0rgyUgfdlYHsNnm+27xu23spAGSgDP4sBNtuzZgFncWRvMWihNuf1O+VHRVvGspB8bVFLfIpScFmcWtiK1Xmxzl579LMoFKdFbcaausjMBZn5zFhXi1qxZ2+RzNzMyaIaWVsZKAPPZ2B7rfYF+HzqG7EMlIGfxEALnZ+02s21DJSBj2CgRe1HsN6YZaAM/DgGWtT+uCVvwmWgDDyZgRa1Tya84cpAGfiZDLSo/Znr3qzLQBl4HgMtap/HdSOVgTLwgxloUfuDF7+pl4Ey8BQGXora7eL2Rv9e//4XrOWhPPQe6D3Qe6D3QO+B3gO9B77UPdA/FHvKjxANUgbKwI9lgEOxrQyUgTJQBh7HwPbDRzfbx1Fcz2WgDJSB3z/3tDyUgTJQBsrA4xhoUfs4buu5DJSBMvDCwD1PaufnzebnoSrb+wzWl4AXL/w8WT8L96LZTS0/E3Y7TF7ewpZ+kGUOKZv5vAVP+r16/ex4R1ysPpN3lYd6cu7n+h6th/zTa5efY5y2fhbvjK3tnP9u43vviau8wPt83RrLNZlc6hu566xOrtn0q85H92Kc2B+Fa+OxT2ofRXD9loEyUAZggM32auMg85Dy0LPonEXgVZ97etP/nt5qfnVgrfCROzmt2tR/C56V/9UcXBKH9ox4ieGIC4tVsaWd1/6DB3W4T/CZBSq6e/N7RZL6+GpR+48bp77m5H6vl9M9ufcY3Pq6Rtd7X77zdY8cXV83vtZc57wPpp89HB8xL+4WtR/BfmOWgTJQBh7EAAfaleYBdfVAveLzSMcD9zXx9g4sDmIP46PYyMw3D/szm7fIrxSOb/F/Zst9sMfNFWzqWNzsxbNInXrEFkNyzpxfFlnTt7Zz/ruN731NHPHia0Sd5DwLUzhU1zVjPXxd+jpxbbwP5B6/xPhszZw+ZVHrCwHSJJTFd7F8Qbggk1xfZNqi7wKlT/3YEyPljvUnWZM87F3kKZvYOi4DZaAMPJIB9qMrzcMLfQ+0tFPu4ejeZo+dMu1yz/Va36sDPPf06Uuf9MZ0D2ZOfPpnLvfitGNeH8aZeFKenJgHc3zN5jy9vvWlDB8zHn4sNtTL/PRhn/7FQDxt6T2zkDP2XFLf3pxSX5m9OvjZO2vRFcPUcW31g64caENuq6atMn2Yqzw5b2zvCdcBe2NNPlJXv8azl3vj6MN5xhkLu6M1RZ6+9MOczTkxmRvyyYs29NjxlXkpN6a+jMF6uCbM0bQXEzH5ssmn49kbS/wplz99MJ73oDmqm/Zc78nNKeVzbVKGf/mYMa6Msf+Nb1eayUjuDCwhc17fyl0kSZa8e8Z5g/pCkjzH4iX+lImpfRkoA2XgGQxc3WfB4l6IDV/ukcjcfz0Y3NuwSVv3QffKue+q7+Hp2H06Yym7BYhvxhZn9qH2SyEnHn3qw3wmHuXq49c5eeFQ5MsGDv3Jl/b0yelevD3+jD39qa/cc3CFLbGKmX5iS5nX5iPX5qnc3nUUh/PExtZ1IH8xZ69+9toyl/aMjce1nOIvdeXIPMW2Wi/m9po45xrIhXLjzbHYxafcsfj0r77+MlcwJi97mF03MaJnHHkQB3Emh9OemHzZxKQv5+n1i0/atPVeSnnyz3XG4jrlK3/maWy5dCyXjo09Y2UeV66xv7uoBUQmaKAjUtGZchfNZF1gkzsaSyoJTHIcJzkSp0zM7ctAGSgDz2CA/eie5p61bdK3AxD7ebip595Gn/vi2b6b+7C+3ZOJp/0K+4ytjpg9YBl7Zsx93ZjEoSUexqsY8xBVB9uZv5jsZ/wZb/rGLueMtcf3jCMXzicXztlPbM6vev3ay7W6rtucJxds5J180GVe7phbNW1TJh8TB2PXVCzapYw58waTuLTVJntjugZzbB7Kc/30k3Pik6t5TyjXduWfnI7aKq/MG9vMQwzM0aZ94kcuRnO4GW3fpq5xiEEDOzo25eQ5c0Un5yZOfdinr2nLWA7AgN+3NvzcVdRuBr88ORCEpKpDn0QpV99FIimayUn03lg/yiVikpfxp0wM7ctAGSgDz2CA/eg1zf1Oe/dN5mlzb/PAYZ6m/W2wKBo9lNhP9U2s+aV99jO2Mufdy/HlWeC+7eFrTPNJPPjTl/s8c/ia+Bhju9IXF73xxTbjJVbtjMd4+p98KzeftMV+5d84E5vze73Y8UncbK67PCtLPFw7xn7moo29uozVZY4245nLXF90wbv6QnelfwsQ3+TYe2KOxSYnK84zF7EbQl7JgaZ8YjZ++tLH7Fd5JUfomwfxxWAO2ouJmHKfGGdcxuKb+IlBY54cbfJHLyZzRUc5srzWPvtpv9KfuMwx/Vy93nxd22xRhhxBSYjBXHjIp6nnoky5i2YCLrB+98bgQDbJmmPxgmXKxNy+DJSBMvAMBtiPXtvcO7H3cPMQmnvbvftu7sP6dk8+wztjq++8e3nuxXNfN6b5JB786Yu8bPNAd55+5p8yrvUnthlv5TvntBfPjJe6xGOca59cTGyTmylfjcUPrmzeM57HyhKP8cCEn5mLNvZpq39ljo0nLuflC33iMb9q835Y6cw1mOOZx1wTfOacGCd2XwfKV1j0lWu80lvlJW64orke6KovBvl0nSemzGfGP5KhO+9JccGjXOb65Zy4xDljpy9k2ppH6ivzfkzZ1Wts73pSCzk0DOdNKcneGAIUvHLHLuBc0LMxsWmTrDlGT7xTdnPQb2WgDJSBJzHgvnUWbu6b6Od+62Hn/jv3tmk/x+7DHkLzUFKeB6uxJvYZWzn7buabe/GMpw9j7MnJw6aNc0fx9vjynDmLJ3/GmrGVM08TC3H1vceF+djPM9H57PXvnHjMx/lcR+fo017s4nNsLmk3bfVPXDnGD9c2Y835mSdydGn68n7QV/bmfHVNpr55au/YvMXna2TKzd1czTMxzutVXs4ZFz+ZN9fyYg7GFFPyr58ZW1vznXjhny/voZVcHPjmeo6xt+V6ztjiFuvkUu7NU59X+y2XP8AcGSZQA0sCdoLbnN5I4tqm3CSRSTI60+feWDL0ow/HM36O1RVT+zJQBsrAMxjIvfAs3tzL8gDxIGQ/panr3kZPLOZt7qXMe62cPdx59YnHHF8ZW7m9sdXNPg+l6SftxGM+E4+65mds7YyZ8dBxfsaWP+bxMeNhK4f6yNgTj7rM0/SnrTiZp008t8ntm7ra2s81cN4+8enP83by4tqiJxdyP3PRl/3KVgxiTyxypX/90ItPe2UTk/PZ69dYc7zKwznjaatf8SP3mt5mDO1dT+TJi/qz38tr3i/TTt/EnZgT04rj9GVO4s/7gjnipE7K8ZM4uJ4t5fiziVHsrgPztnkvqKv8nn7L7w8A9xjfqyvwSda9fqpfBspAGfhqDORG/5HYPUTzUPlIPI39fRmYBc33zfRrZ2ZR+7Wz+B19i9rvsIrNoQyUgU/PwEcVtRYWPnVynE+aPj15BfglGfDpXR9kfe7la1H7yvXpk9pXElezMlAGvjwDH1XUQpzFxfYU45e3Jnx5YpvAp2PA3wZwv/U3ApbaZHcAACAASURBVJ9uef4NUIvaf6OkE2WgDJSBMnDEwEcWtUe4KisDZaAMfBcGth/cn/Oe2u9CWvMoA2WgDNzLQIvaexmrfhkoA2XgPgZa1N7HV7XLQBkoA69i4GpRm3+BjM38S+D5VoL5V8/bpn77K/tp+yrgO0bEAct7tczrDPeRru8ZBt/kRqxyfPRez7P8kue8PsMuhvZloAy8PwPba7FPat+f2nosA2WgDPzBAJvtWaMgQs/3ITr2j7oowlI+/SHzD8Ie/TcMxMqiFqzinrjOxmDVl0XpXsF5pJt87XGVBfFeDPDO/GYOK7nFsus1bTouA2XgsQzwurz8zxceC6Xey0AZKAPflwE223ubf3BjoWrRRj+bso8oqIz92qIWbsxxrxg13yNdi0p1swDWL/YWtu9d1L6VB3G3LwNl4HUM8PpuUfs67mpVBspAGbjMAJvtvc2nlhZ8Fm3bxv3ydBO/yo4KNePPYtmCjyKQlmPmjJe+maM41Jc6PnG1wHPeHMRgr70FsbFX+me6xDY+/sVuTsqcz3zEY29+jme/kpuzuUybjstAGXgsA9t+c/9m+1hY9V4GykAZ+F4MsNne0yzgsKNYolGU6cfiz0LUotaCDT18rJq+LRynL8fGUt9Y+ERmkbgq5pCrb3FuHolJ3xaCxtb2Hl3wiAk7ucBntr351Mn8ct7rlfyKX+3bl4Ey8P4M8Lrsk9r357Uey0AZKAO/MMBme7VZ2K0Kp/RhEcWcRa3FYcrShmsLybOiFh82sMyxBeQsaq/iTyzi1jZjiUHce7rPLmq3A/TlSTbjWUCLvX0ZKAOPZ2B7TV7fbB8PqRHKQBkoA9+PATbbqy2LpaMiycIVHYta9Sn88HP0dPTeotYiljzw7XgWtciNf5bLXqEqtuTsTHevqE0fXCdvU+Y483Mu+5Sbv3ykXq/LQBl4HgPbfnN9s30etEYqA2WgDHwfBthsrzQLLvQp4o6auuhYWH1EUTuLzYmZYo98wDsbeJFZxB75OtNNPogzi1xjqydXzmcPpqMidcr9oWKVY/rtdRkoA49jgNdl337wOH7ruQyUgTJwY4DN9qxZmKLL9Wzbhn2bngUek8gtDi3cpg/G2lqA+VTV8ZTrO4s8YjmehahjsejP8cREXH2JBRuaxSI+aUe68oeuMfE3Gz7Ab4wpZ5z5XZVjw9dq7VY+OlcGysD7MrC9Bs832/cNW29loAyUgZ/FAJvtWbOAsziytxi0UJvz+p3yo6ItY1lIvraoJT5FKbgsTi1sxeq8WGevPfpZFIrTojZjTV1k5oLMfGasq0Wt2LO3SGZu5mRRjaytDJSB5zOwvVb7Anw+9Y1YBsrAT2Kghc5PWu3mWgbKwEcw0KL2I1hvzDJQBn4cAy1qf9ySN+EyUAaezECL2icT3nBloAz8TAZa1P7MdW/WZaAMPI+Bl6J2u7i9J6rXv7/ZvzyUh94DvQd6D/Qe6D3Qe6D3wJe6B/qe2uf9HNFIZaAM/EQGOBTbykAZKANl4HEMbD98dLN9HMX1XAbKQBn4/SOiykMZKANloAw8joEWtY/jtp7LQBkoAy8MXH1Su23Kv7wVbH501IvTV174cVt+VNh040eD7X0k1tTPcX6s1cwlP2LMj/BK27zG1rzfgid9Xr1+drwjLvyIsvyYs1Ue6sm5Hz3mWjs/e3L1I86Q5Uen5Vru3Sva5tqu8H31uXvviTNe/Ki6XI/kKOdzTdBJ2711SV8fcX2W/6Mwbbz1Se2jCK7fMlAGygAMsNleaehZzKm/mlP2mt5CZ+9AvPcATwwWQhZVymYOR4UcNqn/FjzGP+vBa+H4jHiJ54gLi1WxpZ3Xrqc6Fj2zGNrzZQEC57lu+mF+717RFs6+c7v3njjjhTVHZ9VS5hqo5xqCZ667Op+hP8v/URi5V/sfxR7Fbv2WgTJQBjYG2GyvNPQ41LJZKFq0pOw11x6Ge4XKvQd4YhBrFkfIPeRS9+h6xcOR/ltkFgrvxe+9WN5a1Ip/FrETh3ozT9cGHHnviYu12LtXtG1R+yvbR7z4+lpxqszXj69V1wy/c42Y+2ztKP9HYuVevVzUbsovP80CzJ8ikmTnVvr5IskXypENethJEuN88XoTGM+b4ZHE1XcZKANl4B4G2J+uNPe71HWPy8PLw261783CUl0P0Rxrn/hW8XL/zf0+cXI9YyvHf+L3LFCuHXoWX8aZeNQVk361MyfsshkTub71pQ2+Zjx8yJl6ec4og9+MkbGPzjhtUt9rcwLnXlMHbGDZa+pNX/IoRvJPDvDrvTN9ayvXk0/tjJ348Os64Nf4cpyx1JUr46lj3OnDee3Vp3fdjAfGbGJG7rX3GnrpG53MbfKSfqcdtuajjJ4mRrGhmxjgIznMOFzL17TT7+Rr2mPnV8ZFz3tEuWuNzPwzvjmsbI9ymJiOxhuW65stBpmYgAXkgri4JiYI9R3Tn9lImD6nj8SkL2+IjNPrMlAGysBHMcA+daWh536a+qt9zkMiDyhs3Af35OqLycPJuI7d6z34PHgTS2LM2OjML+3Ry31cPMYT/x4e5epnXPf+1dmjP/QzB3hirO3M33hnfOpffQ95x55hK2zEX7WJbaVjPvItjqm750s84qT3WhtzmT61hTN5kydtyVuZflzzlS4xyCHzMDf8rJp4wUMztj6UG2+OxSM+5Y71p3/19YceGMWXvEy86uKDBkbX37j0NOOIAz0xTNubQXwTA1N7/BtXub7nGB/oyqdycYlTPoxtHo6xoznmWlt93RRe+Q2Mdz+pxQhgAslExeENsAV4WehcPHXt92ymf/Uga94A+ELfhdF3+zJQBsrARzLAvnSlzf1Om9zX8kBQnnPuix4w7tUeGnOMD+3Z2z2w3EczNrr4Yc4DSgz0M7Yy935i0xxznXu6+snDxLOKIX7t1aE3X/lQx37Gn/Gmb+xyTv/yq73jGYfckr/kQl37ic35Va8f/cu1unu+zCVxu8YzN33Zp61z2oiDNaCBjy+a/ok5ZYzFag740vZmML653tjR5lhMysWdbnJOfMaXG3RoysW/5195xpnXmau45Uy/xKPBgxgYu+bTp3i1Q575Tb8pxzYx6Tvn8lp59sYy/8mXuMlHnbR/7fV2z13fbAVKQoAEGHPebC6IY/UFbSIJ+MxmLqL69F5vidwWfOpnrF6XgTJQBj6CAfalKw0990/12T9zX1vto7nXui+yT9PmAeZYOTp56Mx4xF59ua+Lk37GVuY8PS1zWB2QycPEo6/Eb/4TJ7orfXHRG19sM15i1c546MqnBcS0N77rmraTC/3bT2zO7/XGhgfxqLvnK/Fwbb7Yz9z0ZZ+2GZvrGc8xPokhH/gy5lw/dGl5Pxg7ezkmBm2OZx7GSx+ZS74e0DE3dGjKJ17jp6+MsbqWFzCLm54mbv0STwzIJ4/6F+/Ex3jllzlzwtZr+UeeOFfym+Pt28x/6ptX4jPn9HPv9ebv+mYLMMAKmCS59uZ0XiCOIYl2dCPt2QBS/+gksfMG0Ef7MlAGysBnYsDD5AzT3O/Q9wBw03dfTV85577oQag9+3f6c8yc9uzVHojM0cDk9W3i4NuMrarz5pBnQe7p6icPE4++zA8b8Wuf/cw/ZVzrT2wz3sp3zk3/Z/baokdLLia2FTdTZ46Nn+uLzp6vxKMO/MPHzG3GWtlis4onLm1y/eAgz/kZJ++HKWPsGupzjmceYkhfOQd3xDSXxI6Nctcw/XCtrz156ss5scQ58/DenDyBkViziXfeA+oZJ+WJOTFpk3Nei0sd+/TFnHzJp3opI5e3Nnzc9fYDgHmzYAxxgPdmNBGAS6p6gEVvAj+z2UC+3FzTB3Lji80b4q0E1b4MlIEy8B4MzH1vz2fuZ+qwv7nHMTf3OQ8o9z3HHlgeKI6Vi8m9mr2YNsfaY0dbYbwJFticd5/HNy338RnP/Mx5T26++NPGuaN46GcO2tLTzuLJn7Ecy++0Fwt6yojPNS25uE3EN2KgK7YQvVzqX38zHxX3fKW9uYjPsbnpyz5t9S8v5pXY1cc/vm3aqqutcvS9H5zL3pyNPcczjz259lNffOCnTfl8jZina5JYlZk/eWVuXBtHv9qLA79ikDN17I2DLl9wqF9tmaNN+Ryjk/ZTrj/vk4yNrXmY81zPycEN1Cu+4ffuotbkXATAe22im+OXRCQdPWTZzmxMXlIYY2Nb2StrXwbKQBn4DAzMfW8PE3rzy/01bTxE1PUwVsdDBbkHoQeOtrmnomdzT/UAZD79pa429hYL4sreAw3deRaknbjMe+JRd+ZsnsbMeBlTuZjpnSPPGQ+5nKmXsZXJ77R3rK35HZ2LYps56YM+m3wqT3zq6cu4zru24KThQ+5nbtrYT9vEYZ7ygo1rp3/90KtvDuJBlpjSxmv9mvccr/Jwznja6lO+kIuNfG3G0J6xbfLivH3ytOJCn/TgzCYWcaVsXu/FMXd8qXOGI3MnzryvUz7zF3Pmkjlynes987g63nz++uK4avwsPUCuyH5W/MYpA2WgDLyVAfaxtjLw0xmwEJwF5E/n5dn5Z1H77NiPjNei9pHs1ncZKANlYGOgRW1vhTLwxxP/fGJXXp7PQIva53P+ErFPal+o6EUZKANflIEWtV904Qr7XRjIX1Xzq+i2j2WgRe3H8t/oZaAMlIEvzUCL2i+9fAVfBsrAF2CAffbyH4p9gXwKsQyUgTLwKRloUfspl6WgykAZ+EYMtKj9RovZVMpAGfi8DFwtav0r4W1z/rePcvIvlZXnXxyTvfP0+dfY780M/t/zD3gzrzPcR7r5F+uTGzmQ46O/tj7LL3nO6zPsYmhfBsrA+zOwvRb7V7nvT209loEyUAb+YIDN9qzNvwx37B/V+L7Evb8cJ4bvV5wfqXMW+145sbKoBeserjPfYNWXRelewXmkm3ztcZUF8V4M8M78Zg4rucWy6zVtOi4DZeCxDPC67NsPHstxvZeBMlAGbkXSvTTMP+awaKOfTdlHFFTGfm1Ry0FkMb5XjJrvka5FpbpZAOvXYpT+vYvat/Ig7vZloAy8jgFe1y1qX8ddrcpAGSgDlxlgs723+dTSgs+ibdu4X55u4lfZUaFm/FksW/BRBNJyzJzx0jdzPPXUlzo+cbXAc94cxGCvvQWxsVf6Z7rENj7+xW5OypzPfMRjb36OZ7+Sm7O5TJuOy0AZeCwD235z/2b7WFj1XgbKQBn4Xgyw2d7TLOCwo1iiUZTpx+LPQtSi1oINPXysmr4tHKcvx8ZS31j4RGaRuCrmkKtvcW4eiUnfFoLG1vYeXfCICTu5wGe2vfnUyfxy3uuV/Ipf7duXgTLw/gzwuuyT2vfntR7LQBkoA78wwGZ7tVnYrQqn9GERxZxFrcVhytKGawvJs6IWHzawzLEF5Cxqr+JPLOLWNmOJQdx7us8uarcD9OVJNuNZQIu9fRkoA49nYHtNXt9sHw+pEcpAGSgD348BNturLYuloyLJwhUdi1r1Kfzwc/R09N6i1iKWPPDteBa1yI1/lsteoSq25OxMd6+oTR9cJ29T5jjzcy77lJu/fKRer8tAGXgeA9t+c32zfR60RioDZaAMfB8G2GyvNAsu9Cnijpq66FhYfURRO4vNiZlij3zAOxt4kVnEHvk6000+iDOLXGOrJ1fOZw+moyJ1yv2hYpVj+u11GSgDj2OA12XffvA4fuu5DJSBMnBjgM32rFmYosv1bNuGfZueBR6TyC0OLdymD8baWoD5VNXxlOs7izxiOZ6FqGOx6M/xxERcfYkFG5rFIj5pR7ryh64x8TcbPsBvjClnnPldlWPD12rtVj46VwbKwPsysL0Gzzfb9w1bb2WgDJSBn8UAm+1Zs4CzOLK3GLRQm/P6nfKjoi1jWUi+tqglPkUpuCxOLWzF6rxYZ689+lkUitOiNmNNXWTmgsx8ZqyrRa3Ys7dIZm7mZFGNrK0MlIHnM7C9VvsCfD71jVgGysBPYqCFzk9a7eZaBsrARzDQovYjWG/MMlAGfhwDLWp/3JI34TJQBp7MQIvaJxPecGWgDPxMBlrU/sx1b9ZloAw8j4GXona7uL0nqte/v9m/PJSH3gO9B3oP9B7oPdB7oPfAl7oH+p7a5/0c0UhloAz8RAY4FNvKQBkoA2XgcQxsP3x0s30cxfVcBspAGfj9I6LKQxkoA2WgDDyOgRa1j+O2nstAGSgDLwzc86R2fjRXfnSUsr2Pq3oJePHCj97yY8Mumt3U8uOztsPk5S1s6QdZ5pCymc9b8KTfq9fPjnfExerjy1Z5qCfnfgTa0XrIP712+ZFvaevHls3Y2s757za+9564ygu8z9etsVyTyaW+kbvO6uSaTb/qfHQvxon9Ubg2Hvuk9lEE128ZKANlAAbYbK82DjIPKQ89i85ZBF71uac3/e/preZXB9YKH7mT06pN/bfgWflfzcElcWjPiJcYjriwWBVb2nntZ+Gqw32CzyxQ0d2b3yuS1MdXi9p/3Dj1NSf3e72c7sm9x+DW1zW63vvyna975Oj6uvG15jrnfTD97OH4iHlxt6j9CPYbswyUgTLwIAY40K40D6irB+oVn0c6Hrivibd3YHEQexgfxUZmvnnYn9m8RX6lcHyL/zNb7oM9bq5gU8fiZi+eRerUI7YYknPm/LLImr61nfPfbXzva+KIF18j6iTnWZjCobquGevh69LXiWvjfSD3+CXGZ2vm9OmKWl8gLPZccBfLhXDMguQCTrs5ZjFcKF9czyLis90IxVMGysD3YoA97Urz8MoDLe2Uu7d6aNjPfRfb3Fe9pqet9uG9PTxxcG3M3KfFp3/0wJQHrnbMe20+E0/KkxPzYI6v2Zyn17e+lOFjxsOPxYZ6mZ8+7NO/GIinLT0xbIyTC+fpzSn1U546+PHMnTqMxTB1XFtjoSsH2pDbqmmrTB/mKk/OG9t7wnXA3liTj9TVr/Hs5d44+nCeccbC7mhNkacv/TBnc05M5oZ88qINPXZ8ZV7KjakvY7AerglzNO3FREy+bPLpePbGEn/K5U8fjOc9aI7qpj3Xe3JzSvlcm5ThXz5mjCtj7H/j25UGKYCRbMbeKNpLCuO5CGmHfI71JZnpS//ty0AZKANfkYGr+yy5zQPIPRGZ+6oHg4cGNmlrgeG+6uGob/XnPpz7rrHUvQWIb8beDpJfCrlQu81zcNHEo099mM/Eo1x9fDgnL/jWP3Lw6G/mgB/k2u7F2+PP2OLRn/rKiUtbYUusN6Xtm77EljKvzUfOzVO5vesoDueJja3rQCwxZ69+9toyl/aMjce1nOIvdeXIPMW2Wi/m9po45xrIhXLjzbHYxafcsfj0r77+MlcwJi97mF03MaJnHHkQB3Emh9OemHzZxKQv5+n16301bb2XUp78c52xuE75yp95GlsuHculY2PPWJnHlWvsLxe1kuwCAxLggpV0xwCQaK61Vz7HAjbJDdybqnZ9ti8DZaAMfCQDeQhcwTH3QfdN99l5aHhIuD87dg/2sJv7bo71bSxwar/CLEZjqTP3bsYeivhmTFyaMc0n8SBfxZiHqDrYzvzFZD/jz3jTN3Y5Zyxz3otnHLkwfnLhnL02cuP8qtevveurrus258kFG3knH3SZNxfmVk3blMnHxMHYNRWLdiljzrzBJC5ttcnemK7BHJuH8lw//eSc+ORq3hPKtV35J6ejtsor88Y28xADc7Rpn/iRi9Ecbkbbt6lrHO8zsKNjU06eM1d0cm7i1Id9+pq2jOUADPh9a8PP5aJ2AtiMXzBIuvPZo2TyOc81SdEkSnKPFuklaC/KQBkoA1+AAfa61zT3Qe3dZ5mn7R0azNO0vw1iH3bfdV9mrO+5RxtbH/Yz9pxfHZoeYh6+xjSfxIO/VQzOiBVGbFf64qI3vthmPPx6BmlnvBUezy35Nr75pC32K//Gmdic3+vFjk/jq+u6y7PziYdrx9jPXLSxV5exuszRZjxzmeuL7mrtmEN3pX8LEN/kGAy0ORabnKw4z1zEbgh5JQea8onb+OlLH7Nf5ZUcoW8exBeDOWgvJmLKfWKccRmLb+InBo15crTJH72YzBUd5cjyWvvsp/1Kf+Iyx/Rz9XrzdW2zdWElm8AuCgEn6RNE2iGbY/1r5xi/bWWgDJSBr8wAm+1rm3sh9u6zzNHODg1t3UfnvptjfV89VGZs83Me3zRy9wD2zFBmTPNJPKv8mJsH+i3I9m11aKZ8YpvxVr5zTnvi0Ga81EXOONc+uUhcXE9upnw1Fj+4ss11V5Z4jAcm/MxctLFPW/0rczzvM+flC33iMb9q835Y6cw1mOOZx1wTfOacGCd2XwfKV1j0lWu80lvlJW64p7ke6KovhrnOE1PmM+MfydCd96S44FEuc/1yTlzinLHTFzJtmZ9NmffjlF8ZY3vpSa3AAeI1SeQ1ASU6F4U52tSdY22Zd0EByHVbGSgDZeArM8BedqW5seemj637qHuj47NDY/pzn/UQ2tuHV3v4xD9jK+cQzXy5Zo424+nDfPbk5GHTxrmjeHt8EecIj77lz/GMrZx5mliIay57XNwM4htrgq7YQvRyqX8nxDNtXGdwZEt7sYvPsbmkHddpq3/iyjF+Mp76c37miRxdmr68HyYGxuZ8dU2mvnlq79i8xedrZMrN3VzNc4XVuVVezhkXP5k31/JiDsYUU/KvH2Paa2u+Ey/88+U9tJKLA59czzH2tlzPGVvcYp1cyr156vNqv+XyB5g9wwxM4hi64CnDXkIyMean3Ry7wBuol59aXIg9bJ0vA2WgDHx2BtjXrjYPAvfCPEDcJ9l3aeq6T85DAx0PCvx57aEy92H09/bwW8D4ZmxxZp+HEvOZQ9qJx3wmHnXNz/DaGTPjoeP8jC1/zONjxsNWDvWRsScedZmn6U9bcTJPm3huk9s3dbW1T+70oYw+8elvnsvOu7aM5ULuZy7a2K9sxSH2xCJX+tcPvfi0VzYxOZ+9fo01x6s8nDOetvoVP3Kv6W3G0N71RJ68qD/7vbzm/TLt9E3ciTkxrThOX+YkfvDYmCNO6qQcvcTB9Wwpx59NjGJ3HZi3zXtBXeX39Ft+fwC4x7i6ZaAMlIEycI2B3OivWTxGy0M0D5XHRKrXn87ALGh+Oh+fNX+L2s+K7x5cLWrvYau6ZaAMlIFXMvBRRa2FhU+dHOeTplemVLMycMiAT+/mU79DowqfzkCL2qdT3oBloAyUga/NwEcVtbBmcbE9xbi9ZeFrs1n0n5kBfxvA/dbfCHzmlfodW4vaz79GRVgGykAZ+FQMfGRR+6mIKJgyUAbKwIMY2H5w73tqH8Rv3ZaBMlAGbgy0qO2NUAbKQBl4LAMtah/Lb72XgTJQBm4MXC1q8y+QsZl/CTzfSjD/6nnb1G9/ZT9t33MpiAOW92qZ1xnuI13fMwy+yY1Y5fjovZ5n+SXPeX2GXQzty0AZeH8Gttdin9S+P7X1WAbKQBn4gwE227NGQYSe70N07B91UYSlfPpD5h+E+TE5R4XbtL9nTKwsasEq7nv8oAtWfVmU7uE+0k2+9rjKgngvBphmfjOnldxi2fWaNh2XgTLwWAZ4XV765wuPhVHvZaAMlIHvzQCb7b3NP7ixULVoo59N2UcUVMZ+bVELN+a4V4ya75GuRaW6WQDrF3sL2/cuat/Kg7jbl4Ey8DoGeH23qH0dd7UqA2WgDFxmgM323uZTSws+i7Zt4355uolfZUeFmvFnsWzBRxFIyzFzxkvfzFEc6ksdn7ha4DlvDmKw196C2Ngr/TNdYhsf/2I3J2XOZz7isTc/x7Nfyc3ZXKZNx2WgDDyWgW2/uX+zfSysei8DZaAMfC8G2GzvaRZw2FEs0SjK9GPxZyFqUWvBhh4+Vk3fFo7Tl2NjqW8sfCKzSFwVc8jVtzg3j8SkbwtBY2t7jy54xISdXOAz29586mR+Oe/1Sn7Fr/bty0AZeH8GeF32Se3781qPZaAMlIFfGGCzvdos7FaFU/qwiGLOotbiMGVpw7WF5FlRiw8bWObYAnIWtVfxJxZxa5uxxCDuPd1nF7XbAfryJJvxLKDF3r4MlIHHM7C9Jq9vto+H1AhloAyUge/HAJvt1ZbF0lGRZOGKjkWt+hR++Dl6OnpvUWsRSx74djyLWuTGP8tlr1AVW3J2prtX1KYPrpO3KXOc+TmXfcrNXz5Sr9dloAw8j4Ftv7m+2T4PWiOVgTJQBr4PA2y2V5oFF/oUcUdNXXQsrD6iqJ3F5sRMsUc+4J0NvMgsYo98nekmH8SZRa6x1ZMr57MH01GROuX+ULHKMf32ugyUgccxwOuybz94HL/1XAbKQBm4McBme9YsTNHlerZtw75NzwKPSeQWhxZu0wdjbS3AfKrqeMr1nUUesRzPQtSxWPTneGIirr7Egg3NYhGftCNd+UPXmPibDR/gN8aUM878rsqx4Wu1disfnSsDZeB9Gdheg+eb7fuGrbcyUAbKwM9igM32rFnAWRzZWwxaqM15/U75UdGWsSwkX1vUEp+iFFwWpxa2YnVerLPXHv0sCsVpUZuxpi4yc0FmPjPW1aJW7NlbJDM3c7KoRtZWBsrA8xnYXqt9AT6f+kYsA2XgJzHQQucnrXZzLQNl4CMYaFH7Eaw3ZhkoAz+OgRa1P27Jm3AZKANPZqBF7ZMJb7gyUAZ+JgMtan/mujfrMlAGnsfAS1G7XdzeE9Xr39/sXx7KQ++B3gO9B3oP9B7oPdB74EvdA31P7fN+jmikMlAGfiIDHIptZaAMlIEy8DgGth8+utk+juJ6LgNloAz8/hFR5aEMlIEyUAYex0CL2sdxW89loAyUgRcG7nlSOz+aKz86Stnex1W9BLx44Udv+bFhF81uavnxWdth8vIWtvSDLHNI2cznLXjS79XrZ8c74mL18WWrPNSTcz8C7Wg95J9eu/zIt7T1Y8tmbG3n/Hcb33tPXOUF3ufr1liuyeRS38hdZ3VyzaZfdT66XOm1AwAAIABJREFUF+PE/ihcG499Uvsoguu3DJSBMgADbLZXGweZh5SHnkXnLAKv+tzTm/739FbzqwNrhY/cyWnVpv5b8Kz8r+bgkji0Z8RLDEdcWKyKLe289rNw1eE+wWcWqOjuze8VSerjq0XtP26c+pqT+71eTvfk3mNw6+saXe99+c7XPXJ0fd34WnOd8z6YfvZwfMS8uFvUfgT7jVkGykAZeBADHGhXmgfU1QP1is8jHQ/c18TbO7A4iD2Mj2IjM9887M9s3iK/Uji+xf+ZLffBHjdXsKljcbMXzyJ16hFbDMk5c35ZZE3f2s757za+9zVxxIuvEXWS8yxM4VBd14z18HXp68S18T6Qe/wS47M1c/qURa03fIKTWMn0haSuP00m0d4wLq42LJqL7EKmXa/LQBkoA1+VAfbEK83DKw+0tFPu/umhYY+dMu3cp/Vpj9z9OPdcD+CVL33SGzPPBPGlP/x4RqQd8/oQ88ST8sSdOTE/G3N+6VtfzuNjxsOP55B6mZ8+7NHRvxgYa0tPDBvj5MJ5enNK/ZSnDn7geq+JYeq4tsbCXg60IbdV01aZPsxVnpw3tvdE8mSsyUfq6td49nJvHH04zzhjYXe0psjTl36YszknJnNDPnnRhh47vjIv5cbUlzFYD9eEOZr2YiImXzb5dDx7Y4k/5fKnD8bzHjRHddOe6z25OaV8rk3K8C8fM8aVMfa/8e1K25R/uVkEQ59NAicx6rhAyCWSOfy4iOq2LwNloAx8dQau7rPk6f7pnpv7qHunB4OHhoedthYYHubuq8rVxzdxHLsfg8NYyuYaGFuc2acu854R4tGnPsxn4lGuPn6dkxd86x858fQ3c8APcm334u3xZ2zx6E995cSlrbAl1pvS9k1fYkuZ1+Yj1+ap3N51FIfzxMbWdSCWmLNXP3ttmUt7xsbjWk7xl7pyZJ5iW60Xc3tNnHMN5EK58eZY7OJT7lh8+ldff5krGJOXPcyumxjRM448iIM4k8NpT0y+bGLSl/P0+vW+mrbeSylP/rnOWFynfOXPPI0tl47l0rGxZ6zM48o19ncXtRhBnKSvQLhYAl2BIWn0XAxvnNWirOw7VwbKQBn4KgywT97T3Oy3Tfql6JyHm3oeEu6jjt1f3Vfdtz1kcqxvZeDVfoV9xlZHzMbMM2KeDcYkDi3xMF7FmIeoOtjO/MVkP+PPeNM3djlnLPndi2ccuTB+cuGcvTZgOmv6tZdr7Vy3OU8u2Mg7+aDLvLkwt2rapkw+Jg7GrqlYtEsZc+YNJnFpq032xnQN5tg8lOf66SfnxCdX855Qru3KPzkdtVVemTe2mYcYmKNN+8SPXIzmcDPavk1d43ifgR0dm3LynLmik3MTpz7s09e0ZSwHYMDvWxt+7ipqJQ6ggIEI5pKQCXQL8ktlj46LlHL8tpWBMlAGvhsD7HOvae652rtvMk/bOzTcS7U3tocQ+zctx/rOPdlr7bOfsZU5vzo0PcQ8fI1pPokHf/rKA4/zRlzZY7vSFxe98cU24+FvnmfGW+HxgCduys0nbZGv/N8MF9ic3+vFjk/jq+u6y7PziYdrx9jPXLSxV5exuszRZjx5nuuLbq5ZXqO70r8FiG9zjedYbHKy4jxzEbsh5NXXiPLEyjVxaOlLH7Nf5ZUcoW8exBeDOWgvJmLKPbZinHEZi2/iJwaNeext8kcvJnNFRzmyvNY++2m/0p+4zDH9XL3efF3bbFEmGMlLIIC5TnIJ7mJJmgskWMfa4zvnriZQvTJQBsrAV2CAPe61zf0Wew835mhnh4a22NHcZ+dezFjfym4GB99mbFWdJxaN3D0j8O1+j8yY5jPx6SsPVXzpz5j2q0NTGb3+xDbjrXznnPbimfFSl3iMc+2Ti8TF9eRmyldj8YMr21x3ZYnHeK7HzEUb+7TVvzLH8z5zXr7QJx7zqzbvh5XOXIM5nnnMNcFnzolxYvd1oHyFRV+5xiu9VV7i9l50PdBVXwxznSemzGfGP5KhO+9JccGjXOb65Zy4xDljpy9k2jI/mzLvxym/Msb2rie1AM/AEA+5kJbNxXGxZuK5IF7rC1Bct5WBMlAGvgsD7GtXmvtrbvrYsk/SPOwcnx0a05/7rYfQ3t5MnBlr4p+xlXMeZL5ce0bMePownz05edi0ce4o3sxBW+LQzuLJn7G0d6yceZpYiKvvPS5uBvFtnpshernUvxPiMR/nXWdwZEt7sYvPsbmkHddpq3/iyjF+Mp76c37miRxdmr68HyYGxubsGszxzGNPrv3UF5+vkSk3d3M1zxVW51Z5OSff+Mm8uZYXczCmmJJ//RjTXlvznXjhny/voZVcHPjkeo6xt+V6ztjiFuvkUu7NU59X+y2XP8AcGaLsIifoJF57gW0BboRxDVCIS1+Z1JTpr30ZKANl4CszwJ53tXkQuH/mAeJByL5JU9cDax4a6OR+7LWHymrPJd4q9sRvbHWzz0OJ+cwh7cRjPhOPuuYnBu2MmfHQcX7Glj/m8THjYSuH+sjYE4+6zNP0p604madNPLfJ7Zu62tond/pQRp/49JfnqnP0ri3XciH3M5e027MVh9gTi1zpP/2JT3tlE5Pz2evXWHO8ysM542mrX/Ej95reZgztXU/kyan6s9/La94v007fxJ2YE9OK4/RlTuIHj4054qROytFLHFzPlnL82cQodteBedu8F9RVfk+/5fcHgHuMq1sGykAZKAPXGMiN/prFY7Q8RPNQeUykev3pDMyC5qfz8Vnzt6j9rPjuwdWi9h62qlsGykAZeCUDH1XUWlj41MlxPml6ZUo1KwOHDPj0bj71OzSq8OkMtKh9OuUNWAbKQBn42gx8VFELaxYX21OM21sWvjabRf+ZGfC3Adxv/Y3AZ16p37G1qP38a1SEZaAMlIFPxcBHFrWfioiCKQNloAw8iIHtB/e+p/ZB/NZtGSgDZeDGQIva3ghloAyUgccy0KL2sfzWexkoA2XgxsDVojb/Ahmb+ZfA860E86+et0399lf20/Y9l4I4YHmvlnmd4T7S9T3D4JvciFWOj97reZZf8pzXZ9iJvcKFXfrx+r1/fW/ue++plr+zPOQy+/lX7OaQ+cI58zmXPuTBvOc4dR9x/cx4Z1x4n5/lqZ58e1+71s5nL/85l3HSdnUvnGFPX8+83vLpk9pnkt5YZaAM/DwG2GzP2jxQHVuAeJB44E9/xOAwollgeMBN3beOicVhagPrHi519nqw6suiag/3kW7ytcdVFgB7McA585vYV3ILAddr2jAm/oonsadsNbfyec/cGUb5J/a9bXXPzRxcF3RXberP8crmrXPee/h5RjzxnnHhvar+qnc9la3uS2R7vtD3K+9b9ZHByWxn2Kf+s8ZbLueb7bMANU4ZKANl4DsywGZ7b+OQwc5C1QN3dcgoy4Pp3niv1Td2FmT3+MocPSz3fB3pzgM+C2D9Yu+BzdxeU+8e+RkPYlit0Z6theIejnvn5WiFAV/vXdSas/fwGd49Hs7sXiv3Xnit/Vvs5GavwL+CDR2+ztqeL+/z1euKOb5Yk9nOsE/9Z403zPdvts8C2DhloAyUge/AAJvtvc0Cw4LAgsTDJg8zZRw2Z20Wy/OAyrFFFTHTN2Pi62tisjhx3hwmNu0tYo290j/TBU9yInZi4leZ85nPxGV+c97xSm7O5qKuvfgdZ79n6z2QhYVrLbeZhzJi0aa9cnt8cG2b+swbZ+pqY7/i1bzE7/qia9MO/8anp2nvWF17/bK24kzf+JB35dOX8/ia8bBPrtBd8S1u5Mkn9okt7VdcoG/TzvGqV4f+qKk3dcCDDM70IQeT47RdYVcfn3x5DzqvveuRPIkPO/Rt6upDjMpnv8W+f7OdjjouA2WgDJSBfQbYbO9pbubYzYMbP/NQ8eB188fOQ2XG1beHyvTlWMzq52GDzAPGQ9BigXjI1ffAN4/Eo29tja3tPbrgERN2coHPbHvzqZP55bzXK/mZX3JMfPqiX3GY83I3Y7jurvUcT+6Vu/bK5d+x8ZLTuVaJn2uxwU1+MW+b6yse4+lDPJMX5epnXK71b34Ts/60Jz+w2pQb33jeQ+KdfE/9Kdc/seRDrI7VsZ/YnM9evPItjtThes8Xdsiw4xpM5uicXKXPiV1decInXzQx6kddOZJjdPU7109fiWF1vfHwx4KulDpXBspAGSgDb2OAzfZqc2P3wNmzy8MgDyL0UzbtPeg9OIzn4TrH2INFuWMPGg8tDiua9mf40RXLtM1YN6cXdPMgxUYOwJNtbz51zrAjX33NWOmTuHKe81xPDpU7Ty+v6WPOeR9YMFhAYE+bcu3lO/Xn2mA/ORYn/YpXfXivzHjMw6PNfL0f5njG0F9yog4+zRe9VTuKv/I95/Q/+XZsTDHlfaUvZKs2sa10mJNj70e5Tv09X+LRB3yjC6a8F9IX13vY5UMsqesa4V+M+lGGvlxxLa6UM7/Xtrh/3FB7ip0vA2WgDJSB1zPAZnu1eSDQs+nvNTd/dDxM1D86kOZB4cHi4TrHxAeLB9Ecz8IDufHPchGLRYyxV4fYmW4elmCQH66zOS9XKfN65uu8fcrNP/lRL3ts0F01fciDOvKI3PyTG/ly7bwP0KWlPWPlmTu4tE994yHPr70893h1nvgT71yzycMc60v8+kt8XhNv6jOXjfjo2zKe+b8H3/oglvyJHYyrNrGtdHLOtSOG6698z1fi8ZoeHvTH9WwTu7rmMuPlOuBfPvTD3Pwi5moNJpYcbz7+WNAU9roMlIEyUAbehwE22yvNzR/9eTBNe3WZ9zDmkKB5yKwOpHlQeLB4IM0x/sDjYTzH+iPmqnnA6T91jOUhd+TrTDf5IAZxE7Nx1cPfXpv5Tr0pBz9zqxyxFfteTNdvcqjf9CFXqzn1vXfmfTDl4hJ36h+txeSD8R6vzide43lv6G/yMMf6kkfxJyf6op/5poxr/Tmf8Va+59z0n/zhc94Ted/oSy7EYD+5cf6oN77rr+6er8QjF8yBTV9wMtvEjn++bDOevBpDfPrZWz/vwT258ezB/hvf2spAGSgDZeBxDFzZZ9340V0dJNuGfQO5OgyQu/l7eKwy0tbD1MPL8ZTjA995aOXYgwc/NMdi0Z/jiYm4+hYLNjRsiOUheKQrf+gaU0wZEx/4NEbKvM78nMt+JWeOr9XaiS195LXyxCuPOTexy4+5yJ8YLC4cq+9aTP051h6s4tE28XM9sTHnOiBbjWc8fTBPm7woN190cm7Gm5j3/N2CXYgnf8Z3TBzazMd7ApmxvdcnVjHYJ/fOZb+yl4vU43rPV97HYhefY++d9Dlj6595Ocd3NrmY82LGdvrV1949l/653mL8GngqdVwGykAZKANvY2Bu5CtvHpC5+XPthu6Gr9x5fU05472WsTy8OFxo+nHMHDE97FZjDzV1PIzE6vwtwOKb9ujnISpOiwZM93SRmQt+En+GzEM05/Na3LPHP435mZNFC7LZyGMPD7ppmzGNl/7kRL25zs7Ty4ecamuPDte2qc98+jvKQV5Tn+vkaXVvpZ24zFteHKs7c857IuOBf96Lma/+wcm1Y+NhLybzytjKvD8nf/rTVn18rLhwHegzJ+3pE//MDXni05++HNujL1/60v/MRRv6iV1bcZqnvGDjnP7Tn/gSD3L9rmzS3ust/r+/AFVoXwbKQBkoA29ngM22rQyUgTLwUxmwqM1C9725aFH73ozWXxkoA2VgwUCL2gUpnSoDZeDHMLAVnA/Nt0XtQ+mt8zJQBsrA7wy0qO2dUAbKwE9kIN+CwfUjW4vaR7Jb32WgDJSBjYEWtb0VykAZKAOPZaBF7WP5rfcyUAbKwI2BFrW9EcpAGSgDj2WgRe1j+a33MlAGysCNgRa1vRHKQBkoA49loEXtY/mt9zJQBsrAjYHPUtSCw4/wOVuas79W9iN/toPk9tFP+XFC+TE98710aXv0MVFnGB8pP8v/nth+BJJczTXI9x2qk38lnnxN23twnOkaZ67Xmd2ePPM6w+3HN5n/9Hl0P6mL7dH9dJZf4hWHvTHaf14GtrXqR8183iUqsjJQBr4DA2y2n6GB46y4EOdZUUfxsOcrZRYSFrwWDhQxFnvofLZ2lv89eC3ItGGcxZexlGef/Fn4of+IZqwsasHp2t0TU6z64t7bwz3vg8nP0f0EJmMRI3mdeFf5pY735rwf73ndpL9eP5cB1qn/Uey5nDdaGSgDP5ABNtvP0O45nC20KBhWDV97BQQyC5hZsOhXn1mwOPcZenHu5f8WjOQMRxaLFHF8rdos8FY6j5qbOO+JYwFpjvK58mExKdfT9uh+Uheeju5J4qproT2xiAO9bG/hIf30+rEMsP4tah/Lcb2XgTJQBm6H7RkNPm3y8N826Jf/cuQ4/VgwKsM2m4c0cg/0LJ6MqX0e9uKw0Ei/0w579ZRZGIhRbMRPDBYM6T+vlRMj7fSLnHlzsIjSR8rSXrl29PiymX/am4M6acv11aYdWM3DOXrXQdmMuxdHzK6Fa64/x/bEypydR19f4kJGSz6QTb7F5ro51t9Kf8rEQR5n9xO6fMlV5mNse/3Kh/P2zJMTetnMZYU99Xr9sQxs9+r1F+LHwm30MlAGysDXZIDN9qx5eFt4ecBqq5wCgDbH81BX7iGvP/2rrz8PfOxoFhqOb5PbN3UtDvLQN66FgXHEQXwx4C5tMwbXYrCYgAv96Je5lKdvZDnmWj7xv/InH8Y2D8fy4ZjYYhHbzCPH5isu12UVJ/2CNfGmT6/FJMa5To7Ro6nvOip3LFb5Va5/8JiHGOy1dWwsbZ2nVzbjgAN94hCblpykj7351BG/+aWMa+YzFnNX/E4/HX8MA6xdn9R+DPeNWgbKwA9igM32rHl4W3DMsYer8lkI4D/nVgc4OCxClFtk7PlXfoTfYuBKEUJ8MeDT4of4s4EXuS3zE+9KDubEpH3O5bXy7I1l/pMvcYNRnbRfXesTG+KvGr6QE88cGdNStrLVv3jEbKw5nhxMuTm6Nvo/wi8ubR1rKzbn6ZUZJ3HMnOUk1x0fe/MZJ/3mvNfyQX75NWOp3/5zMbCt2flm+7lgF00ZKANl4GsxwGZ71jy8OeBpczwPbYsGCwFsLA6w9QDn2gYOC0rleXhzbfz0pf1ebzGAT3FzTRO3fveK2pXvic0xPqdf7M0p87egQ5441U15Ypj5T33ji4nenNOP19qjJxfKspc/dIyR+ti7hmnH9RlmMZhz8oH9lK/uscz3KBdtxSg2cpptysQBF/LBHG3FSc4fFaD6Nf+JY/JhDsae+h1/Lga2e/N8s/1csIumDJSBMvC1GGCzPWse3hYwc+xh7qE9CwH859zqAAeHBZFy4qyavvbkaWMxQC/OmYeFgYWC9rPIdZ4evOab81wbJ+WJOTFpm3Nei0sd+/TFnHxhN5sy8IJrNtfyKB9t1BUX/MglOrmG2tifYRanOUwOplx/q5y0Bc/qHpm2c93FTG9c/aSt68wcbfKjH/XyflBmbxzzd97enNCzkR9fezbqtf94Bra1Ot9sPx5qEZSBMlAGvi4DbLZnzcN6Ht6O56E99ZXv6XtgW9SqbxEwD3z8gNtCI/Er86CfBQtj4+iXeDRx4FcMWUSs4ogBPPrVljl9pxw/c4yt9lOuP/kwR2ObhznjB/+2yYHz9OpmbOX6lQPjmpNyxmAhprr6sFd3YnQ85a6F/qZ8YjFHsU25OOjFamxwo0+bXDsWBzy5DuhzLXdiFMPN4cKn89lrK6aUcT35yLlc62nX8edggDXqe2o/x1oURRkoA9+YgSsHokWAB/8ce/DnYe/ctpm/FA1S6SGN3ALE4gAdY2hvUYFMfXRWzQJH26lDHGWziLC4QJ75TB+M9+KYO/LUmT4SR+aunhjpUz7zF3Pmkr6xX3ElzozjNTKasea8GFPO9VHTB/3EPMfeH8zTpjzvD3WSa2IkHxOX/tFLbuUEX7aMhf5syfUq5srn9GF++J9f6IrXXLU35zPu1W//MQxsa/rvN8/HwGnUMlAGysD3ZGB1SH/PTJ+X1ZUi5nloGqkMlIGPZqBF7UevQOOXgTLwIxhoUfv+y9yi9v05rccy8JUZaFH7lVev2MtAGfgyDLSoff+lalH7/pzWYxn4ygy8FLXbxb+9x6Tz//6+m3JSTnoP9B7oPdB7oPdA74HeA5/yHuh7ar/yTybFXgbKwOdngMOvrQyUgTJQBh7HwPZDRjfbx1Fcz2WgDJSB3z9aqjyUgTJQBsrA4xi4u6j1Yy3ykTvva2orA2WgDJSBfQauPqnNvdXr/Cik/QjXJX500t7HE73lvap+JJLYs8+zwo9n2kONnXm/Bc+e/6P5Z8c74sKPoFp9hFXmoJ58+5FUrrXzsyfXPNfRt+Va7t0r2ubaav+d+nvviTNe4HOuRfKVslwTdNJ2b13S10dcn+X/KEwbb9ee1ALysxL4KILqtwyUgTLwHgyw2V5p6FnMqb+aU/aa3kJnbz+/9wBPDBZCFlXKZg5HhRw2qf8WPMY/68Fr4fiMeInniAuLVbGlndeupzoWPbMY2vNlAQLnuW76YX7vXtEWzr5zu/eeOOOFNUdn1VLmGqjnGoJnrrs6n6E/y/9RGLlXL/3zBRf0UUDqtwyUgTLwnRlgs73S0ONQy2ahaNGSstdcexjuFSru93uH7lFMsWZxhL6H3JFtylY8pPw9ry0U3ovfe7G9tagV/yxiJw71Zp6uDTjy3hMXa7F3r2jLPfOd272viSNe9LXiVJmvH1+rrhl+5xox99naUf6PxMq9eqmohVCI9KeGzfAFG3Lnjl4AGOQLJW18UTiHrguaiyZZ6p29kF9A9qIMlIEy8EEMsF9daejloYWNB13ug+6N7oMegui7HzunrodojrVPfKt4ue9OfJnXjK0M/4nfc0C5duhZfBln4lFXTPrVzpw8U4xhTOT61pc2+JrxsJcz9eQ2ZfCbMYxLP89O4tq0cZy9OaV+yrlWB2zg3GvqTV/yKEbyTw7w670zfWsr15NP7Yyd+PDrOuDX+HKcsdSVK+OpY9zpw3nt1ac/WlPkYsbWa+815Okbncxt8pJxpx225qOMniZG4tPQTQzwkRzelOKbfE07/U6+wvR2iZ1fGReh94hy1xqZ+Wd8c1jZHuVwA3Lx24blfLOVaAxsgJhAkij1Zm+Szpv8XFQIUleZN5bjFQb9ti8DZaAMfBYGcu88woTe3FfRZ95Dxf3YQ2Luu2dy9cXk4WRcx8bz4HPfTSwzF2OjM7+0x8a9nWvxGE8fe3iUq48P5+hpyMyPMb70xzhz8FzRduav7z2+xa9/9T3kHaO3hy2x3pS2bxNbyvI6uRZHyrne8yVX4qT3WhtzmT61hTN5kydtyVuZfuRspUuM1XqRI35WTbzeE8aWC+XGm2PxiE+5Y/3pX339oZf4kpeJV1180MDo+huXnmYccaAnhml7M4hvYmBqj3/jKtf3HOMDXflULi5xyoexzcMxdjTHXGurr5vCK7+B8fKTWpQFTLxJ/lVwuYDYmJzJ5hwxJYV5mzfFloDT7ctAGSgDn5IB9qorDT0PjtRnnr2S5p6Z8pxzb3a/nofGHKdP9mEPLONlbHTdf3PPFsuM7bz7PrFpjrkGJzFyr08eJp5VjMwfn+rQm6983ADEtxl/xpu+Mc05/Xsoa+/YUMYhN77kL7lQ116b5EbZ7PWjf7lWb8+XuSRu13jmpi/7tHVOG3GIHXx80fSfHChDLlZzwFfKjWXvemNHm2MxKRe39vQ5Jz7jyw06NOXi3/OvPOPM68xV3HKmX+LR4EEMjOGEudnEqx3yzG/6TTm2iUnfOZfXyrM3lvlPvsQNdnXS/rXX+LurqJVoAko+ydkkanN8I5vrtDMZbWbyzKcf9egl0kWdvlK312WgDJSBz8IA++CVhh77WjYPqKN9L/fRuTe7n3rAOc69Ow+dGW/u545Xh9GMbR7Oexbk3u2+Di5b8jDx6Cvxm7/Y7NFd6RuH3vhim/ESq3bGQ1c+5XfaG991TVv8rfwbZ2Jzfq83NvmLR909X4mHa/FgP3PTl33aZmyuZzzH+CSGfODLmK6bvfcE49Q3vr0cE4M2xzMP42lPn7nk6wGZuaFDUy5Oe+Onr5vBwTd5AbO46Wni1i9xxICcPFa8iFdc2a/8MmdO2Hot/8gT50qOjm3mP/XNK3GZsz5e02/+zjdbAUgswSb5zKlHArZ588zxTB67THT6ygWcvozZvgyUgTLwmRhgT7vS0Ms9Dhv3VTd998z0l3Puze7X2ruXzjF+tOdA80BkjgYmrzPm6nrGVsd5c8i9Ow9L9ZOHiUdf5oeN+LXPfpVvyvUnthlv5Tvnpv8ze23RoyUXiYvrFTdTZ46N73or3/OVeNSBf/iYuenLfmWLDU1fK17xj9wGB/O+V0af90POe+0a6nOOZx7i1p4+5+COmOYip+jQlLuG6Sd97clTX56IJc6ZhxxOnsAopvQp3nkPqGOclJs/tolJm5zzWlzq2Kcv5uRLPtVLGbm8teHj0pNaAs0XHsbzJlwRNe3mouwlD1nKJE5fkG6s9yDirUTWvgyUgTJwxMDVfWq1r849k/0QPQ8+98I59sDyQHGsvpg8ANlvaXOsPXa0FcabIB52iMV593J809zLuZ7xzA+dI3nG0Ma5o3j4zBy0pb8ST/6M5Vh+Zz5iQU8Z8Vdc3ADEN2KgK7YQvVzqX38zHxX3fKW9uYjPsbnpyz5t9S8vrnFiVx//+LZpq662ytH3fnAue3M29hzPPPbk2k998YGfNuXzNWKerkliVWb+5JW5cW0c/WovDvyKQc7UsTcOunzBoX61ZY425XOMTtpPuf68TzI2tuZhznM9Jwc3UK/4ht/LRS3+CbwZ/bIIxjYxdexZCElgzhsHu0xee4lPG3SV63cSJY72ZaAMlIHPxAB71pXm3pZ9Hnj6mHth7qnouK/ix4PQA0db909JmDH2AAAgAElEQVRj6dt91314+kN/r1ks6DN74to8SxynnbjMe+JRd+ZsnsbMeMQxpnJj0ztHzjMecjlTL2Mrk99p71hb87MYEVfi8XrmpA/6bPpQnvjU05dxnfdeAScNH3I/c9PGftomDvOUF2xcO/3rh159cxAPssSUNl7r17zneJWHc8bTVp/yhVxs+ZowhvaMbZMX5+2TpxUX+qQHZzaxiCtl83ovjrnjS50zHJk7ceZ9nfKZv5gzl8yR61zvmcfV8ebz1xfHVePqlYEyUAbKwDUG2GzbysBPZ8BCcBaQP52XZ+efRe2zYz8yXovaR7Jb32WgDJSBjYEWtb0VysAfv0HIJ3bl5fkMtKh9PueNWAbKQBn4Ngy0qP02S9lEXsFA/qqaX0W3fSwDLWo/lv9GLwNloAx8aQZa1H7p5Sv4MlAGvgADffvBF1ikQiwDZeDrM9Ci9uuvYTMoA2XgczPQovZzr0/RlYEy8E0YuFrU+lfC2+b8bx/l5F8qK8+/OIYq5+nzr7Hfm0b8r/5a+rVxMq8z3Ee6+RfrkxuxyfHRX1uf5Zc85/UZdjG0LwNl4P0Z2F6L/avc96e2HstAGSgDfzDAZnvW5l+GO/aPanxf4t5fjhPD9yvOj9Q5i32vnFhZ1IJ1D9eZb7Dqy6J0r+A80k2+9rjKgngvBnhnfjOHldxi2fWaNh2XgTLwWAZ4Xd71ObWPhVPvZaAMlIHvyQCb7b1t/jGHRRv9bMo+oqAy9muLWrixGN8rRs33SNeiUt0sgPWLvYXtexe1b+VB3O3LQBl4HQO8vlvUvo67WpWBMlAGLjPAZntv86mlBZ9F27ZxvzzdxK+yo0LN+LNYtuCjCKTlmDnjpW/mKA71pY5PXC3wnDcHMdhrb0Fs7JX+mS6xjY9/sZuTMuczH/HYm5/j2a/k5mwu06bjMlAGHsvAtt/cv9k+Fla9l4EyUAa+FwNstvc0CzjsKJZoFGX6sfizELWotWBDDx+rpm8Lx+nLsbHUNxY+kVkkroo55OpbnJtHYtK3haCxtb1HFzxiwk4u8Jltbz51Mr+c93olv+JX+/ZloAy8PwO8Lvuk9v15rccyUAbKwC8MsNlebRZ2q8IpfVhEMWdRa3GYsrTh2kLyrKjFhw0sc2wBOYvaq/gTi7i1zVhiEPee7rOL2u0AfXmSzXgW0GJvXwbKwOMZ2F6T1zfbx0NqhDJQBsrA92OAzfZqy2LpqEiycEXHolZ9Cj/8HD0dvbeotYglD3w7nkUtcuOf5bJXqIotOTvT3Stq0wfXyduUOc78nMs+5eYvH6nX6zJQBp7HwLbfXN9snwetkcpAGSgD34cBNtsrzYILfYq4o6YuOhZWH1HUzmJzYqbYIx/wzgZeZBaxR77OdJMP4swi19jqyZXz2YPpqEidcn+oWOWYfntdBsrA4xjgddm3HzyO33ouA2WgDNwYYLM9axam6HI927Zh36ZngcckcotDC7fpg7G2FmA+VXU85frOIo9Yjmch6lgs+nM8MRFXX2LBhmaxiE/aka78oWtM/M2GD/AbY8oZZ35X5djwtVq7lY/OlYEy8L4MbK/B8832fcPWWxkoA2XgZzHAZnvWLOAsjuwtBi3U5rx+p/yoaMtYFpKvLWqJT1EKLotTC1uxOi/W2WuPfhaF4rSozVhTF5m5IDOfGetqUSv27C2SmZs5WVQjaysDZeD5DGyv1b4An099I5aBMvCTGGih85NWu7mWgTLwEQy0qP0I1huzDJSBH8dAi9oft+RNuAyUgScz0KL2yYQ3XBkoAz+TgRa1P3Pdm3UZKAPPY+ClqN0ubu+J6vXvb/YvD+Wh90Dvgd4DvQd6D/Qe6D3wpe6Bvqf2eT9HNFIZKAM/kQEOxbYyUAbKQBl4HAPbDx/dbB9HcT2XgTJQBn7/iKjyUAbKQBkoA49joEXt47it5zJQBsrACwN9UvtCRS/KQBkoAw9hoEXtQ2it0zJQBsrArwy0qP2Vj47KQBkoA+/NQIva92a0/spAGSgDCwZa1C5I6VQZKANl4B0ZuKuoRdn/oOJ/efmf//mf2ycm+B9vwKaM/wDjf5VRPsfo53+AIYb/BWcD92+fyKA8/3sLuvlfaN6Ro7oqA2WgDLyZAfaotjJQBspAGXgcA1vdeG2zRZmi1n/FaHHpvxwUJjoWv7OInWMLUwvS6Quf+JoHgoWwdvrxXxiKpX0ZKANl4DMwMPewPUx//vOf/+0H+b/85S//+vvf/75n0vkyUAbKQBn41+9/kPvb1c3WopbC0aIVFi0wKVgtWi0uLYD9H9zKfXI7i1iLU4tV/K+KWuYSg3pzrqtcBspAGfgMDNyzz6K7+vrb3/72GVIphjJQBsrAp2Rg2zevP6l1o6U4tVm4UqhmgavcOW3pZ1GbMq7Pilp0ZgHLmPm2MlAGysBnY+Dq3oQeX+6x7K/sl877G7LPll/xlIEyUAY+moFtn7xWCKJM4ejTVDddkuCJKzK/9hI7e1K7slsVq6s4q7mVv86VgTJQBp7NAPvnlWbxmvsrdr4twae1/paL/fhPf/rTv3iLAu2vf/3rbR/WD3b/+7//e5Np41sZ/vnPf96KZextyLDFT1sZKANl4CsxsO171zdbCkcahmyQNgtd5n0Kqyz7WdRq59sV3HTzacSqqPXpL/Y0/TjOmL0uA2WgDHw0A+yNV9q2Kb88qdXGPW/uleq7HzvOnsKWRkHMvAWr+yZzFro+FXZs/PZloAyUgc/OwLbvXd9sLWrd+PJpgptozk0CZlGL3M16z35V1GKXGzK2LWgn2x2XgTLwWRhgj7rS9vZB98lZ1Fqg8tSVRuHqQwGe0OoPGfOMcx/nKS1z+mGcT26vYK5OGSgDZeAzMLDtd9c22zPAuVme6VZeBspAGfhJDLA/XmnbpvxvT2p9+4E/vPtbrfkQgaJXXX1lbGUUvBS3vG2Bni+L4KPftl3JoTploAyUgY9gYNvzrm22RwB9atrN8IilyspAGfipDGRhecSBhajFKk9X/c0YMp/CrorauQ9bpGZs34KgT2x4SosOBS69hfMRzsrKQBkoA5+NAfavyx/ptQfezTU3zj3dzpeBMlAGfiIDV/fHbVO+FZfzOotN912LXzi1qJ12Gdu3IKjD2LeFOedbGX7iOjXnMlAGvi4D2x729ie1X5eCIi8DZaAMPJ6BLCyPovn2AAtM3t/KE9QsXrFfFbXM+wQWe+z0lzGdo7f53lps2spAGSgDX5GBFrVfcdWKuQyUgS/HwNWi9sslVsBloAyUgU/CQIvaT7IQhVEGysD3ZqBF7fde32ZXBsrAxzPQovbj16AIykAZ+AEMtKj9AYvcFMtAGfhQBl6K2u1i+ccJla3/D3t5KS+9B3oP9B7oPdB7oPdA74FPdQ/0D8U+9EeLBi8DZeDbM8Ch11YGykAZKAOPY2D74aKb7eMorucyUAbKwO//Wrw8lIEyUAbKwOMYuLuo9WNk8lG7Hwb+OJj1XAbKQBn42gxcfVKbe6vX/lvb92LAz6Xd+2c5fpYt+/297eizcvOsIKcjTpCZ91vw3Isf/WfHO+LCf4+cn1G8ykk97xn/nbJr7fzsyTXP9fzouFzLvXtF21zbFb6vPnfvPXHGS370nmuSHDlHn2uCTtrurUv6+ojrs/wfhWnj7dqTWkB+VgIfRVD9loEyUAbegwE22ysNPYs59Vdzyl7TW+js7ef3HuCJwULIokrZzOGokMMm9d+Cx/hnPXgtHJ8RL/EccWGxKra089r1VMeiZxZDe74sQOA8100/zO/dK9rC2Xdu994TZ7yw5uisWspcA/VcQ/DMdVfnM/Rn+T8KI/fqpf8o5oI+Ckj9loEyUAa+MwNstlcaehxq2SwULVpS9pprD8O9QsX9fu/QPYop1iyO0PeQO7JN2YqHlL/ntYXCe/F7L7a3FrXin0XsxKHezNO1AUfee+JiLfbuFW25Z75zu/c1ccSLvlacKvP142vVNcPvXCPmPls7yv+RWLlXLxW1EAqR/tSwGf6CTfKVJdG+mJTZ+yLU1kWeYwK52Nqq+wuIDspAGSgDn5AB9q0rDb08tLBx78s91T3S/dBDEH32a+adU9c9M8fa09tW8Tyk0Jv4tFvFVoZd4sdHxhQzc54Xxpl41BWTfrXDB1/YZTMmMn3rSxt8zXj4kDP15DZl8JsxMjYybemJa9PGcfbmlPop51od/IJzr6k3fcmjGMk/OcCv9870ra1cTz61M3biw6/rgF/jM89XNnXlynjqGHf6cF579emP1hS5mLH12nsNefpGJ3ObvGTcaYet+Sijp4mR+DR0EwN8JIc3pfgmX9NOv5OvML1dYudXxkXoPaLctUZm/hnfHFa2RzncgFz8tmH59eZZ2Uo0BjZAJBBkJqW+C+MN4VgyJCkJxv/ZeNqLqX0ZKANl4DMykHvnET70cl9Vl3n3S/dXD4m5X57J1ReT+6lxHRvPg495WmIRn72x0Zlf2qNLLOOLx3j62MOjXH38OUdPQ6Z/4+mPMTLtz84nfe/xLX79qz/PQ/T2sCXWm9L2bWJLWV5j75c4Us71ni+5Eje919qYy/SpLWvrfSNP2pK3Mv3I2UqXGOSQeZhb3kOJRbxzTfWh3HhzLB7xKXdsLvpXX3/ogVF8yUvi5FpdfNDAiC3NuPQ044gDPTEgT9ubQXwTA1N7/BtXub7nGB/o/v/2zu66deXoto7FsTgVZ+JAnIcfvxScip/vHZMHU2epTgMEJVEiqdVjUI2u/1oNVtfGpijxlG9cxike+jYP1+gxXHOtrrYuAh/8QYynn9QibMD4m+BDM9HN8Ju8N4QJziSurb0JBARfK9oHcahaESgCReCuCFATzwzkPDhSHroHTh4IyiTN2my9vlZfsaE+NdY6rr/0jexR7Z2+jc/Dl1gYrrme5wO0xGHGs/Jh/Bfj43wyf/FQxnn6n/6mbfSSpn0PZfVdTz/kxgs5RmKhrPOMTfpq1o72xVrZPVvmknG7xzM3bTmnrjR1jMNzn/h4MbSfGMiDb6zmgK3k68t53hNzbUzYZRi3+pNmfPoXG/QY8o1/z7789DOvM1fjFjPt4o8BDsbAGkygzWG86sHPnKfd5KObMWk7aXktP2d9mf/Ey7iJXZnU/+g19m5qagUah4JPcozN2KXrnjwBUIY5N0aAk8+1GzIBwp8godtRBIpAEXhkBKhnZwZy8/D2gLJmeiCkvayRs/5aX62nrq3d2LGe4mv6m3XZ9eowmr6NUTozI3PwfMhanjjMeLSV8Zu/sTkju5I3Lmb9G9v0l7Gqpz9kxVN8p77+3dfUnVho33nGJn1v1jf5G4+ye7YyHq7NF/2Zm7acUzd9cz39ucYmPsQDW/p035y9J1invP6dxRgfjLmeeehPfebMJd8P8MwNGYZ843TWf9q6KBz8EBdiNm5mhnFrFz/GAJ88VrgYr3HlvLILzZzQ9Vr84WecKz4yjpn/lDevjMuctfGRebN3vdgagMDiLMHP6+Qpn2AYaG6G9kmcMdcCAtiOFU1e5yJQBIrAIyFAsT0zkJuHlPXQou+BkfaSZj22/qq/V1+xoz411gMRGoOYvE6fq+vpWxnp5kCOYrI6HxKHGY+2zA8fxq+/nGf+yeNae8Y2/a1sJ23av6avLnKMxGLGtsJmysy1/t1v+Xu2Mh5lwB88Zm7acl7posPQ1gpX7MN3ZD8gLee8H5LutXuozbmeeRi3+sxJs78wFzFFhiHfPUw7aWuPn/LihC/jnHmI4cQJXIwpbRrvvAeU0U/yzR/djEmdpHltXMo4py1o4iWeyiWPXD47sHHqSS2O5hsvbzJvIAEyITdmBUDamwBfW1/bsM8CU/0iUASKwFcicLZgZ13V/zzIrLfWV+vlXFuPPVBcK29M1lMPx7lWHz3GKkZjnbFJ90zANiPr//SnDWQYe3zzRUYdaUf+kM8c1GU+40/89OVafGe8xoKcPPxzzUgsLoT4gQ9kjS1Yb5fa197MR8E9W6lvLsbn2ty05Zy62hcX88rYlcc+th3qKquufOS9H6TlbM76nuuZxx5f/SlvfMTPmPz5HjFP9yRjlWf+5JW5ca0f7apvHNg1BjFTxlk/yPICQ+2qC40x+XONTOpPvva8T9I3uuZhznM/JwaXoD7wA7unm1rs43hTercJ8EwCvgkIoBuhrrObMQGZa+wLorqC94G8q1IEikAR+FYEqFtnhvUt5zzwtGGNVM7DWH7WY+uvNVNd67Q21LXWWr+hpz3k94bNgjZzxq/Ds8R16hmXec94lJ05m6c+0x9+9Clf38zSyHP6gy9myqVveeI79V2ra36ef8aV8Xg9c9IGcw5tyM/4lNOWfqW7t8TJwIbYz9zUcZ66GYd5igs67p32tcOsvDkYD7yMKXW81q55z/UqD2n6U1eb4gXf2MjXoQ/1WTsmLtKdE6cVFtpkJs4cxmJcyZvXe37MHVvKXIsjc8fPvK+TP/M35swlc+Q693vmcXa92Xz/5jirXLkiUASKQBE4hwDFtqMI/HYEbARnA/nbcfnu/LOp/W7f9/TXpvae6NZ2ESgCRWBDoE1tb4Ui8OcT/3xiV1y+H4E2td+PeT0WgSJQBF4GgTa1L7OVTeQDCOR/VfNf0R0/i0Cb2p/Fv96LQBEoAk+NQJvap96+Bl8EisATINCPHzzBJjXEIlAEnh+BNrXPv4fNoAgUgcdGoE3tY+9PoysCReBFEDjb1Ppbwltx/stXOfmbyvLzN46BSjpz/jb2V8OI/dVvS3/UT+Z1Le4j2fyN9YmNsYnx0W9bX8svcc7ra7EbQ+ciUAS+HoHtvdjfyv16aGuxCBSBIvAnAhTba2P+Zrhrf6nGzyXu/eY4Pvy84vxKnWu+b+XjK5taYt2L65ptYtWWTelew3kkm3jtYZUN8Z4P4p35zRxWfJtl92vqdF0EisB9EeB9edP31N43nFovAkWgCLwmAhTbW8f8ZQ6bNuY55P1EQ6Xvjza1YGMzvteMmu+RrE2lstkAaxd9G9uvbmo/i4Nxdy4CReBjCPD+blP7MeyqVQSKQBE4jQDF9tbhU0sbPpu2rXC/Pd3ErryjRk3/s1m24aMJZOQamv7SNjSaQ20p4xNXGzzp5mAMzurbEOt7JX9NFt/6x76xm5M86ZmP8Tibn+s5r/jmbC5Tp+siUATui8BWb24vtvcNq9aLQBEoAq+FAMX2lmEDhx7NEoOmTDs2fzaiNrU2bMhhYzW0beM4bbnWl/L6wiY8m8RVMwdfeZtz88iYtG0jqG91b5ElHmNCTyywmWOPnjKZX9K9XvHP2FW/cxEoAl+PAO/LPqn9elxrsQgUgSLwDgGK7dlhY7dqnNKGTRQ0m1qbw+SlDtc2kteaWmw4iGWubSBnU3s2/ozFuNVNX8Zg3Huy393Ubgfo25Ns1rOBNvbORaAI3B+B7T15vtjeP6R6KAJFoAi8HgIU27Mjm6WjJsnGFRmbWuVp/LBz9HT01qbWJpY8sO16NrXw9X8tl71G1dgSs2uye01t2uA6cZs815mftJyTb/7ikXK9LgJF4PsQ2OrN+WL7faHVUxEoAkXgdRCg2J4ZNlzI08QdDWWRsbH6iaZ2NpszZpo98iHeOYgXnk3ska1rsokHfmaTq2/lxEp6zsR01KROvv+oWOWYdntdBIrA/RDgfdmPH9wP31ouAkWgCFwQoNheGzamyHI9x1awL+TZ4EGEb3No4zZtsFbXBsynqq4nX9vZ5OHL9WxEXRuL9lzPmPCrLWNBh2GziE3Gkaz4IatP7M2BDeLXx+SzzvzO8tHhtdq7lY3SikAR+FoEtvfg9WL7tW5rrQgUgSLwuxCg2F4bNnA2R842gzZqk67dyT9q2tKXjeRHm1r805QSl82pja2xSjfWOauPfDaFxmlTm76mLDxzgWc+09fZptbYc7ZJhjZzsqmG11EEisD3I7C9V/sG/H7o67EIFIHfhEAbnd+02821CBSBn0CgTe1PoF6fRaAI/DoE2tT+ui1vwkWgCHwzAm1qvxnwuisCReB3ItCm9nfue7MuAkXg+xBoU/t9WNdTESgCvxiBNrW/ePObehEoAt+CwFtTu11cPujf6z9+g7U4FIfeA70Heg/0Hug90Hug98BT3QP9RbFv+SdEnRSBIvBrEeBQ7CgCRaAIFIH7IbD946PF9n4Q13IRKAJF4I/vPS0ORaAIFIEicD8EvrWpnd9biHO/f/F+KdZyESgCReDnEbjlSe38vtn8PlR5e9/Bemum1uWP1OL8TtjtMHn7CFvGAS9zSN7M5zPxpN2z19/t7wiL1XfyrvJQTsz9Xt+j/RB/ZvXye4xT1+/inb7VnfRXW996T5zFBdzn+1Zf7snEUtvw3Wdlcs+mXWV+ejbGGfu94tpwvP+TWjcu30T3Sqp2i0ARKAKPhgDF9uzgIPOQsnbadM4m8KzNPblpf09uRV8dWKv4yJ2cVmPKfyaelf0VDSzxw/gOfxnDERY2q8aWel77Bx6U4T7B5jxb9+h7TZLy2GpT+38XTH3Pif3eLKZ7fO8xsPV9jaz3vnjn+x4+sr5vfK+5z3kfTDt7cfwE3bhfrqnl5nDjfgLY+iwCRaAI/CQCHGhnhgfU2QP1jM0jGQ/cj/jbO7A4iD2Mj3zDM9887K/pfIZPnuyFTeFnbH1EF9972JyJTRmbm70YbFKnHL6NITGH5mvvrFZ3z+er0G99Txzh4ntEmcQ8G1OwU9Y9Yz98X/o+cW+8D8Qcu/h4tGFOD9nU5hvBmz8LgzeCvNw8wDY5+W6OmzD15U+6+m6gmz3p2u1cBIpAEfhpBKhPZ0bWMw+01JNvfbWuOuNHnnoegPC81rb11TU6HsArW9pk1mceWMaX9rBjvU496Now5hlP8o0fG+YBjdcc0pm1rS152Jj+sGOzoVzmpw3ntG8M+FOXGR8O1omFdGZzSvnkpwx2wHpvGMOUcW/1hb4YqENuq6GuPG2YqzhJ17f3hPuAvr4mHimrXf05i71+tCGddfpC72hP4act7UBzSDMmc4M/cVGHGT1emZd8fWpLH+yHewKNob4x4ZOXQzxdz1lfxp988dMG63kPmqOyqc/1Ht+ckj/3JnnYF4/p48wa/b/x48zYhN+SNRB14Qu4N5A3ubJu0OS7lu+Gag8fbuoKEGnqacfYOheBIlAEfhKBs3WWGOcBlAfMrIMeGtZKda29s7bKV96a6dqDjTj0JW/ip2/PhpxTFjpnAMN4tKmNWcMn3zU21BEXbGsfPv60N3PADnx1Z/7a3sNPvvFoT3n5+GWsYstYL0LbD20ZW/K8Nh+xNk/5zu6jcUjHN7ruA76MOWflc1YXWuqz1h/XYoq9lBUj8zS21X5B2xvGOfdALOTrb66N3fjkuzY+7SuvvcyVGBOXvZjdN2NETj/iYBz4mRhOfXzychiTtqQza9f7aup6LyU/8ec6fXGd/JU989S3WLoWS9f6nr4yjzPX6N/U1GZiBmNwOBT4zfAFTOgTBGnac0My6EnTtmClLNf6ZBbAKdN1ESgCReAnEKAu3TKsr9Y1a9qsg8pZh5nRcW0d9bDzsNRerrUtj3jVX8U+fStjzPpkba3HNmsPMX1a1zMe7K18YEt7KYPuzN+YnKf/6W/aRi9pM549f/oRC/0nFtKc1REb6atZu85iraz7Nunkgo64kw+y0M0F2mqomzzxmHGwdk+NRb3kQTNvYjIuddXJWZ/e43NtHvJz/7STNOMTq3lPyFd3ZZ+cjsYqr8wb3czDGKAxpn7GD98YzeGitP2YsvrxPiN2ZBzyyXPmikzSZpzacE5bU5e1GBADdj87sHNTU5s3WiZGIJuxS7GS54ZMUJGHhs68vhAWmzQ3VTnt4FOAAaqjCBSBIvAoCFjrbo3Hw0r9WQf3Dg1rr/r6nTUy19q2luesfs7Ttzzp2GZgx0PTQ8zDV5+eLRkPutrKA8+an/Fxje5K3riY9W9s01/Gqp7+VvHMs07/5pO66K/s62fGJn1vNnZs4jeH+y7O8jIerl2jP3NRx1lZ1spCY0x/5jL3F1niXb2QXclfHMQPMfaemGtjE5MV5pmLsetCXMmBIX/GrP+0pY05r/JKjJA3D/wbgzmob0z4FPuMcfplbXwzfnwwoJOjQ/yYjclckZEPL6/Vz3nqr+RnXOaYds5eb7aO/4WhMYQTxAzWQJkZrpFheFNcFtuP3JQVf9Lc1AR/brzrz4CSMfa6CBSBIvAVCFA/PzqyFs46mHUY+3u1Fz3GrJG51vbZ+jl9m590bDPy7MA2a3n6tK5nPOhqy7MFWp4dFwfxY+YfrMul9vQ//a1sJ01945n+UhaHrHPvE4sZ28Rm8ldr4yeuHN4z7ru8jEd/7sfMRR3n1NW+PNf6My7p4oU8/qCvxrwfVjJzD+Z65jH3BJtJM8YZu+8D+atYtJV7vJJb5WXc3ovuB7LKG4N4us8zpsxn+j/iITvvSeMCR7HM/UuacRnn9J224KlrHikvz/sxeWev0b3pSW06AyjWDIMxMQE3cPmuryUqUMrjw03GtkM5ad4UxqFc5yJQBIrATyJgrbwWw6yVyKNrjZt18FotnfaszdZIa6hr+Xmw6nvGPn3Lz7PB+KExpj9t6GOPTx4OdaQd+dvDCz9H8Whb/FxP3/KhM4wFv+aSe8+1WFwU4ofnl7EF6+1S+xKMZ+rkPirLnPrGbnyuzSX1pq728SvG2OHaoa9Jn3kmJtryftBWzuZ8dk+mvHmq79q8jc/3xOSbu7maZ8Y4r1d5SdMvdjJvrqExzEGfxpT4a2f6Vtd8Z7zgz8t7aMU3DmxzPdfoO3I/p2/jNtaJpdibpzbPzlsufwZzpGigOmWdjg0OujK5QSazOb00wukPQOUxm7Qy3gBpE56+0IE3AVe/cxEoAkXgpxCgPp0dHgTWwzxAZh1U1gPLOpv1M2uk1/Ktu9Ad+Fv5lu+sb2VzzrMBeuaQesZjXZ/xKGt++lZPn+kPGenTt/hBx8b0hxwZrVwAACAASURBVK4YaiN9z3iUhc7QnrrGCZ0x47kQtx/Kquuc2GlDHnPGpz3whDdxcW+REwuxn7loy3mlaxzGnrGIlfa1w2x86subMUnPWbv6mutVHtL0p652jR++18wOfajvfsJPXJSf815e836ZetrG74w5Y1phnLbMyfjzvoCGn5RJPnYyDq7nSD72HMZo7O4DdMe8F5SVf8u85fdnAEfKJn4kU14RKAJFoAj8FYEs9H/lfh/FQzQPle/zXk+/CYHZ0Pym3J8p11fq7drUPtOd11iLQBF4WgR+qqm1sfCpk+t80vS0oDbwh0bAp3fzqd9DB/0Lg2tT+ws3vSkXgSJQBD6DwE81tcRsc7E9xfjLR7s+k1d1i8BEwP8N4H7r/whMdB5v/Wub2sfbikZUBIpAEXgOBH6yqX0OhBplESgCReBzCGz/cD/3mdrPuap2ESgCReD3ItCm9vfufTMvAkXgexBoU/s9ONdLESgCvxyBs01t/gYyOvM3gedHCeZvPW9F/fKb71P3K7cAP8TyVSPzuhb3kayfGSa+iY2xivHRZz2v5Zc45/W12I2hcxEoAl+PwPZe7JPar4e2FotAESgCfyJAsb02aIiQ83OIrv2lLpqw5E978PyFML8m56hxm/q3rPGVTS2xGvctdpAlVm3ZlO7FfSSbeO1hlQ3xng9imvnNnFZ8m2X3a+p0XQSKwH0R4H15+o8v3DeUWi8CRaAIvC4CFNtbh79wY6Nq08Y8h7yfaKj0/dGmFmzMca8ZNd8jWZtKZbMB1i76NrZf3dR+Fgfj7lwEisDHEOD93ab2Y9hVqwgUgSJwGgGK7a3Dp5Y2fDZtW+F+e7qJXXlHjZr+Z7Nsw0cTyMg1NP2lbWg0h9pSxieuNnjSzcEYnNW3Idb3Sv6aLL71j31jNyd50jMf43E2P9dzXvHN2VymTtdFoAjcF4Gt3txebO8bVq0XgSJQBF4LAYrtLcMGDj2aJQZNmXZs/mxEbWpt2JDDxmpo28Zx2nKtL+X1hU14NomrZg6+8jbn5pExadtGUN/q3iJLPMaEnlhgM8cePWUyv6R7veKfsat+5yJQBL4eAd6XfVL79bjWYhEoAkXgHQIU27PDxm7VOKUNmyhoNrU2h8lLHa5tJK81tdhwEMtc20DOpvZs/BmLcaubvozBuPdkv7up3Q7QtyfZrGcDbeydi0ARuD8C23vyfLG9f0j1UASKQBF4PQQotmdHNktHTZKNKzI2tcrT+GHn6OnorU2tTSx5YNv1bGrh6/9aLnuNqrElZtdk95ratMF14jZ5rjM/aTkn3/zFI+V6XQSKwPchsNWb88X2+0KrpyJQBIrA6yBAsT0zbLiQp4k7GsoiY2P1E03tbDZnzDR75EO8cxAvPJvYI1vXZBMP/MwmV9/KiZX0nInpqEmdfP9Rscox7fa6CBSB+yHA+7IfP7gfvrVcBIpAEbggQLG9NmxMkeV6jq1gX8izwYMI3+bQxm3aYK2uDZhPVV1PvrazycOX69mIujYW7bmeMeFXW8aCDsNmEZuMI1nxQ1af2JsDG8Svj8lnnfmd5aPDa7V3KxulFYEi8LUIbO/B68X2a93WWhEoAkXgdyFAsb02bOBsjpxtBm3UJl27k3/UtKUvG8mPNrX4pyklLptTG1tjlW6sc1Yf+WwKjdOmNn1NWXjmAs98pq+zTa2x52yTDG3mZFMNr6MIFIHvR2B7r/YN+P3Q12MRKAK/CYE2Or9pt5trESgCP4FAm9qfQL0+i0AR+HUItKn9dVvehItAEfhmBNrUfjPgdVcEisDvRKBN7e/c92ZdBIrA9yHw1tRuF5fPRPX6jw/7F4fi0Hug90Dvgd4DvQd6D/QeeKp7oJ+p/b5/R9RTESgCvxEBDsWOIlAEikARuB8C2z8+WmzvB3EtF4EiUAT++Iqo4lAEikARKAL3Q6BN7f2wreUiUASKwBsCZ5/UbkX53UfB5ldHvRntRREoAkWgCLwh0Kb2DYpeFIEiUATuh8AtTe1sYtGdtPtFWstFoAgUgedEoE3tc+5boy4CReDJEPhMU+uX+ucfJXiy9BtuESgCReDuCJxuav0LLEbkX4vxL93wFCGL9lzD80lD/tUb7XUuAkWgCLwyAlkfj/LMWqmcNdO/kGWTa12W7l/fwgYvm2Dp/oUx1/K151q/nYtAESgCz4TAVvuu/6LYLHr+KUL/dOFsYuc6C7WFGFpHESgCReA3IHC23mWtTFyg27xaj10jJ82abJ1Nnk0rtnj5UMImN/31uggUgSLwbAhste16c+mTAosgTatPXknaAuqTgL2m1ie8FtVnA6zxFoEiUAQ+ggA178xALmurOtBtYm1gebgwhw8crLHWZNbU76zB+knb017XRaAIFIFnQWCre+eKbTauFkgTtendDL795q586BRQXthhhtZRBIpAEfgNCJytd9bKxMT6etTU2ujaqGa9xpZ116bXWT2f4qbfXheBIlAEngkB6uffzhZbi5/F0v/mWiU8m9bN0aWRRW/yVzZKKwJFoAi8CgJn6yxyNqbm7tNVG09rcT6ptS6r49ontepgH56NsrVZOfU7F4EiUASeDYGtnp1/YmoBZD4as2lVLz++cM3Gkf3yikARKALPhMDZeofcbGpZJ80GddXU0gBnw2qzmjT1rNM0uR1FoAgUgWdHYOs1jxvUTNJfKLA5TV5eWyylbY4uxRba5CvXuQgUgSLwigjc0tRaL52zoQWbVVObTSt61mpkHT699X/Z/AiCTa5ynYtAESgCz4jAVjNvb2otis+YdGMuAkWgCHw3AhTbjiJQBIpAEbgfAjc3tZvC/SKq5SJQBIrACyLQpvYFN7UpFYEi8FAInG5q/e8uFPK/sx4qmwZTBIpAEXhQBNrUPujGNKwiUAReBoG3pna7ePsqrq7/+HLy4lAceg/0Hug90Hug90Dvgd4DT3MPXP+s1//+97//d6/Xy/wToYkUgSJQBHYQ4EDsKAJFoAgUgfshsP3D43qxvVdDi92OIlAEisCrI9Cm9tV3uPkVgSLw0wi0qf3pHaj/IlAEfgUCZ5varSi/+yjY/EqvzwLmH3PY+2pGvx7sI99fm79/MXPxO3OJ/9rXOqJr3p+J5yNYfbe/Iyz82rVrv8uinJj7NW3utfQ5k6tf9QYvv9ko93LvXlE39/YjmD+6zq33xDVc/Mq93I/EIOm5J8ik7t6+pK2fuL6W/71i2nDrk9p7AVy7RaAIFAEQoNieGcjZzCm/osn7yGyjs3cg3nqAZww2QjZV8mYOR40cOin/mXj0f20mXhvH7/CX8RxhYbNqbKnntfupjE3PbIb2bNmAgHnum3ag790r6oLZK49b74lruLDnyKxG8twD5dxD4pn7rswjzNfyv1eM3Kun/kxuP35wry2o3SJQBH4DAhTbMwM5DrUcNoo2Lcn7yLWH4V6jcusBnjEYazZH8D3kUvboeoXDkfxneDYKX4XvrbF8tqk1/tnEzjiUm3m6N8SR955xsRd794q6bWrfo32Ei++vFabyfP/4XnXPsDv3CNqjjaP87xkr9+rppvaf//zn5V/Pm9LbL47997//fUeX//e///1NhqaY9Yp3zwRruwgUgSLwCAhQ+84M5PLQQseDLg8vDztrqocg8rOxVNZDNNfqZ3wrfx5Sq/gyr+lbHnoZvw2TfPWQs/kShxmPssakXfWwwQu9HPqEp21tqYOt6Q8bYqZc4i0PfNNH+oanLjN+Heq4ztmcUj75XCuDXWLZG8pNW+JojOSfGGDXe2faVlesJ57q6Tvjw677gF39Q+eVQ1mx0p8y+p02pKuvPLP7pj9izGHM8L32XkMubSOTuU1c0u7UQ9d85DEzjNHYkM0YwCMxTD9ci9fU0+7Ea+qj5yv9Iuc9It+9hmf+6d8cVrpHOcyYjtZbLO9vnpXCv//970tizDSoKP7jH/+4XNvUupafTS3yubbBRbajCBSBIvDqCFADzwzkVgUeuoeKB5+HRB5Q+LjGV96YPJz061p/HnwevBnLzEnfyMyX+uh42HFtPPrTxl488pXPnOEx4Jkfa2xpj3XmYMOi7sxff3t4G7/2lfeQd43cXmwZ60Vo+zFjS15eJ9bGkXyu92yJlXEye62OuUyb6oKZuImTuuQtTztitpLFx2q/yBE7q2G83hP6Fgv5+ptr4zE++a61p33ltYdcxpe4zHiVxQaDGN1//TIz9GMcyBnD1L0oxA9jgLSHv37la3uusYGseMo3LuMUD32bh2v0GK65VldbF4EP/iDG009qaUB52cTy5DbXe03tbIjRSdoHY69aESgCReBpEPDwuBZwHhwpC90DJw8EZZLmwegBMw+NucaG+hw6Hlj6S9/Ieih7QBkD8/Qtz4Mb3wzXXNsweABCSxxmPCsfxn8xHnEga77ioYzz9D/9TdvoJU37Hsrqu55+yI2X+CUWyjrP2KSvZu1oX6yV3bNlLhm3ezxz05Zz6kpTxzjcV+LjxdB+YiAPvrGaA7aSry/neU/MtTFhl2Hc6k+a8elfbNBjyDf+Pfvy08+8zlyNW8y0iz8GOBgDazCBNofxqgc/c552k49uxqTtpOW1/Jz1Zf4TL+MmdmVS/6PX2Lupqf3Pf/5zATAbWJvcpGHYJ7P/+te/Ljo+5c2mFl5HESgCReDVEVgdPKuckZuHtweUh5kHQurnIeLByMHDmAeYa/nI5KEz/W0HxaWO5/XqMJq+jVG6h3XmsDogE4cZj7YyfvPP+LhGdiVvXMz6N7bpL2NVT3/IiqcNxNTXv/uauthb2dfPjE363qxvcjceZfdsZTxcGw/6MzdtOadu+uZ6+nONTXyIB7b0OfcPWQb0lNe/sxjjgzHXMw/9qc+cueT7AZ65IcOQP+PVf9q6KBz8EBdiNm5mhnFrF3/GAJ88VrgY74yP9couNHNC12vxh59xrvgXw9uPmf+UN6+Mz5zTzq3Xm72/dvnTEI1ovmhYbVqvNbX5VFYbSZu+ui4CRaAIvBoCHibX8kJuHlIeABZ9D4y0lTQPRg9C9TlYGHMNTX0ONA9EaAxi8vpCOPgxfSsq3RyyqcjDUvnEYcajLfNDx/jVz3mVb/K1Z2zT38p20qb9a/rqIsdILDIurlfYTJm51r/7LX/PVsajDPiDx8xNW84rXXQY2lrhin34DjCY97085rwfku61e6jNuZ55GLf6zEmbTZiYIsOQ7x6mnbS1x095cSJG45x5iOHECVyMKW0a77wHlNFP8s0f3YxJnaR5bVzKOKctaOKF3znkkctnBzZOPan1l8RoYGlMN8V3Hz/w4wjybXpX62yKP5tE9YtAESgCj47A2YKN3Dzc50G2d2B7EM4Dy0PDA0y+MXkAejjOtfoeSKsYxX/GJn0ecuS0518b4jDjkW+++Ji0I3/IZw7qMjOu+RM//bsW36lvLMjJwz/XjMTiQogf15oHRLWvvZmP5vZspb65GJ9rc9OWc+pqX1zMS1wzVuxj26GusurKz/2SlrM563uuZx57fPWnvPGRL2Py53skcck4uZZn/uTKy8G1frQrzzjYa2MQM2Wc9YMsLzDUrrrQGJM/18ik/uRrz/skfaNrHuY893NicAnqAz+we6qppTHl4wWbwmWmwfWJK3Q+moDcqomFRiOrfja8H4i7KkWgCBSBp0KA2ndmWCNzzgNPGx4iynkYy/dQge9B6IGjrgeNNtSdBxb0tIf83rBZ0GbOHmjoklPaST3jMu8Zj7IzZ/PUZ/pLn/IzB2nkOf0hJ2bKpW954jv1XatrfjYjE4uMa+akDeYc2pCf8SmnLf1Kd2+Jk4ENsZ+5qeM8dTMO8xQXdNw77WuHWXlzMB54GVPqeK1d857rVR7S9KeuNsULvrGRr0Mf6rN2TFykOydOKyy0yUycOYzFuJI3r/f8mDu2lLkWR+aOn3lfJ3/mb8yZS+bIde73zOPserP5/s2xUrZZvce88ldaESgCReCVEKDYdhSB346AjeBsIH87Lt+dfza13+37nv7a1N4T3douAkWgCGwItKntrVAE/nzin0/sisv3I9Cmdvyi2Fc+sf3+7azHIlAEisD3ItCm9nvxrrfHQiD/q5r/iu74WQR+fVP7s/DXexEoAkXguRFoU/vc+9foi0AReHwETn/84PFTaYRFoAgUgcdFoE3t4+5NIysCReA1EGhT+xr72CyKQBF4cATONrX+lvBWnC+/LZ6p+ZvK8vM3jpGTzpy/jZ02vuIa+6vflv6o7czrWtxHsvkb6xMbYxPjo9+2vpZf4pzX12I3hs5FoAh8PQLbe7G/lfv10NZiESgCReBPBCi218b8zXDX/lKNn0vc+81xfPh5xfmVOtd838rHVza1xLoX1zXbxKotm9K9hvNINvHawyob4j0fxDvzmzms+DbL7tfU6boIFIH7IsD78tT31N43jFovAkWgCLw2AhTbW8f8ZQ6bNuY55P1EQ6Xvjza1YGMzvteMmu+RrE2lstkAaxd9G9uvbmo/i4Nxdy4CReBjCPD+blP7MeyqVQSKQBE4jQDF9tbhU0sbPpu2rXC/Pd3ErryjRk3/s1m24aMJZOQamv7SNjSaQ20p4xNXGzzp5mAMzurbEOt7JX9NFt/6x76xm5M86ZmP8Tibn+s5r/jmbC5Tp+siUATui8BWb24vtvcNq9aLQBEoAq+FAMX2lmEDhx7NEoOmTDs2fzaiNrU2bMhhYzW0beM4bbnWl/L6wiY8m8RVMwdfeZtz88iYtG0jqG91b5ElHmNCTyywmWOPnjKZX9K9XvHP2FW/cxEoAl+PAO/LPqn9elxrsQgUgSLwDgGK7dlhY7dqnNKGTRQ0m1qbw+SlDtc2kteaWmw4iGWubSBnU3s2/ozFuNVNX8Zg3Huy393Ubgfo25Ns1rOBNvbORaAI3B+B7T15vtjeP6R6KAJFoAi8HgIU27Mjm6WjJsnGFRmbWuVp/LBz9HT01qbWJpY8sO16NrXw9X8tl71G1dgSs2uye01t2uA6cZs815mftJyTb/7ikXK9LgJF4PsQ2OrN+WL7faHVUxEoAkXgdRCg2J4ZNlzI08QdDWWRsbH6iaZ2NpszZpo98iHeOYgXnk3ska1rsokHfmaTq2/lxEp6zsR01KROvv+oWOWYdntdBIrA/RDgfdmPH9wP31ouAkWgCFwQoNheGzamyHI9x1awL+TZ4EGEb3No4zZtsFbXBsynqq4nX9vZ5OHL9WxEXRuL9lzPmPCrLWNBh2GziE3Gkaz4IatP7M2BDeLXx+SzzvzO8tHhtdq7lY3SikAR+FoEtvfg9WL7tW5rrQgUgSLwuxCg2F4bNnA2R842gzZqk67dyT9q2tKXjeRHm1r805QSl82pja2xSjfWOauPfDaFxmlTm76mLDxzgWc+09fZptbYc7ZJhjZzsqmG11EEisD3I7C9V/sG/H7o67EIFIHfhEAbnd+02821CBSBn0CgTe1PoF6fRaAI/DoE2tT+ui1vwkWgCHwzAm1qvxnwuisCReB3ItCm9nfue7MuAkXg+xB4a2q3i8tnonr9x4f9i0Nx6D3Qe6D3QO+B3gO9B3oPPNU90M/Uft+/I+qpCBSB34gAh2JHESgCRaAI3A+B7R8fLbb3g7iWi0ARKAJ/fEVUcSgCRaAIFIH7IfDtTe38mhcC8Otq7pdmLReBIlAEfhaBW57Uzq/myq+Okrf3dVW3ZmlN/kgdzq/P2g6Tt4+wZRzwMofkzXw+E0/aPXv93f6OsFh9fdkqD+XE3K9AO9oP8WdWL7/yLXX92rLpW91Jf7X1rffEWVzAfb5v9eWeTCy1Dd99Vib3bNpV5qdnY5yx3yuuDcfveVLr5uUb6V6J1W4RKAJF4JEQoNieHRxkHlLWTZvO2QSetbknN+3vya3oqwNrFR+5k9NqTPnPxLOyv6KBJX4Y3+EvYzjCwmbV2FLPa78LVxnuE2zOc3WPvtckKY+tNrX/d8HU95zY781iusf3HgNb39fIeu+Ld77v4SPr+8b3mvuc98G0sxfHT9CN+yWbWm4QN+8nwK3PIlAEisBPIcCBdmZ4QJ09UM/YPJLxwP2Iv70Di4PYw/jINzzzzcP+ms5n+OTJXtgUfsbWR3TxvYfNmdiUsbnZi8Emdcrh2xgSc2i+9s5pdfd8vgr91vfEES6+R5RJzLMxBTtl3TP2w/el7xP3xvtAzLGLj0cb5vSQTa0b7Y3vnMGagLwsHAA++W4QG6F9N0sbuUlurDw3PGV6XQSKQBF4NASoWWdG1rhVfZPv4WhNdcaPPP1lTfVa21l3lfcAXtlShlmfeQYYn/aRw04euOpB99qYZzzJR1675gGN1xzSmbWtLXnYmP6wY7OhXOanDee0bwz4U5cZHw7WiYV0ZnNK+eSnDHbAem8Yw5Rxb/WFvhioQ26roa48bZirOEnXt/eE+4C+viYeKatd/TmLvX60IZ11+kLvaE/hpy3tQHNIMyZzgz9xUYcZPV6Zl3x9aksf7Id7Ao2hvjHhk5dDPF3PWV/Gn3zx0wbreQ+ao7Kpz/Ue35ySP/cmedgXj+njzBr9v/HjzBBkkzXYeSPv8Q3cTfImU1/7xuMmCoB8N3Xyz+RQmSJQBIrATyBgXTvjex5A1lR0Z92zDlsX1bWuWmetu/KVn3XVgy19KTtj1/d2kLxr5FIWPvWfYTza1MZenZevPDakiQu2tQ8ff9oTL/WZ4as789f2Hn7ypz3l5eOXsYotY70IbT9mbMnz2nzE3DzlO7uPxiEd3+i6D+RvzDkrn7O60FKftf64FlPspawYmaexrfYL2t4wzrkHYiFff3Nt7MYn37XxaV957WWuxJi47MXsvhkjcvoRB+PAz8Rw6uOTl8OYtCWdWbvYZExd76XkJ/5cpy+uk7+yZ576FkvXYula39NX5nHmGv0va2oxZiI6T9oEYoLrJpo8/NyoeQPAX9H03bkIFIEi8CgIUAtvGRb7rUhfah3683BTzkOCGR3XWUPRn3U219pe1eBV7NO3MsbsAcvaQ9Ga7SGmT8+OjAd7Kx/zEFUG3Zm/MTlP/9PftI1e0vQlvnv+9CMW+k8spDmrIzbSV7N2ncVa2bnv0skFHXEnH2Shmwu01VA3eeIx42DtnhqLesmDZt7EZFzqqpOzPt2DuTYP+bl/2kma8YnhvCfkq7uyT05HY5VX5o1u5mEM0BhTP+OHb4zmcFHafkxZ/XifETsyDvnkOXNFJmkzTm04p62py1oMiAG7nx3YOd3UmoigZbATcANLsCawyEBDhrECx4Sxv9o0+W6OfjsXgSJQBB4JAevcrTFZ99SftTbrMLat09AZ6uvXOkvtZORa2/iaL/Vznr7lSbcuY8tD05qNL4Y+iZOR8bDWVh54nhszRnRX8hfD2w/9G9v0l7Gqp79VPBNv/ZtP6qK/sq+fGZv0vdnYsYnfHO67OMvLeLh2jf7MRR1nZVkrC40x/ZnL3F9k5765RnYlf3EQP8TYe2KujU1MVphnLsauC3ElB4Z843TWf9rSxpxXeSVGyJsH/o3BHNQ3JnyKfcY4/bI2PuN2xgeDNTk6xI/ZmMwVGfnw8lr9nKf+St54nM0x7Zy93mwc/wtDY26A6xnsBAa5pHljqM+cG+MmZkLqsKH659qxosnrXASKQBF4FASohR8d1kH0Pdw8hGYdnoeGutbNWWdzre2swUcxT9/KSs9D0wPYmi1Pn+aT8WBPW+TlyHNDmvPMX7qz9vQ//a1sJ01945n+UhafrHPvuYa2GhOblcykGT9x5Zj7Li/j0R8xYWfmoo5z6mpfnut5n0kXL+TxB3015v2wkpl7MNczD+KemCfNGGfsvg/kr2KBlrjsyazyMm7vRfcDWeWNYe7zjCnzmTEc8ZCd96RxgaNY5v4lzbiMc/pOW/DUhT6HPO/HyT+zRvf0k9p5I85g3RA3SL5rAzYZ+dAZgoMfhpvqzS9f8OS7vij1RxEoAkXgARGwrl0LbdZJ5LP2Wvesi7OOTv259jC0bs66Kh8/09eMffqWPw954ofGmP60YT57fM8JbKgj7cjfzEFd/BzFo23xc62+a/nQGcaCX3PJvU8sLgrxY56hwXq71L4E4zEf6bmP0phT39iNz7W5pN7U1T5+xRg7XDv0Nekzz8REW94P2srZnN2DuZ557PHVn/LG53tk8s3dXM0zY5zXq7ykiTd2Mm+uoTHMQZ/GlPhrZ/pW13xnvODPy3toxTcObHM91+g7cj+nb+M21oml2JunNs/OWy5/BrNSFPhN+JL8vFbPBOQLknwTki/I8JGFTlKCmsAhM2PxptN+5yJQBIrAIyJAbTs7Zh3NOmgN9PBT1lpqjfXQwKcHhfWVWX7WXeOz/iKXvuU76xu5+cpDadpJPWMznxmPsuanb/X0m/6QkT59ix90bEx/6IqhNtL3jEdZ6AztqWuc0Bkzngtx+6Gsus5zD6Q7Z3zam82CdPeWtViI/cxFHeeVrjEYe8YiVtrXDrPxqS9vxiQ9Z+3qa65XeUjTn7raNX74XjM79KG++wk/cVF+znt5zftl6mkbvzPmjGmFcdoyJ+MnHgc0/KRM8pHLOLieI/nYcxijsbsP0B3zXlBW/i3zlt+fAayU3YyVIwNe6d1Kc3PzRrrVRuWLQBEoAo+IQBb6n4zPOpuHyk/GU9+vi4D9wap3eN2sny8zm9rni/yvEbep/SsmpRSBIlAEvhyBn2pqbSx8WOA6nzR9ebI1WATi6d586ldwHguBX9fUfhf8PkGw+H6X3/opAkWgCNwbgZ9qaslr/tdgn9Lee7d/t33Pcu753muPfy+0qX38PWqERaAIFIGHQuAnm9qHAqLBFIEiUATuhAB19vS3H9wphpotAkWgCLw8Am1qX36Lm2ARKAI/jECb2h/egLovAkXgdyBwa1O7+uxr/rcu9uZvPKuzFfa3r+i5B8L4WP0W9Ed95Uckrv1i0ZFsYjDxMTZ/y/vos57X8hPjOV+L3Rg6F4Ei8PUIbO/H428/yBCNCQAAHaJJREFU+Hq3tVgEikAR+F0IUGzPjvyKm/yFLmxkI8na30GgmWLtZxht/M76vFVuxoJ/fd9qi3zNy6Z0r+E8khUDMPNbe2ZM4kL8ez6If+Y3c1rxbZZzz6Ze10WgCNwPAd6X/fjB/fCt5SJQBIrABQGK7ZmxFeW3X+46apBs0LBrM+iTQhuso8btTDxnZGwmZwN5RhcZcrY532tGtXUka87KZgOsXfTF7Qgb5bQ15xX/szhMH10XgSJwGwK8L9vU3oZZpYtAESgCNyNAsT0zlLNB22tqs0nDLnLo2ljSuPFaDWVnI0kTyNA2a17bQfHuySY07GtLGX3a4EnX14xHfePW90r+muzM2djNydikt6mdu9F1EXhuBLZ6c67YPneqjb4IFIEi8HMIUGxvGdeaWho0bNKgOWwIodvAycvZ5tDGUT1tuTZm5eVjK33YwNqYylceOvLIzaFtdfWtbspfk91rarGZA9vEM+kpk/kl3esV/4xd9TsXgSLw9QjwvuyT2q/HtRaLQBEoAu8QoNjeMo6aWpsnbNLoMWbDp8zKp7LXmlpsOPA11zbOs6m1MUVHGe3M2Viesaklv/k6apRn7l0XgSLwtQhs78fbiu3XhlBrRaAIFIHXR4Bie8vYa2qlY89GELvSbarOPB29tanNBhX/rmdTSzz63w6Z3Seje02tsSVm12SJx5jQ22vspYtV+vA685OWc/LNP32nbK+LQBH4HgS2enNbsf2e0OqlCBSBIvA6CFBsbxk2qTRyDpsnbM2mT3kbNZtKdOawOdQGOtj0Sexcow8/m7Zcay+b7PSJXtpPnr6M5cjWNVmbVe3jN2OWrhz29kbmt5KZfPEXw5VOaUWgCNwXAd6X/fjBfTGu9SJQBIrApam7BQabpGxqt4L91nymPRteG0sbt5Tx2ubQBswG2PXkozebuFzPRtS1jar2XBuHM35tPo3FhnPicCQrBvjXp3joixkbxK+P5Hmd+UnLecWHxmv1D4nU7XURKAL3QWB7D972BOE+odRqESgCReB1EaDY3jJmM2ejaOOUs3Zt6uQdNW3aR9ZG8qNNLf59GmtzOuOVbqxzVp94sik0Tuw59mThmwt2zEc957NNrTjmbJMMbeaU+OurcxEoAt+HwPZeva3Yfl949VQEikAReA0EKLYdRaAIFIEicD8E2tTeD9taLgJFoAi8IdCm9g2KXhSBIlAE7oJAm9q7wFqjRaAIFIH3CLSpfY9HV0WgCBSBr0bgrandLi4fcu/1X797sJgUk94DvQd6D/Qe6D3Qe6D3wMPfA9c/6/W///3v/z3K66s7+9orAkWgCNwbAQ7CjiJQBIpAEbgfAts/OK4X20dpaImjowgUgSLwbAi0qX22HWu8RaAIPBsCbWqfbccabxEoAk+JwC1Nrd+xuhXod18dJW/v66puBcev3uKrs24d+fVZxuqctqDNr7+SP/P5TDzavGX+bn9HWKy+vmyVi3Ji7VegHe2H+OfXoeVXvqWuX1s2fas76a+2vvWeOIsL+zXft/pyLyeW2obvPiuTezbtKvPTszHO2O8V14Zjn9TeC+DaLQJFoAiAAMX27OAg85Dy0LPpnE3gWZt7ctP+ntyKvjqwVvGROzmtxpT/TDwr+ysaWOKH8R3+MoYjLGxWjS31vPa7cJXhPsFmNqjI7tH3miTlsdWm9v8umPqeE/u9WUz3+N5jYOv7GlnvffHO9z18ZH3f+F5zn/M+mHb24vgJunG3qT34DO9PbEx9FoEiUAQ+gwAH2pnhAXX2QD1j80jGA/cj/vYOLA5iD+Mj3/DMNw/7azqf4Z9pHD9j/5ou98EeNmdiU8bmZs+fTeqUw7cxJObQfNlkTdvqTvqrrW99Txzh4ntEmcQ8G1MwVNY9Yz98X/o+cW+8D8Qeu/h4tGFOD9nUAvDf//73yy+M/fOf/7y8Af7zn/9c1sy+IZj/9a9/LenKaOcf//jHRe+///3v//v3v/99uVaXWfm0+Wib1niKQBEoAtcQoIadGR5eyHugpZ58D0cPDWf05KnnAahNZ/irA9wDeGVLm8z6zAPL+DJ27OSBqx50r415xpP8jDtzgj4HNF/a1pZ0bEx/2LHZUC7z04YzMto3BtbqMuPDwTqxkM5sTimf/JTBDljvDWOYMu6tvtAXA3XIbTXUlacNcxUn6fr2nkic9DXxSFnt6s9Z7PWjDems0xd6R3sKP21pB5pDmjGZG/yJizrM6PHKvOTrU1v6YD/cE2gM9Y0Jn7wc4ul6zvoy/uSLnzZYz3vQHJVNfa73+OaU/Lk3ycO+eEwfZ9bo/40f1wa/oIUczSgNKNfM0GczaoNL4+svmKlDEyuNOZtabGMLujZc20Rjp6MIFIEi8GwInKmz5jQPoDxgPNw8GDw0POzUtcHwMPdwlK+8h6drDzZi0Zc843PWN7nNlzLM8Di4GMajTW2Yz4xHvvLYkCYu2Na+/rQ3c8AO8ai7528PP30bj/aUl+/BvIotY72Asv3QlrElz2vzEW/zlO/sPhqHdHyj6z7gy5hzVj5ndaGlPmv9cS2m2EtZMTJPYyMe88j8LsqLH8Y590Ab8vU318ZufPJdG5/2ldde5kp4icsi3AvJvIwRon7EwTjwMzGc+vjk5TAmbUln1q731dT1Xko+NAfX6Yvr5K/smae+xdK1WLrW9/RlDGdn9G9uanmC6pPWbExXzaq0a02tjbGNsnrSt0Avze7Z5CpXBIpAEXgUBPIQOBOTxd7a56EwDzflPCSY0XE9DzsPS+3lWtvyiFP9VczTtzLG7AHL2kMR26w9xPTpIZjxYG/lYx6iyqA78zcm5+l/+pu20UuavsR3z59+xEL/iYU0Z3XERvpq1q6zWCvrvk06uaAj7uSDLHRzgbYa6iZPPGYcrN1TY1EvedDMm5iMS111ctanezDX5iE/9087STM+sZr3hHx1V/bJ6Wis8sq80c08jAEaY+pn/PCN0RwuStuPKasf7zNiR8YhnzxnrsgkbcapDee0NXVZiwExYPezAzs3NbWbwqW5tPGkwYXumjmfwLK+1tSi78cOkPdJrXZ9Ugu9owgUgSLwbAhQyz4yPKzUn4fb3qEBnaG+vj2EOEwYudY2vuZL/Zynb3nSV4emh5iHrz6Jk5HxsNZWHngcwDM+1uiu5I2LWf/GNv1hJw94dPS3iscDHr/JN5/Uhb+yf1FcxCZ9bzZ2bOpfWfddnKVnPFy7Rn/moo6zsqyVhcaY/sR57i+yxLt6IbuSvziIH3OP59rYxGSFeeZi7LoQV98j8mfM+GGkLW3MeZVXYoS8eeDfGMxBfWPCp9ija4zTL2vjm/HjgwEdfYf4MRuTuSIjH15eq5/z1F/Jz7jMMe2cvd5sXS+2NJoI+xEBrmkws4Hl2pdNretrTa1NrI2tTaxPbl23qT27tZUrAkXgkRCgZn505IHl4eYhdO3QUBc9hoelB0eutS3vWrzTt/LS89D0AMY2WMjTp/lkPNjTVh6q80DXL/Pq0Ey+9vQ//a1sJ01945n+Uha/rHPvuYa2GhOblcykGT9x5Zj7Li/j0Z/7MXNRxzl1tS/P9bzPpIsX8viDvhrzfljJzD2Y65kHcU/Mk2aMM3bfB/JXsUBLXPZkVnkZt/ei+4Gs8sYw93nGlPnMGI54yM570rjAUSxz/5JmXMY5facteOpCn0Oe9+Pkn1mje9OTWj92gKKfj/UjAjaks0Glsb3W1MLPRtgm1s/UboH24wdndrUyRaAIPBwC1LAzw8KeRR9dmwAPO9fXDo1pz8PQQ2geSvLzYNXXjH/6lj8PeeKHxpj+tKGPPT55ONSRduRvDy/8HMWjbfFzPX3Lh84wFvyaS+59YnFRiB82NcYWrLdL7UswnqmT+6gsc+obu/G5NpfUm7rax68YY4drh74mfeaZmGjL+0FbOZvz2T2Z8uapvmvzNj7fI5Nv7uZqnhnjvF7lJU2/2Mm8uYbGMAd9GlPir53pW13znfGCPy/voRXfOLDN9Vyj78j9nL6N21gnlmJvnto8O2+5/BnMniKNKcI2tTadPq21kd0MvvsowdmmdjbH2mLWH41zRxEoAkXg2RCgjp0dHgTWwDxAPAg9/JT1wJqHBj49KLDntYcKB5l048Pfyrd8Z30rm3MeStAzh9QzHvOZ8ShrfvpWT5/pDxnp07f4QcfG9IeuGGojfc94lIXO0J66xgmdMeO5ELcfyqrrnNhpQx5zxqe92SxId29Zi4XYz1zUcV7pGoexZyxipX3tMBuf+vJmTNJz1q6+5nqVhzT9qatd44fvNbNDH+q7n/ATF+XnvJfXvF+mnrbxO2POmFYYpy1zMn7icUDDT8okH7mMg+s5ko89hzEau/sA3THvBWXl3zJv+f0ZwJ6yHyN4hHkvxtKLQBEoAo+KQBb6n4zRQzQPlZ+Mp75fF4HZ0Lxups+dmU3tc2fxR/Rtal9hF5tDESgCD4/ATzW1NhY+dXKdT5oeHrwG+JQI+PRuPvV7ymReOOg2tfELYT/x5PaF762mVgSKwIsi8FNNLXDaXGxPMS6fz3tRmJvWAyDg/wZwv/V/BB5gQ66E8Cub2iuYlF0EikARKAIHCPxkU3sQVllFoAgUgZdBYPuH+/XP1L5Mxk2kCBSBIvADCLSp/QHQ67IIFIFfhUCb2l+13U22CBSBn0Lg1qZ29dnX/G9d7M3feFZnK+xvX9Fzj5zxsfot6I/6yo9IXPvt5yPZxGDiY2z+lvfRZz2v5SfGc74WuzF0LgJF4OsR2N6PfVL79dDWYhEoAkXgTwQotmdHfsVN/kIXNrKRZO0vgM2vyrHxO+vzVrkZC/4/+vlJ8jUvm9K9hvNIVgzADH1inDGJC7w9H2Ax85v4rPg2y7lnU6/rIlAE7ocA78tTf3zhfiHUchEoAkXg9RGg2J4ZW1F+++WuowbJBg27NoM+KbTBOmrczsRzRsZmcjaQZ3SRIWeb871mVFtHsuasbDbA2kVf3I6wUU5bc17xP4vD9NF1ESgCtyHA+7JN7W2YVboIFIEicDMCFNszQzkbtL2mNps07CKHro0ljRuv1VB2NpI0gQxts+a1HRTvnmxCw762lNGnDZ50fc141Ddufa/kr8nOnI3dnIxNepvauRtdF4HnRmCrN+eK7XOn2uiLQBEoAj+HAMX2lnGtqaVBwyYNmsOGELoNnLycbQ5tHNXTlmtjVl4+ttKHDayNqXzloSOP3BzaVlff6qb8Ndm9phabObBNPJOeMplf0r1e8c/YVb9zESgCX48A78s+qf16XGuxCBSBIvAOAYrtLeOoqbV5wiaNHmM2fMqsfCp7ranFhgNfc23jPJtaG1N0lNHOnI3lGZta8puvo0Z55t51ESgCX4vA9n68rdh+bQi1VgSKQBF4fQQotreMvaZWOvZsBLEr3abqzNPRW5vabFDx73o2tcSj/+2Q2X0yutfUGltidk2WeIwJvb3GXrpYpQ+vMz9pOSff/NN3yva6CBSB70Fgqze3FdvvCa1eikARKAKvgwDF9pZhk0oj57B5wtZs+pS3UbOpRGcOm0NtoINNn8TONfrws2nLtfayyU6f6KX95OnLWI5sXZO1WdU+fjNm6cphb29kfiuZyRd/MVzplFYEisB9EeB92Y8f3BfjWi8CRaAIXJq6W2CwScqmdivYb81n2rPhtbG0cUsZr20ObcBsgF1PPnqzicv1bERd26hqz7VxOOPX5tNYbDgnDkeyYoB/fYqHvpixQfz6SJ7XmZ+0nFd8aLxW/5BI3V4XgSJwHwS29+BtTxDuE0qtFoEiUAReFwGK7S1jNnM2ijZOOWvXpk7eUdOmfWRtJD/a1OLfp7E2pzNe6cY6Z/WJJ5tC48SeY08Wvrlgx3zUcz7b1IpjzjbJ0GZOib++OheBIvB9CGzv1duK7feFV09FoAgUgddAgGLbUQSKQBEoAvdDoE3t/bCt5SJQBIrAGwJtat+g6EURKAJF4C4ItKm9C6w1WgSKQBF4j0Cb2vd4dFUEikAR+GoE3pra7eLyIfde//W7B4tJMek90Hug90Dvgd4DvQd6Dzz8PdDPen31vxZqrwgUgSKQCHAQdhSBIlAEisD9ENj+wdFiez+Ia7kIFIEi8MdXYhWHIlAEikARuB8CbWrvh20tF4EiUATeEDj7pHYryu8+Cja/OurNaC+KQBEoAkXgDYE2tW9Q9KIIFIEicD8EbmlqZxOL7qTdL9JaLgJFoAg8JwJtap9z3xp1ESgCT4bAZ5pav9Q//yjBk6XfcItAESgCd0fgpqbWwropvfvb4/7VF3k8VfDPFPpXXeaa7KZN/2qMf/FFe84WdW1Jx39HESgCReBREaBWnRnIzaey1jtrqXXTOil91mHrpXTsMFzL157rM3FWpggUgSLwaAhsPeH1YmtR9U8E+qcIbUItkq5JVB0L7lwjSwDa1IaFFxvS0q568FZ+LsT+KAJFoAg8EAKfaWpJA31rqU2oa/jSrJXw9CnPphU6L2uodfaB4GooRaAIFIGbEdhq2/WmVss2lBZFi6RF0YKK/Gxi51odm1ht2+RiQ5m0K029lEuaMXcuAkWgCPw0AtTMMwO5+aQWPeg2sTapWSu17QMHa7Q1kTW10zqbftK2djoXgSJQBJ4Nga3uXS+2FMZN+NKsWjjPNLXqOVuYbU6lO2ehViabWp9AWKwBfSX3bJvReItAEXhdBKhvZwZys6m1/lo7V02tNHVnnWQNz9rtrJ61/EyMlSkCRaAIPCICWx95vdhaAG0uXVsIV03lLMRzrU42pxMkZfQLX1rqrWjTVtdFoAgUgZ9C4DNNrU9Xrbc2otRhh03sXFsn1SEOZK3H2yFwWavbuQgUgSLwjAjc3NRaRPkXP8oWWZvKbD4tmhRQxlxbqNFlrGysaFNPu9q5GOuPIlAEisADIUC9PDOQ82mr8qyTZoNqPUbOppb6aE3EFteMpKlnHbdG669zESgCReAZEaDm/e1ssbUAIm+zaSPp+pamFsAszlsgb02yYK7swssCbTzqdC4CRaAIPBoCZ+ustTDnbGjJy7ppcwptVROx4YMHZLLxZY0+MmkHekcRKAJF4BkR2OrmuScIz5hgYy4CRaAIPAICFNuOIlAEikARuB8CbWrvh20tF4EiUATeEGhT+wZFL4pAESgCd0GgTe1dYK3RIlAEisB7BNrUvsejqyJQBIrAVyPw1tRuF29f29X1H19OXhyKQ++B3gO9B3oP9B7oPdB74GnugX7W66v/tVB7RaAIFIFEgAOxowgUgSJQBO6HwPYPjxbb+0Fcy0WgCBSBP/4iWHEoAkWgCBSB+yHQpvZ+2NZyESgCReANgbNParei/O6jYPMrvd6M9qIIFIEiUATeEGhT+wZFL4pAESgC90PglqZ2NrHoTtr9Iq3lIlAEisBzItCm9jn3rVEXgSLwZAh8pqn1jy3kH1J4svQbbhEoAkXg7gjc1NRuwrv/Leafr1UuC3D+ZTD/8o1/mjF5ZsxTCe0oB2/+BZz5F3KQkaa+Np2l50wMDuORL50ZWj4xMc6U6XURKAJFYCJA7TgzZo1BZ9ZMm1xrnTVy1i5rsHTsMFzL157rM3FWpggUgSLwaAhsfdvHim0WX4suxZJh8+mfzbWI5t8ln4VYWQs1dqZdaDaS+tBn8rhmaMtiDo24/bOQNuLa0Kax4Cub2MwZW8ZycdYfRaAIFIEdBKgdZ8asMepAt2bahLpGRpq1y9qXPJtWbPGy7lmf9dW5CBSBIvCMCGy17WPFFmUbvtkMzmbUoknBlWdBXvEstoCaxZm1jWj6T7oN6x4NPWW0pb/ZxM68ps82taDcUQSKwDUEqB1nxqwx6kC3ZtrAWseUYbZmIc/Lf9BzTZ2z5rG2fnOt7bTV6yJQBIrAMyFALfsbP86MLILI53oW0s3wX54EnG1q1c85Y7TRzaK+KvQWcJtWG2qfWEy+TWr65Rq5mTNr5TO2XheBIlAEJgLUkTMDOZtN5a1bNp6rWidNXWukTS1reNZqZ/WsifrsXASKQBF4NgS23u1jxTaLrwXS5m8CQVOJPPxZoFc8m9Bph7W+tuDfnkTYoMJ3TJoF3Djl64+i76GgjZwzZ+jIQusoAkWgCBwhcLZOzBqDTeuUjad1LGudTawxuLapVQf78KzDrHkpp37nIlAEisCzIbDVs3NNGcLZ8OXaAkmxZNh4WoRXjauyyUM3i/G065o4LPQZ02wyteXGzLU2bGpn3NNe5ozNyddP5yJQBIpAIkDtODNmjUGHOsPLYYO6amqpadZJbHHNSJp61i9rsfY7F4EiUASeEQFq3pd8/IDkbRA3o5fGVlBsXOWtZvQdFlvkspjblCqrXYs0+sroY2VTXs7TpjwPBexIm3MPBVHuXASKwAoBasaZMWsL66yB2Fg1tdm0omNt9MECetZGa53/iM/6eSbGyhSBIlAEHhGBrX6eK7aPmMAtMXEw+EQ29SjwAGGhT96Zaw6KNrVnkKpMEfi9CFBjOopAESgCReB+CLSpjSfMbWrvd6PVchH47Qi0qf3td0DzLwJF4N4I/Kqm9t5g1n4RKAJFYA+BNrV7yJReBIpAEfgaBN6a2u1i9zOj5f/xG8LFoTj0Hug90Hug90Dvgd4DvQce9h7oZ72+5t8ItVIEikARWCPAAdhRBIpAESgC90Ng+4dGi+39IK7lIlAEisAf35xSHIpAESgCReB+CLSpvR+2tVwEikAReEPg7JParSi/+yjY/EqvN6O9KAJFoAgUgTcE2tS+QdGLIlAEisD9ELilqZ1NLLqTdr9Ia7kIFIEi8JwItKl9zn1r1EWgCDwZAp9pav1jC/mHFJ4s/YZbBIpAEbg7Ajc1tZvw7n+Lwedpgn+1hvX87tfkwc8xeaz9wwj+dRxjSL3Jy8JPPOjkX8zxr+ikf659EpJ/mUc/2klf6Sd10hb6HkjGMNfIpN2MS/+di0AReG4Ezr6vZ/0ga+sLNZFhDbFmSp91xBolHTsM1/K15/oi1B9FoAgUgSdDgPr5ZX8mdzP21sjaCIrJXFuQLbRzjZ5NrQfCXnG3edbG9GnDCl0ZbULjWpkV39gt+soYO3xoDGPea2I9QOTbZJsDtozlYrA/ikAReHoEst4cJZO1KOWgW2OsIa6Rk2YdsUYlz/qFLV40twyb3MuiP4pAESgCT4rAVtvePzHdywXhbLaurW3WKKSz0cPHpFmEbRRTxuILbSWnry2hy5MNZIlXGv5siqUhwzAXY5p87WzibweIjal09ZiN2cNG2bnGduJqLsTSUQSKwGsgQE04M5DLeqAOdJvYWUOUYbZ+IM/Leso1NSlrnH7SdtrqdREoAkXgmRDY6t7Hii3KFkWSnoXRwsvstY0d8hZXm79Vs6pM6iGPL4q1do1j2oAuDT0LvjbcLHNRnhmagzUvx4xLeeKRZ17GiL18mZO6yeMaOx1FoAi8BgK8p88M5LLWoOM/xo+aWuuMutY9m1rW8KyBzuoxdxSBIlAEnhmBrY/6WLGdxXeus2ja6NnIAdqkzSKcMjaI0FLOazfBtYWcIg4Nfa55cc2LeB0bEBcacSGX/Ln2ICCfmYdrY05Z/M21cRlL5yJQBF4PgawnR9khR03IYU2x8Zw1BFlrn3qurYXqYB+ejTJrXsqp37kIFIEi8GwIbPXsz+buKAGEs9iu1tAowIzZCM61RVefrrO4Wsyxy7AQI8tQBzl5yGoDn8ikHa73mlob0Rmraw8V/eJH28akbW15mNjQz3U2/+Skr0uC/VEEisBLIGANu5YMctSAHKyTNmsIstakvVqY9dFaZK2xdqXPXheBIlAEng0B6ueX/qIYRdKmLptLgbHwbo4lX2Z5NqQQbRixaQHO4p6FGpv6tvlE1oKtPnaVMwDj0XfKIuPaBhR5YnNoDzr+kOfFmAfQXCOT+tgwDu13LgJF4LkR4H19ZiA3X9YS9Vc15FotRNcaa+2yntnkar9zESgCReAZEdhq57liey1BjM3ie03nGj+b2muy9+STF/l1FIEiUAQ+gkDrx0dQq04RKAJF4DwCbWpPYtWm9iRQFSsCRWCJQJvaJSwlFoEiUAS+DIE2tSehbFN7EqiKFYEisESgTe0SlhKLQBEoAl+GwFtTu1385bNcpf/1823FpJj0Hug90Hug90Dvgd4DvQce7x74/4MSM7GUOa/nAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "forbidden-chance",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-mills",
   "metadata": {},
   "source": [
    "The Double BiLSTM model seems to yield the best results, thus I will try to improve it a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-messaging",
   "metadata": {},
   "source": [
    "### Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-blast",
   "metadata": {},
   "source": [
    "#### Double Bidirectional LSTM layer model 500 epochs 256 units 256 embedding dimensions 0.001 LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-black",
   "metadata": {},
   "source": [
    "I will try to increase the embedding dimensions, because higher dimensional embedding can capture fine-grained relationships between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "pacific-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "145/145 [==============================] - 13s 55ms/step - loss: 6.9503 - accuracy: 0.0371\n",
      "Epoch 2/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 6.4102 - accuracy: 0.0450\n",
      "Epoch 3/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 6.2606 - accuracy: 0.0397\n",
      "Epoch 4/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 6.1846 - accuracy: 0.0484\n",
      "Epoch 5/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 6.0825 - accuracy: 0.0640\n",
      "Epoch 6/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 6.0019 - accuracy: 0.0562\n",
      "Epoch 7/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 5.8579 - accuracy: 0.0614\n",
      "Epoch 8/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 5.6706 - accuracy: 0.0774\n",
      "Epoch 9/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 5.6245 - accuracy: 0.0726\n",
      "Epoch 10/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 5.4282 - accuracy: 0.0879\n",
      "Epoch 11/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 5.2377 - accuracy: 0.0924\n",
      "Epoch 12/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 5.1187 - accuracy: 0.1025\n",
      "Epoch 13/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.9372 - accuracy: 0.1020\n",
      "Epoch 14/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.7326 - accuracy: 0.1073\n",
      "Epoch 15/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.6758 - accuracy: 0.1161\n",
      "Epoch 16/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.4756 - accuracy: 0.1378\n",
      "Epoch 17/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.3754 - accuracy: 0.1523\n",
      "Epoch 18/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.2039 - accuracy: 0.1530\n",
      "Epoch 19/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.0758 - accuracy: 0.1785\n",
      "Epoch 20/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 4.0243 - accuracy: 0.1717\n",
      "Epoch 21/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 3.8276 - accuracy: 0.1984\n",
      "Epoch 22/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 3.6446 - accuracy: 0.2153\n",
      "Epoch 23/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 3.5773 - accuracy: 0.2205\n",
      "Epoch 24/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 3.4057 - accuracy: 0.2587\n",
      "Epoch 25/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 3.3403 - accuracy: 0.2581\n",
      "Epoch 26/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 3.1758 - accuracy: 0.2891\n",
      "Epoch 27/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 3.0598 - accuracy: 0.3078\n",
      "Epoch 28/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.9586 - accuracy: 0.3347\n",
      "Epoch 29/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.8669 - accuracy: 0.3410\n",
      "Epoch 30/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 2.7626 - accuracy: 0.3603\n",
      "Epoch 31/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.6844 - accuracy: 0.3731\n",
      "Epoch 32/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.5992 - accuracy: 0.3891\n",
      "Epoch 33/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.4541 - accuracy: 0.4224\n",
      "Epoch 34/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.4241 - accuracy: 0.4458\n",
      "Epoch 35/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.2928 - accuracy: 0.4490\n",
      "Epoch 36/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.2263 - accuracy: 0.4637\n",
      "Epoch 37/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.1148 - accuracy: 0.4900\n",
      "Epoch 38/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.1193 - accuracy: 0.4828\n",
      "Epoch 39/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 2.0047 - accuracy: 0.5122\n",
      "Epoch 40/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.9548 - accuracy: 0.5256\n",
      "Epoch 41/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.8790 - accuracy: 0.5405\n",
      "Epoch 42/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.7735 - accuracy: 0.5578\n",
      "Epoch 43/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.7008 - accuracy: 0.5787\n",
      "Epoch 44/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.6838 - accuracy: 0.5945\n",
      "Epoch 45/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.6391 - accuracy: 0.5855\n",
      "Epoch 46/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.6200 - accuracy: 0.5912\n",
      "Epoch 47/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.5027 - accuracy: 0.6105\n",
      "Epoch 48/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.5221 - accuracy: 0.6180\n",
      "Epoch 49/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.4120 - accuracy: 0.6551\n",
      "Epoch 50/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.3983 - accuracy: 0.6496\n",
      "Epoch 51/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.3415 - accuracy: 0.6598\n",
      "Epoch 52/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.2697 - accuracy: 0.6829\n",
      "Epoch 53/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.2796 - accuracy: 0.6705\n",
      "Epoch 54/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.2485 - accuracy: 0.6844\n",
      "Epoch 55/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1827 - accuracy: 0.6893\n",
      "Epoch 56/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1369 - accuracy: 0.7085\n",
      "Epoch 57/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.1199 - accuracy: 0.7129\n",
      "Epoch 58/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0864 - accuracy: 0.7247\n",
      "Epoch 59/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0127 - accuracy: 0.7355\n",
      "Epoch 60/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0056 - accuracy: 0.7399\n",
      "Epoch 61/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 1.0244 - accuracy: 0.7284\n",
      "Epoch 62/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9766 - accuracy: 0.7456\n",
      "Epoch 63/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9629 - accuracy: 0.7488\n",
      "Epoch 64/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.9397 - accuracy: 0.7554\n",
      "Epoch 65/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8803 - accuracy: 0.7656\n",
      "Epoch 66/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8946 - accuracy: 0.7683\n",
      "Epoch 67/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8571 - accuracy: 0.7702\n",
      "Epoch 68/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8361 - accuracy: 0.7800\n",
      "Epoch 69/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8134 - accuracy: 0.7827\n",
      "Epoch 70/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.8090 - accuracy: 0.7871\n",
      "Epoch 71/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7820 - accuracy: 0.7913\n",
      "Epoch 72/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7537 - accuracy: 0.7912\n",
      "Epoch 73/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7496 - accuracy: 0.7945\n",
      "Epoch 74/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.7443 - accuracy: 0.8008\n",
      "Epoch 75/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6941 - accuracy: 0.8093\n",
      "Epoch 76/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6952 - accuracy: 0.8096\n",
      "Epoch 77/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6867 - accuracy: 0.8075\n",
      "Epoch 78/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6813 - accuracy: 0.8148\n",
      "Epoch 79/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6564 - accuracy: 0.8228\n",
      "Epoch 80/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6383 - accuracy: 0.8249\n",
      "Epoch 81/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6671 - accuracy: 0.8165\n",
      "Epoch 82/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6301 - accuracy: 0.8342\n",
      "Epoch 83/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6473 - accuracy: 0.8246\n",
      "Epoch 84/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6127 - accuracy: 0.8266\n",
      "Epoch 85/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.6089 - accuracy: 0.8343\n",
      "Epoch 86/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5681 - accuracy: 0.8404\n",
      "Epoch 87/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5774 - accuracy: 0.8383\n",
      "Epoch 88/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5761 - accuracy: 0.8435\n",
      "Epoch 89/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5601 - accuracy: 0.8403\n",
      "Epoch 90/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5356 - accuracy: 0.8555\n",
      "Epoch 91/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5472 - accuracy: 0.8469\n",
      "Epoch 92/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5237 - accuracy: 0.8475\n",
      "Epoch 93/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5384 - accuracy: 0.8464\n",
      "Epoch 94/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5321 - accuracy: 0.8423\n",
      "Epoch 95/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.5260 - accuracy: 0.8480\n",
      "Epoch 96/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4963 - accuracy: 0.8680\n",
      "Epoch 97/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4832 - accuracy: 0.8537\n",
      "Epoch 98/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4902 - accuracy: 0.8545\n",
      "Epoch 99/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4795 - accuracy: 0.8612\n",
      "Epoch 100/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4618 - accuracy: 0.8678\n",
      "Epoch 101/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4775 - accuracy: 0.8633\n",
      "Epoch 102/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4393 - accuracy: 0.8751\n",
      "Epoch 103/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4599 - accuracy: 0.8668\n",
      "Epoch 104/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4726 - accuracy: 0.8572\n",
      "Epoch 105/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4344 - accuracy: 0.8741\n",
      "Epoch 106/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4782 - accuracy: 0.8598\n",
      "Epoch 107/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4477 - accuracy: 0.8594\n",
      "Epoch 108/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4389 - accuracy: 0.8701\n",
      "Epoch 109/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4425 - accuracy: 0.8648\n",
      "Epoch 110/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4444 - accuracy: 0.8662\n",
      "Epoch 111/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4469 - accuracy: 0.8640\n",
      "Epoch 112/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4146 - accuracy: 0.8737\n",
      "Epoch 113/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4130 - accuracy: 0.8816\n",
      "Epoch 114/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4313 - accuracy: 0.8730\n",
      "Epoch 115/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4315 - accuracy: 0.8726\n",
      "Epoch 116/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4297 - accuracy: 0.8677\n",
      "Epoch 117/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3897 - accuracy: 0.8784\n",
      "Epoch 118/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3773 - accuracy: 0.8829\n",
      "Epoch 119/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3964 - accuracy: 0.8803\n",
      "Epoch 120/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4101 - accuracy: 0.8697\n",
      "Epoch 121/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4189 - accuracy: 0.8687\n",
      "Epoch 122/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3789 - accuracy: 0.8897\n",
      "Epoch 123/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3742 - accuracy: 0.8837\n",
      "Epoch 124/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3974 - accuracy: 0.8740\n",
      "Epoch 125/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3866 - accuracy: 0.8787\n",
      "Epoch 126/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4047 - accuracy: 0.8778\n",
      "Epoch 127/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.4067 - accuracy: 0.8735\n",
      "Epoch 128/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3901 - accuracy: 0.8828\n",
      "Epoch 129/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3833 - accuracy: 0.8773\n",
      "Epoch 130/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3732 - accuracy: 0.8856\n",
      "Epoch 131/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3747 - accuracy: 0.8820\n",
      "Epoch 132/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3642 - accuracy: 0.8891\n",
      "Epoch 133/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3680 - accuracy: 0.8890\n",
      "Epoch 134/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3933 - accuracy: 0.8713\n",
      "Epoch 135/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3649 - accuracy: 0.8784\n",
      "Epoch 136/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3601 - accuracy: 0.8871\n",
      "Epoch 137/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3579 - accuracy: 0.8878\n",
      "Epoch 138/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3597 - accuracy: 0.8830\n",
      "Epoch 139/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3612 - accuracy: 0.8816\n",
      "Epoch 140/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3520 - accuracy: 0.8893\n",
      "Epoch 141/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3723 - accuracy: 0.8856\n",
      "Epoch 142/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3613 - accuracy: 0.8830\n",
      "Epoch 143/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3567 - accuracy: 0.8936\n",
      "Epoch 144/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3601 - accuracy: 0.8842\n",
      "Epoch 145/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3420 - accuracy: 0.8887\n",
      "Epoch 146/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3568 - accuracy: 0.8883\n",
      "Epoch 147/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3419 - accuracy: 0.8935\n",
      "Epoch 148/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3455 - accuracy: 0.8905\n",
      "Epoch 149/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3508 - accuracy: 0.8882\n",
      "Epoch 150/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3231 - accuracy: 0.8896\n",
      "Epoch 151/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3271 - accuracy: 0.8914\n",
      "Epoch 152/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3595 - accuracy: 0.8841\n",
      "Epoch 153/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3615 - accuracy: 0.8793\n",
      "Epoch 154/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3131 - accuracy: 0.8974\n",
      "Epoch 155/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3281 - accuracy: 0.8939\n",
      "Epoch 156/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3171 - accuracy: 0.9025\n",
      "Epoch 157/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3111 - accuracy: 0.9007\n",
      "Epoch 158/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3312 - accuracy: 0.8945\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3185 - accuracy: 0.8954\n",
      "Epoch 160/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3329 - accuracy: 0.8975\n",
      "Epoch 161/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3639 - accuracy: 0.8832\n",
      "Epoch 162/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3141 - accuracy: 0.8983\n",
      "Epoch 163/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3349 - accuracy: 0.8872\n",
      "Epoch 164/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3137 - accuracy: 0.8987\n",
      "Epoch 165/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3426 - accuracy: 0.8881\n",
      "Epoch 166/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3240 - accuracy: 0.8884\n",
      "Epoch 167/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3306 - accuracy: 0.8895\n",
      "Epoch 168/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3426 - accuracy: 0.8864\n",
      "Epoch 169/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3019 - accuracy: 0.9012\n",
      "Epoch 170/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2942 - accuracy: 0.9040\n",
      "Epoch 171/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3063 - accuracy: 0.8973\n",
      "Epoch 172/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3124 - accuracy: 0.8980\n",
      "Epoch 173/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3435 - accuracy: 0.8863\n",
      "Epoch 174/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3186 - accuracy: 0.8955\n",
      "Epoch 175/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3336 - accuracy: 0.8908\n",
      "Epoch 176/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3342 - accuracy: 0.8864\n",
      "Epoch 177/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3405 - accuracy: 0.8855\n",
      "Epoch 178/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3097 - accuracy: 0.8928\n",
      "Epoch 179/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3299 - accuracy: 0.8896\n",
      "Epoch 180/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3268 - accuracy: 0.8942\n",
      "Epoch 181/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3177 - accuracy: 0.8912\n",
      "Epoch 182/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3073 - accuracy: 0.8990\n",
      "Epoch 183/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3034 - accuracy: 0.8994\n",
      "Epoch 184/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3049 - accuracy: 0.8958\n",
      "Epoch 185/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3187 - accuracy: 0.8935\n",
      "Epoch 186/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3032 - accuracy: 0.8998\n",
      "Epoch 187/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3066 - accuracy: 0.8926\n",
      "Epoch 188/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3219 - accuracy: 0.8883\n",
      "Epoch 189/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3030 - accuracy: 0.8942\n",
      "Epoch 190/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2953 - accuracy: 0.9026\n",
      "Epoch 191/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3050 - accuracy: 0.9005\n",
      "Epoch 192/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3138 - accuracy: 0.8933\n",
      "Epoch 193/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3098 - accuracy: 0.8947\n",
      "Epoch 194/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3519 - accuracy: 0.8815\n",
      "Epoch 195/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3029 - accuracy: 0.8942\n",
      "Epoch 196/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2988 - accuracy: 0.9007\n",
      "Epoch 197/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3099 - accuracy: 0.8930\n",
      "Epoch 198/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3078 - accuracy: 0.8936\n",
      "Epoch 199/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2978 - accuracy: 0.8977\n",
      "Epoch 200/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3108 - accuracy: 0.8898\n",
      "Epoch 201/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3041 - accuracy: 0.8965\n",
      "Epoch 202/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3071 - accuracy: 0.8921\n",
      "Epoch 203/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2963 - accuracy: 0.8988\n",
      "Epoch 204/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2820 - accuracy: 0.9042\n",
      "Epoch 205/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3092 - accuracy: 0.8923\n",
      "Epoch 206/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3044 - accuracy: 0.8970\n",
      "Epoch 207/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3033 - accuracy: 0.8952\n",
      "Epoch 208/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2768 - accuracy: 0.9016\n",
      "Epoch 209/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2895 - accuracy: 0.9038\n",
      "Epoch 210/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2938 - accuracy: 0.8946\n",
      "Epoch 211/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2878 - accuracy: 0.8999\n",
      "Epoch 212/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2934 - accuracy: 0.8928\n",
      "Epoch 213/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3129 - accuracy: 0.8910\n",
      "Epoch 214/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2983 - accuracy: 0.8975\n",
      "Epoch 215/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2892 - accuracy: 0.9004\n",
      "Epoch 216/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2891 - accuracy: 0.9033\n",
      "Epoch 217/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2822 - accuracy: 0.8978\n",
      "Epoch 218/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2734 - accuracy: 0.9017\n",
      "Epoch 219/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3072 - accuracy: 0.8928\n",
      "Epoch 220/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2648 - accuracy: 0.9030\n",
      "Epoch 221/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3126 - accuracy: 0.8869\n",
      "Epoch 222/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2939 - accuracy: 0.8977\n",
      "Epoch 223/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2841 - accuracy: 0.8935\n",
      "Epoch 224/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2794 - accuracy: 0.9017\n",
      "Epoch 225/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2925 - accuracy: 0.9005\n",
      "Epoch 226/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3047 - accuracy: 0.8948\n",
      "Epoch 227/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3071 - accuracy: 0.8911\n",
      "Epoch 228/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2767 - accuracy: 0.8985\n",
      "Epoch 229/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2734 - accuracy: 0.9043\n",
      "Epoch 230/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2711 - accuracy: 0.9007\n",
      "Epoch 231/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2884 - accuracy: 0.8963\n",
      "Epoch 232/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2975 - accuracy: 0.8883\n",
      "Epoch 233/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2943 - accuracy: 0.8956\n",
      "Epoch 234/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2892 - accuracy: 0.8965\n",
      "Epoch 235/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2912 - accuracy: 0.8921\n",
      "Epoch 236/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2741 - accuracy: 0.9047\n",
      "Epoch 237/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2897 - accuracy: 0.8932\n",
      "Epoch 238/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.3141 - accuracy: 0.8908\n",
      "Epoch 239/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2952 - accuracy: 0.8908\n",
      "Epoch 240/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2794 - accuracy: 0.8988\n",
      "Epoch 241/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2865 - accuracy: 0.8975\n",
      "Epoch 242/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2788 - accuracy: 0.8995\n",
      "Epoch 243/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2627 - accuracy: 0.9046\n",
      "Epoch 244/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2651 - accuracy: 0.9002\n",
      "Epoch 245/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2764 - accuracy: 0.8982\n",
      "Epoch 246/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2595 - accuracy: 0.9074\n",
      "Epoch 247/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2747 - accuracy: 0.9033\n",
      "Epoch 248/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2900 - accuracy: 0.8979\n",
      "Epoch 249/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2976 - accuracy: 0.8941\n",
      "Epoch 250/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2668 - accuracy: 0.9034\n",
      "Epoch 251/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2772 - accuracy: 0.9020\n",
      "Epoch 252/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2849 - accuracy: 0.8961\n",
      "Epoch 253/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2693 - accuracy: 0.9029\n",
      "Epoch 254/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2782 - accuracy: 0.9013\n",
      "Epoch 255/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2706 - accuracy: 0.9001\n",
      "Epoch 256/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2802 - accuracy: 0.8940\n",
      "Epoch 257/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2651 - accuracy: 0.8997\n",
      "Epoch 258/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2700 - accuracy: 0.9079\n",
      "Epoch 259/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2783 - accuracy: 0.8950\n",
      "Epoch 260/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2780 - accuracy: 0.9043\n",
      "Epoch 261/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2822 - accuracy: 0.8969\n",
      "Epoch 262/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2743 - accuracy: 0.8984\n",
      "Epoch 263/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2655 - accuracy: 0.9046\n",
      "Epoch 264/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2518 - accuracy: 0.9082\n",
      "Epoch 265/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2646 - accuracy: 0.9019\n",
      "Epoch 266/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2582 - accuracy: 0.9080\n",
      "Epoch 267/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2716 - accuracy: 0.9010\n",
      "Epoch 268/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2680 - accuracy: 0.9010\n",
      "Epoch 269/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2567 - accuracy: 0.9055\n",
      "Epoch 270/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2824 - accuracy: 0.9006\n",
      "Epoch 271/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2675 - accuracy: 0.9053\n",
      "Epoch 272/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2488 - accuracy: 0.9130\n",
      "Epoch 273/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2872 - accuracy: 0.8948\n",
      "Epoch 274/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2760 - accuracy: 0.9004\n",
      "Epoch 275/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2837 - accuracy: 0.8979\n",
      "Epoch 276/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2721 - accuracy: 0.9006\n",
      "Epoch 277/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2826 - accuracy: 0.8903\n",
      "Epoch 278/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2663 - accuracy: 0.9044\n",
      "Epoch 279/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2606 - accuracy: 0.9004\n",
      "Epoch 280/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2619 - accuracy: 0.9071\n",
      "Epoch 281/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2896 - accuracy: 0.8950\n",
      "Epoch 282/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2822 - accuracy: 0.8976\n",
      "Epoch 283/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2697 - accuracy: 0.9044\n",
      "Epoch 284/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2537 - accuracy: 0.9049\n",
      "Epoch 285/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2845 - accuracy: 0.8934\n",
      "Epoch 286/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2771 - accuracy: 0.8958\n",
      "Epoch 287/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2566 - accuracy: 0.9051\n",
      "Epoch 288/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2972 - accuracy: 0.8901\n",
      "Epoch 289/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2815 - accuracy: 0.9026\n",
      "Epoch 290/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2651 - accuracy: 0.9017\n",
      "Epoch 291/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2627 - accuracy: 0.9018\n",
      "Epoch 292/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2720 - accuracy: 0.8980\n",
      "Epoch 293/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2752 - accuracy: 0.8990\n",
      "Epoch 294/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2766 - accuracy: 0.9028\n",
      "Epoch 295/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2750 - accuracy: 0.8959\n",
      "Epoch 296/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2431 - accuracy: 0.9091\n",
      "Epoch 297/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2774 - accuracy: 0.8966\n",
      "Epoch 298/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2725 - accuracy: 0.9016\n",
      "Epoch 299/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2759 - accuracy: 0.8944\n",
      "Epoch 300/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2546 - accuracy: 0.9085\n",
      "Epoch 301/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2430 - accuracy: 0.9126\n",
      "Epoch 302/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2867 - accuracy: 0.8936\n",
      "Epoch 303/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2751 - accuracy: 0.8990\n",
      "Epoch 304/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2738 - accuracy: 0.8979\n",
      "Epoch 305/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2839 - accuracy: 0.8931\n",
      "Epoch 306/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2716 - accuracy: 0.8981\n",
      "Epoch 307/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2794 - accuracy: 0.8957\n",
      "Epoch 308/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2535 - accuracy: 0.9067\n",
      "Epoch 309/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2905 - accuracy: 0.8955\n",
      "Epoch 310/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2711 - accuracy: 0.9026\n",
      "Epoch 311/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2728 - accuracy: 0.9027\n",
      "Epoch 312/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2655 - accuracy: 0.9037\n",
      "Epoch 313/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2469 - accuracy: 0.9073\n",
      "Epoch 314/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2692 - accuracy: 0.8987\n",
      "Epoch 315/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2661 - accuracy: 0.9013\n",
      "Epoch 316/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2750 - accuracy: 0.8942\n",
      "Epoch 317/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2595 - accuracy: 0.9017\n",
      "Epoch 318/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2687 - accuracy: 0.8957\n",
      "Epoch 319/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2620 - accuracy: 0.9032\n",
      "Epoch 320/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2654 - accuracy: 0.8963\n",
      "Epoch 321/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2576 - accuracy: 0.9020\n",
      "Epoch 322/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2467 - accuracy: 0.9076\n",
      "Epoch 323/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2851 - accuracy: 0.8963\n",
      "Epoch 324/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2724 - accuracy: 0.8963\n",
      "Epoch 325/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2610 - accuracy: 0.8972\n",
      "Epoch 326/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2736 - accuracy: 0.8979\n",
      "Epoch 327/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2630 - accuracy: 0.9044\n",
      "Epoch 328/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2527 - accuracy: 0.9071\n",
      "Epoch 329/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2744 - accuracy: 0.8924\n",
      "Epoch 330/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2548 - accuracy: 0.9040\n",
      "Epoch 331/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2646 - accuracy: 0.9035\n",
      "Epoch 332/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2718 - accuracy: 0.8923\n",
      "Epoch 333/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2651 - accuracy: 0.9010\n",
      "Epoch 334/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2735 - accuracy: 0.8958\n",
      "Epoch 335/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2618 - accuracy: 0.8985\n",
      "Epoch 336/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2575 - accuracy: 0.9041\n",
      "Epoch 337/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2546 - accuracy: 0.9067\n",
      "Epoch 338/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2692 - accuracy: 0.9025\n",
      "Epoch 339/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2330 - accuracy: 0.9122\n",
      "Epoch 340/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2556 - accuracy: 0.9005\n",
      "Epoch 341/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2535 - accuracy: 0.9036\n",
      "Epoch 342/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2684 - accuracy: 0.8922\n",
      "Epoch 343/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2608 - accuracy: 0.8980\n",
      "Epoch 344/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2605 - accuracy: 0.9081\n",
      "Epoch 345/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2521 - accuracy: 0.9003\n",
      "Epoch 346/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2581 - accuracy: 0.8990\n",
      "Epoch 347/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2717 - accuracy: 0.8987\n",
      "Epoch 348/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2646 - accuracy: 0.9027\n",
      "Epoch 349/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2668 - accuracy: 0.8963\n",
      "Epoch 350/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2540 - accuracy: 0.9015\n",
      "Epoch 351/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2723 - accuracy: 0.9029\n",
      "Epoch 352/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2576 - accuracy: 0.9017\n",
      "Epoch 353/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2593 - accuracy: 0.9026\n",
      "Epoch 354/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2540 - accuracy: 0.9008\n",
      "Epoch 355/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2684 - accuracy: 0.8964\n",
      "Epoch 356/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2579 - accuracy: 0.8985\n",
      "Epoch 357/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2691 - accuracy: 0.8977\n",
      "Epoch 358/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2568 - accuracy: 0.9040\n",
      "Epoch 359/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2441 - accuracy: 0.9086\n",
      "Epoch 360/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2554 - accuracy: 0.8996\n",
      "Epoch 361/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2585 - accuracy: 0.9055\n",
      "Epoch 362/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2746 - accuracy: 0.8962\n",
      "Epoch 363/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2639 - accuracy: 0.9027\n",
      "Epoch 364/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2583 - accuracy: 0.9022\n",
      "Epoch 365/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2415 - accuracy: 0.9084\n",
      "Epoch 366/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2578 - accuracy: 0.9009\n",
      "Epoch 367/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2608 - accuracy: 0.9015\n",
      "Epoch 368/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2529 - accuracy: 0.9011\n",
      "Epoch 369/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2453 - accuracy: 0.9055\n",
      "Epoch 370/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2593 - accuracy: 0.9035\n",
      "Epoch 371/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2548 - accuracy: 0.9013\n",
      "Epoch 372/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2575 - accuracy: 0.9007\n",
      "Epoch 373/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2691 - accuracy: 0.8946\n",
      "Epoch 374/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2388 - accuracy: 0.9081\n",
      "Epoch 375/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2550 - accuracy: 0.9039\n",
      "Epoch 376/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2678 - accuracy: 0.8976\n",
      "Epoch 377/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2714 - accuracy: 0.8976\n",
      "Epoch 378/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2656 - accuracy: 0.8983\n",
      "Epoch 379/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2429 - accuracy: 0.9087\n",
      "Epoch 380/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2437 - accuracy: 0.9093\n",
      "Epoch 381/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2575 - accuracy: 0.8983\n",
      "Epoch 382/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2551 - accuracy: 0.9001\n",
      "Epoch 383/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2395 - accuracy: 0.9051\n",
      "Epoch 384/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2773 - accuracy: 0.8955\n",
      "Epoch 385/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2680 - accuracy: 0.8938\n",
      "Epoch 386/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2455 - accuracy: 0.9058\n",
      "Epoch 387/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2526 - accuracy: 0.9048\n",
      "Epoch 388/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2717 - accuracy: 0.8951\n",
      "Epoch 389/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2462 - accuracy: 0.9031\n",
      "Epoch 390/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2619 - accuracy: 0.8958\n",
      "Epoch 391/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2401 - accuracy: 0.9058\n",
      "Epoch 392/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2591 - accuracy: 0.9001\n",
      "Epoch 393/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2547 - accuracy: 0.9034\n",
      "Epoch 394/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2623 - accuracy: 0.9010\n",
      "Epoch 395/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2515 - accuracy: 0.9016\n",
      "Epoch 396/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2644 - accuracy: 0.8999\n",
      "Epoch 397/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2440 - accuracy: 0.9064\n",
      "Epoch 398/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2665 - accuracy: 0.8950\n",
      "Epoch 399/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2625 - accuracy: 0.9001\n",
      "Epoch 400/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2439 - accuracy: 0.9054\n",
      "Epoch 401/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2544 - accuracy: 0.9004\n",
      "Epoch 402/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2590 - accuracy: 0.8984\n",
      "Epoch 403/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2541 - accuracy: 0.9023\n",
      "Epoch 404/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2660 - accuracy: 0.8997\n",
      "Epoch 405/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2614 - accuracy: 0.9011\n",
      "Epoch 406/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2560 - accuracy: 0.9008\n",
      "Epoch 407/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2365 - accuracy: 0.9096\n",
      "Epoch 408/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2669 - accuracy: 0.8962\n",
      "Epoch 409/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2643 - accuracy: 0.8986\n",
      "Epoch 410/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2518 - accuracy: 0.9014\n",
      "Epoch 411/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2411 - accuracy: 0.9046\n",
      "Epoch 412/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2593 - accuracy: 0.8986\n",
      "Epoch 413/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2521 - accuracy: 0.9027\n",
      "Epoch 414/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2623 - accuracy: 0.8991\n",
      "Epoch 415/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2507 - accuracy: 0.9081\n",
      "Epoch 416/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2481 - accuracy: 0.9064\n",
      "Epoch 417/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2420 - accuracy: 0.9072\n",
      "Epoch 418/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2427 - accuracy: 0.9098\n",
      "Epoch 419/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2591 - accuracy: 0.8970\n",
      "Epoch 420/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2392 - accuracy: 0.9046\n",
      "Epoch 421/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2663 - accuracy: 0.8997\n",
      "Epoch 422/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2601 - accuracy: 0.9010\n",
      "Epoch 423/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2663 - accuracy: 0.8974\n",
      "Epoch 424/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2536 - accuracy: 0.9072\n",
      "Epoch 425/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2624 - accuracy: 0.8943\n",
      "Epoch 426/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2380 - accuracy: 0.9087\n",
      "Epoch 427/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2438 - accuracy: 0.9057\n",
      "Epoch 428/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2541 - accuracy: 0.9025\n",
      "Epoch 429/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2368 - accuracy: 0.9130\n",
      "Epoch 430/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2307 - accuracy: 0.9058\n",
      "Epoch 431/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2573 - accuracy: 0.9054\n",
      "Epoch 432/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2554 - accuracy: 0.8980\n",
      "Epoch 433/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2436 - accuracy: 0.9026\n",
      "Epoch 434/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2451 - accuracy: 0.9060\n",
      "Epoch 435/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2598 - accuracy: 0.8928\n",
      "Epoch 436/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2774 - accuracy: 0.8922\n",
      "Epoch 437/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2492 - accuracy: 0.9015\n",
      "Epoch 438/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2563 - accuracy: 0.8979\n",
      "Epoch 439/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2543 - accuracy: 0.9030\n",
      "Epoch 440/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2680 - accuracy: 0.8973\n",
      "Epoch 441/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2413 - accuracy: 0.9053\n",
      "Epoch 442/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2441 - accuracy: 0.9023\n",
      "Epoch 443/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2505 - accuracy: 0.9023\n",
      "Epoch 444/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2506 - accuracy: 0.8983\n",
      "Epoch 445/500\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.2603 - accuracy: 0.8987\n",
      "Epoch 446/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2539 - accuracy: 0.8986\n",
      "Epoch 447/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2564 - accuracy: 0.9002\n",
      "Epoch 448/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2481 - accuracy: 0.8991\n",
      "Epoch 449/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2489 - accuracy: 0.9025\n",
      "Epoch 450/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2622 - accuracy: 0.9015\n",
      "Epoch 451/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2563 - accuracy: 0.8965\n",
      "Epoch 452/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2667 - accuracy: 0.8968\n",
      "Epoch 453/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2529 - accuracy: 0.9032\n",
      "Epoch 454/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2491 - accuracy: 0.9028\n",
      "Epoch 455/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2524 - accuracy: 0.8997\n",
      "Epoch 456/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2717 - accuracy: 0.8955\n",
      "Epoch 457/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2729 - accuracy: 0.8925\n",
      "Epoch 458/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2351 - accuracy: 0.9073\n",
      "Epoch 459/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2529 - accuracy: 0.8978\n",
      "Epoch 460/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2505 - accuracy: 0.8980\n",
      "Epoch 461/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2424 - accuracy: 0.9085\n",
      "Epoch 462/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2590 - accuracy: 0.8994\n",
      "Epoch 463/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2599 - accuracy: 0.9002\n",
      "Epoch 464/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2678 - accuracy: 0.8969\n",
      "Epoch 465/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2431 - accuracy: 0.9063\n",
      "Epoch 466/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2579 - accuracy: 0.8975\n",
      "Epoch 467/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2602 - accuracy: 0.9033\n",
      "Epoch 468/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2720 - accuracy: 0.8980\n",
      "Epoch 469/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2248 - accuracy: 0.9080\n",
      "Epoch 470/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2498 - accuracy: 0.8989\n",
      "Epoch 471/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2428 - accuracy: 0.9076\n",
      "Epoch 472/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2505 - accuracy: 0.9021\n",
      "Epoch 473/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2570 - accuracy: 0.8997\n",
      "Epoch 474/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2539 - accuracy: 0.8999\n",
      "Epoch 475/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2492 - accuracy: 0.9055\n",
      "Epoch 476/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2605 - accuracy: 0.8992\n",
      "Epoch 477/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2444 - accuracy: 0.9018\n",
      "Epoch 478/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2530 - accuracy: 0.9032\n",
      "Epoch 479/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2567 - accuracy: 0.8987\n",
      "Epoch 480/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2593 - accuracy: 0.8971\n",
      "Epoch 481/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2232 - accuracy: 0.9091\n",
      "Epoch 482/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2403 - accuracy: 0.9073\n",
      "Epoch 483/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2593 - accuracy: 0.8964\n",
      "Epoch 484/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2491 - accuracy: 0.8995\n",
      "Epoch 485/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2510 - accuracy: 0.8972\n",
      "Epoch 486/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2406 - accuracy: 0.9034\n",
      "Epoch 487/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2377 - accuracy: 0.9085\n",
      "Epoch 488/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2354 - accuracy: 0.9079\n",
      "Epoch 489/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2514 - accuracy: 0.9028\n",
      "Epoch 490/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2591 - accuracy: 0.8962\n",
      "Epoch 491/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2458 - accuracy: 0.9015\n",
      "Epoch 492/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2552 - accuracy: 0.9028\n",
      "Epoch 493/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2540 - accuracy: 0.9002\n",
      "Epoch 494/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2548 - accuracy: 0.9001\n",
      "Epoch 495/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2741 - accuracy: 0.8927\n",
      "Epoch 496/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2578 - accuracy: 0.8992\n",
      "Epoch 497/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2663 - accuracy: 0.8970\n",
      "Epoch 498/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2474 - accuracy: 0.9000\n",
      "Epoch 499/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2412 - accuracy: 0.9049\n",
      "Epoch 500/500\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.2369 - accuracy: 0.9079\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 23, 256)           518912    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 23, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2027)              1039851   \n",
      "=================================================================\n",
      "Total params: 4,184,299\n",
      "Trainable params: 4,184,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 256, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(256,return_sequences=True, kernel_initializer='random_uniform')),\n",
    "    Bidirectional(LSTM(256,return_sequences=False, kernel_initializer='random_uniform')),  \n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_model.fit(xs,ys,epochs=500,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-newcastle",
   "metadata": {},
   "source": [
    "#### Compare with the best results from the previous check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "printable-mercury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Double Bidirectional LSTM layer model 500 epochs 256 units 128 embedding dimensions 0.001 LR</th>\n",
       "      <th>Double Bidirectional LSTM layer model 500 epochs 256 units 256 embedding dimensions 0.001 LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>голяма</td>\n",
       "      <td>голяма лае за да опази не селото а себе си се не се казва се или преувеличава или не раче да вникне в положението</td>\n",
       "      <td>голяма мечка и пак за мишките мислела много се хвали обещава или преувеличава или за нещо несъществено несериозно несъществено несериозно а цялото другиго цялото</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>кърпиш</td>\n",
       "      <td>кърпиш петко празна му торбата трябва да яде яде и сам се да не ти пука да ти пука долния не раче да вникне</td>\n",
       "      <td>кърпиш мляко котките не го лочат сладка у малко зад полето гръб да спи по малко друг а от 30 нагоре го жени цялото</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>магаре</td>\n",
       "      <td>магаре от прякор не умира по горите и скалите а по хората в ръката му парите в положението на всички го червена в другиго</td>\n",
       "      <td>магаре от срам не мре а мокра е лош гората а той се разсърди или един нещо да го отричаш предварително в другиго от</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>жена</td>\n",
       "      <td>жена и съдран калпак лесно се добиват но ще знай видяло не го за опак и неразбран човек го или от хайвера кога другиго</td>\n",
       "      <td>жена и съдран калпак лесно се добиват кома̀та кой ще се върне ли ще е крив негодувание нещо да го отричаш предварително в другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>мъж</td>\n",
       "      <td>мъж под чехъл камък що да закачиш е без бълхата години ли оттам големи поразии прави да го счупим не раче да вникне на</td>\n",
       "      <td>мъж — като лайно на дъжд а се голяма нея ще се разсърди за по умни един от друг а от другиго от другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>бълха</td>\n",
       "      <td>бълха е най скъпата покъщнина баща да е съжаляват — тежко ти ти да не ти с нея парите по висок а върху другиго</td>\n",
       "      <td>бълха се бои да влезе у работлива жена по малко зад полето гръб да спи по малко един един несериозно а от другиго нагоре</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>кучето</td>\n",
       "      <td>кучето скача според тоягата с пари не се купуват а се за опак и неразбран човек в положението на всички го червена в извара</td>\n",
       "      <td>кучето лае за да опази не селото а себе си слагам в нея парите в по висок от друг от 30 нагоре го жени</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>бавно</td>\n",
       "      <td>бавно заек си езика в мозъка тогава акъл давай гащи да е умно — по голямата тояга негодувание твоя гръб и неразбран емоции негодувание</td>\n",
       "      <td>бавно чудо за три дни а той се хвали обещава или преувеличава или преувеличава все да го отричаш предварително в другиго в другиго цялото</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>работа</td>\n",
       "      <td>работа при пари отиват да е умрял как се е въргаляло в праха насред мегдана кога друг го или не раче да вникне накрай</td>\n",
       "      <td>работа не е до колене той се голяма риба той върши се е въргаляло в праха насред мегдана от друг нагоре го жени цялото</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>учи</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал без ръката му парите в 30 нагоре го жени цялото село свършил направя</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал е от хайвера не го женят роднините му а от 30 нагоре го</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>зло</td>\n",
       "      <td>зло не бие мъжа си но лесно го надвива което му трябва да ги продаде често да го счупим не раче да мъжа власт</td>\n",
       "      <td>зло не те лажем прост да те не милва — дваж вика по висок от всички го мегдана а все в положението на другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>добро</td>\n",
       "      <td>добро лозе копа юнак вино пие сляп с едното око да тегли счупим не се крив за нещо несъществено несериозно чернят не бързай да</td>\n",
       "      <td>добро гиздосия булка поразия а той пита колко деца имам кога някой не разбира или не раче да вникне в положението на другиго другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>котка</td>\n",
       "      <td>котка по гърб не пада по далеч не стига е без жълтък стиснат сам си върша работата не го или не раче да гнездо</td>\n",
       "      <td>котка по гърб не пада а за болярина един ще ум струва когато нещо много го чернят не бързай да го отричаш предварително в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>агнето</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите на другите ще сам ще ти е жал гърбът не раче да вникне в положението</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите един цепят през другите зад твоя гръб да вникне в положението на другиго цялото село</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>пешеходец</td>\n",
       "      <td>пешеходец заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго</td>\n",
       "      <td>пешеходец е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>програмиране</td>\n",
       "      <td>програмиране заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго</td>\n",
       "      <td>програмиране е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  \\\n",
       "0         голяма   \n",
       "1         кърпиш   \n",
       "2         магаре   \n",
       "3           жена   \n",
       "4            мъж   \n",
       "5          бълха   \n",
       "6         кучето   \n",
       "7          бавно   \n",
       "8         работа   \n",
       "9            учи   \n",
       "10           зло   \n",
       "11         добро   \n",
       "12         котка   \n",
       "13        агнето   \n",
       "14     пешеходец   \n",
       "15  програмиране   \n",
       "\n",
       "                                                  Double Bidirectional LSTM layer model 500 epochs 256 units 128 embedding dimensions 0.001 LR  \\\n",
       "0                            голяма лае за да опази не селото а себе си се не се казва се или преувеличава или не раче да вникне в положението   \n",
       "1                                  кърпиш петко празна му торбата трябва да яде яде и сам се да не ти пука да ти пука долния не раче да вникне   \n",
       "2                    магаре от прякор не умира по горите и скалите а по хората в ръката му парите в положението на всички го червена в другиго   \n",
       "3                       жена и съдран калпак лесно се добиват но ще знай видяло не го за опак и неразбран човек го или от хайвера кога другиго   \n",
       "4                       мъж под чехъл камък що да закачиш е без бълхата години ли оттам големи поразии прави да го счупим не раче да вникне на   \n",
       "5                               бълха е най скъпата покъщнина баща да е съжаляват — тежко ти ти да не ти с нея парите по висок а върху другиго   \n",
       "6                  кучето скача според тоягата с пари не се купуват а се за опак и неразбран човек в положението на всички го червена в извара   \n",
       "7       бавно заек си езика в мозъка тогава акъл давай гащи да е умно — по голямата тояга негодувание твоя гръб и неразбран емоции негодувание   \n",
       "8                        работа при пари отиват да е умрял как се е въргаляло в праха насред мегдана кога друг го или не раче да вникне накрай   \n",
       "9                              учи се от мал кога остарееш да не ти е жал без ръката му парите в 30 нагоре го жени цялото село свършил направя   \n",
       "10                               зло не бие мъжа си но лесно го надвива което му трябва да ги продаде често да го счупим не раче да мъжа власт   \n",
       "11              добро лозе копа юнак вино пие сляп с едното око да тегли счупим не се крив за нещо несъществено несериозно чернят не бързай да   \n",
       "12                              котка по гърб не пада по далеч не стига е без жълтък стиснат сам си върша работата не го или не раче да гнездо   \n",
       "13                        агнето го гледай по опашката а ярето по гърдите на другите ще сам ще ти е жал гърбът не раче да вникне в положението   \n",
       "14     пешеходец заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго   \n",
       "15  програмиране заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго   \n",
       "\n",
       "                                                                         Double Bidirectional LSTM layer model 500 epochs 256 units 256 embedding dimensions 0.001 LR  \n",
       "0   голяма мечка и пак за мишките мислела много се хвали обещава или преувеличава или за нещо несъществено несериозно несъществено несериозно а цялото другиго цялото  \n",
       "1                                                  кърпиш мляко котките не го лочат сладка у малко зад полето гръб да спи по малко друг а от 30 нагоре го жени цялото  \n",
       "2                                                 магаре от срам не мре а мокра е лош гората а той се разсърди или един нещо да го отричаш предварително в другиго от  \n",
       "3                                   жена и съдран калпак лесно се добиват кома̀та кой ще се върне ли ще е крив негодувание нещо да го отричаш предварително в другиго  \n",
       "4                                                             мъж — като лайно на дъжд а се голяма нея ще се разсърди за по умни един от друг а от другиго от другиго  \n",
       "5                                            бълха се бои да влезе у работлива жена по малко зад полето гръб да спи по малко един един несериозно а от другиго нагоре  \n",
       "6                                                              кучето лае за да опази не селото а себе си слагам в нея парите в по висок от друг от 30 нагоре го жени  \n",
       "7                           бавно чудо за три дни а той се хвали обещава или преувеличава или преувеличава все да го отричаш предварително в другиго в другиго цялото  \n",
       "8                                              работа не е до колене той се голяма риба той върши се е въргаляло в праха насред мегдана от друг нагоре го жени цялото  \n",
       "9                                                                  учи се от мал кога остарееш да не ти е жал е от хайвера не го женят роднините му а от 30 нагоре го  \n",
       "10                                                      зло не те лажем прост да те не милва — дваж вика по висок от всички го мегдана а все в положението на другиго  \n",
       "11                               добро гиздосия булка поразия а той пита колко деца имам кога някой не разбира или не раче да вникне в положението на другиго другиго  \n",
       "12                                          котка по гърб не пада а за болярина един ще ум струва когато нещо много го чернят не бързай да го отричаш предварително в  \n",
       "13                               агнето го гледай по опашката а ярето по гърдите един цепят през другите зад твоя гръб да вникне в положението на другиго цялото село  \n",
       "14                                  пешеходец е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето  \n",
       "15                               програмиране е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_model_result = getPredArray(\n",
    "    double_bilstm_more_epochs_and_units_larger_embedding_dim_model)\n",
    "\n",
    "secondResultDf = pd.DataFrame(index = predWords) \n",
    "secondResultDf.index.name = 'Word'\n",
    "secondResultDf['Word']=secondResultDf.index\n",
    "secondResultDf = secondResultDf.reset_index(drop=True)\n",
    "secondResultDf['Double Bidirectional LSTM layer model 500 epochs 256 units 128 embedding dimensions 0.001 LR'] = double_bilstm_more_epochs_and_units_model_result\n",
    "secondResultDf['Double Bidirectional LSTM layer model 500 epochs 256 units 256 embedding dimensions 0.001 LR'] = double_bilstm_more_epochs_and_units_larger_embedding_dim_model_result\n",
    "secondResultDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-childhood",
   "metadata": {},
   "source": [
    "I can see a slight improvement in the results so I will attempt to increase the embedding dimensions again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-report",
   "metadata": {},
   "source": [
    "#### Double Bidirectional LSTM layer model 500 epochs 256 units 512 embedding dimensions 0.001 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "145/145 [==============================] - 13s 48ms/step - loss: 6.9455 - accuracy: 0.0381\n",
      "Epoch 2/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 6.3632 - accuracy: 0.0428\n",
      "Epoch 3/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 6.2296 - accuracy: 0.0389\n",
      "Epoch 4/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 6.1518 - accuracy: 0.0394\n",
      "Epoch 5/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 6.0568 - accuracy: 0.0495\n",
      "Epoch 6/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 5.9639 - accuracy: 0.0505\n",
      "Epoch 7/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 5.8682 - accuracy: 0.0595\n",
      "Epoch 8/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 5.6949 - accuracy: 0.0680\n",
      "Epoch 9/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 5.6773 - accuracy: 0.0668\n",
      "Epoch 10/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 5.4650 - accuracy: 0.0873\n",
      "Epoch 11/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 5.3179 - accuracy: 0.0934\n",
      "Epoch 12/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 5.2106 - accuracy: 0.1003\n",
      "Epoch 13/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 5.0325 - accuracy: 0.1170\n",
      "Epoch 14/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 4.8613 - accuracy: 0.1206\n",
      "Epoch 15/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 4.8117 - accuracy: 0.1317\n",
      "Epoch 16/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 4.5629 - accuracy: 0.1548\n",
      "Epoch 17/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 4.4651 - accuracy: 0.1573\n",
      "Epoch 18/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 4.2781 - accuracy: 0.1724\n",
      "Epoch 19/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 4.1081 - accuracy: 0.1949\n",
      "Epoch 20/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 4.0554 - accuracy: 0.1975\n",
      "Epoch 21/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 3.8359 - accuracy: 0.2202\n",
      "Epoch 22/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 3.6785 - accuracy: 0.2484\n",
      "Epoch 23/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 3.5509 - accuracy: 0.2611\n",
      "Epoch 24/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 3.3888 - accuracy: 0.2842\n",
      "Epoch 25/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 3.2996 - accuracy: 0.3082\n",
      "Epoch 26/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 3.1774 - accuracy: 0.3216\n",
      "Epoch 27/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 2.9708 - accuracy: 0.3574\n",
      "Epoch 28/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 2.8577 - accuracy: 0.3868\n",
      "Epoch 29/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 2.7303 - accuracy: 0.4083\n",
      "Epoch 30/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 2.5820 - accuracy: 0.4440\n",
      "Epoch 31/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 2.4785 - accuracy: 0.4693\n",
      "Epoch 32/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 2.3763 - accuracy: 0.4764\n",
      "Epoch 33/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 2.2389 - accuracy: 0.5080\n",
      "Epoch 34/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 2.1747 - accuracy: 0.5278\n",
      "Epoch 35/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 2.1182 - accuracy: 0.5231\n",
      "Epoch 36/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 2.0005 - accuracy: 0.5445\n",
      "Epoch 37/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.8346 - accuracy: 0.5941\n",
      "Epoch 38/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.7703 - accuracy: 0.6114\n",
      "Epoch 39/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.6622 - accuracy: 0.6278\n",
      "Epoch 40/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 1.5780 - accuracy: 0.6524\n",
      "Epoch 41/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.5270 - accuracy: 0.6676\n",
      "Epoch 42/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.4044 - accuracy: 0.6874\n",
      "Epoch 43/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 1.3174 - accuracy: 0.7083\n",
      "Epoch 44/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.3222 - accuracy: 0.7016\n",
      "Epoch 45/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 1.2442 - accuracy: 0.7151\n",
      "Epoch 46/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.2254 - accuracy: 0.7196\n",
      "Epoch 47/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.0801 - accuracy: 0.7540\n",
      "Epoch 48/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 1.0176 - accuracy: 0.7725\n",
      "Epoch 49/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.9515 - accuracy: 0.7833\n",
      "Epoch 50/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.9174 - accuracy: 0.7896\n",
      "Epoch 51/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.8942 - accuracy: 0.7915\n",
      "Epoch 52/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.8377 - accuracy: 0.7946\n",
      "Epoch 53/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.8247 - accuracy: 0.8012\n",
      "Epoch 54/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.7840 - accuracy: 0.8096\n",
      "Epoch 55/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.7575 - accuracy: 0.8192\n",
      "Epoch 56/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.7053 - accuracy: 0.8303\n",
      "Epoch 57/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.6745 - accuracy: 0.8281\n",
      "Epoch 58/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.6579 - accuracy: 0.8386\n",
      "Epoch 59/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.6319 - accuracy: 0.8406\n",
      "Epoch 60/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.5997 - accuracy: 0.8520\n",
      "Epoch 61/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.6124 - accuracy: 0.8493\n",
      "Epoch 62/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.5676 - accuracy: 0.8562\n",
      "Epoch 63/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.5557 - accuracy: 0.8598\n",
      "Epoch 64/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.5557 - accuracy: 0.8612\n",
      "Epoch 65/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.5252 - accuracy: 0.8668\n",
      "Epoch 66/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.5126 - accuracy: 0.8696\n",
      "Epoch 67/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.4919 - accuracy: 0.8755\n",
      "Epoch 68/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.4869 - accuracy: 0.8751\n",
      "Epoch 69/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.4710 - accuracy: 0.8734\n",
      "Epoch 70/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.4566 - accuracy: 0.8764\n",
      "Epoch 71/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.4472 - accuracy: 0.8754\n",
      "Epoch 72/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.4186 - accuracy: 0.8833\n",
      "Epoch 73/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.4279 - accuracy: 0.8848\n",
      "Epoch 74/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.4072 - accuracy: 0.8930\n",
      "Epoch 75/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3972 - accuracy: 0.8880\n",
      "Epoch 76/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.4100 - accuracy: 0.8852\n",
      "Epoch 77/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.4240 - accuracy: 0.8852\n",
      "Epoch 78/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.4124 - accuracy: 0.8903\n",
      "Epoch 79/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3911 - accuracy: 0.8856\n",
      "Epoch 80/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3909 - accuracy: 0.8925\n",
      "Epoch 81/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.3557 - accuracy: 0.8939\n",
      "Epoch 82/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.3714 - accuracy: 0.8883\n",
      "Epoch 83/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3883 - accuracy: 0.8871\n",
      "Epoch 84/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3765 - accuracy: 0.8847\n",
      "Epoch 85/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3747 - accuracy: 0.8930\n",
      "Epoch 86/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3440 - accuracy: 0.8970\n",
      "Epoch 87/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.3606 - accuracy: 0.8935\n",
      "Epoch 88/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.3367 - accuracy: 0.8939\n",
      "Epoch 89/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3706 - accuracy: 0.8898\n",
      "Epoch 90/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3416 - accuracy: 0.9029\n",
      "Epoch 91/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.3194 - accuracy: 0.9044\n",
      "Epoch 92/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3424 - accuracy: 0.9012\n",
      "Epoch 93/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2778 - accuracy: 0.8973\n",
      "Epoch 186/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2655 - accuracy: 0.9006\n",
      "Epoch 187/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2643 - accuracy: 0.9042\n",
      "Epoch 188/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2661 - accuracy: 0.9011\n",
      "Epoch 189/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2622 - accuracy: 0.9061\n",
      "Epoch 190/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2458 - accuracy: 0.9063\n",
      "Epoch 191/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2640 - accuracy: 0.9057\n",
      "Epoch 192/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2696 - accuracy: 0.8996\n",
      "Epoch 193/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2658 - accuracy: 0.9040\n",
      "Epoch 194/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2769 - accuracy: 0.8928\n",
      "Epoch 195/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2587 - accuracy: 0.9025\n",
      "Epoch 196/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2430 - accuracy: 0.9121\n",
      "Epoch 197/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2505 - accuracy: 0.9061\n",
      "Epoch 198/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2528 - accuracy: 0.9066\n",
      "Epoch 199/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2599 - accuracy: 0.9037\n",
      "Epoch 200/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2646 - accuracy: 0.9003\n",
      "Epoch 201/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2623 - accuracy: 0.9059\n",
      "Epoch 202/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2686 - accuracy: 0.8999\n",
      "Epoch 203/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2535 - accuracy: 0.9061\n",
      "Epoch 204/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2697 - accuracy: 0.8975\n",
      "Epoch 205/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2693 - accuracy: 0.9005\n",
      "Epoch 206/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2581 - accuracy: 0.9030\n",
      "Epoch 207/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2428 - accuracy: 0.9093\n",
      "Epoch 208/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2490 - accuracy: 0.9040\n",
      "Epoch 209/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2524 - accuracy: 0.9034\n",
      "Epoch 210/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2447 - accuracy: 0.9117\n",
      "Epoch 211/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2512 - accuracy: 0.9040\n",
      "Epoch 212/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2539 - accuracy: 0.9073\n",
      "Epoch 213/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2737 - accuracy: 0.8994\n",
      "Epoch 214/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2442 - accuracy: 0.9077\n",
      "Epoch 215/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2555 - accuracy: 0.9007\n",
      "Epoch 216/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2564 - accuracy: 0.9069\n",
      "Epoch 217/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2503 - accuracy: 0.9030\n",
      "Epoch 218/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2421 - accuracy: 0.9044\n",
      "Epoch 219/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2631 - accuracy: 0.9017\n",
      "Epoch 220/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2342 - accuracy: 0.9035\n",
      "Epoch 221/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2613 - accuracy: 0.8997\n",
      "Epoch 222/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2638 - accuracy: 0.8981\n",
      "Epoch 223/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2432 - accuracy: 0.9079\n",
      "Epoch 224/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2396 - accuracy: 0.9056\n",
      "Epoch 225/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2559 - accuracy: 0.9000\n",
      "Epoch 226/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2545 - accuracy: 0.9029\n",
      "Epoch 227/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2620 - accuracy: 0.8995\n",
      "Epoch 228/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2452 - accuracy: 0.9009\n",
      "Epoch 229/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2641 - accuracy: 0.9050\n",
      "Epoch 230/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2346 - accuracy: 0.9140\n",
      "Epoch 231/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2539 - accuracy: 0.9042\n",
      "Epoch 232/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2559 - accuracy: 0.8972\n",
      "Epoch 233/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2552 - accuracy: 0.9044\n",
      "Epoch 234/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2481 - accuracy: 0.9000\n",
      "Epoch 235/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2506 - accuracy: 0.9028\n",
      "Epoch 236/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2399 - accuracy: 0.9068\n",
      "Epoch 237/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2451 - accuracy: 0.9017\n",
      "Epoch 238/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2726 - accuracy: 0.8966\n",
      "Epoch 239/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2435 - accuracy: 0.9049\n",
      "Epoch 240/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2586 - accuracy: 0.9042\n",
      "Epoch 241/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2557 - accuracy: 0.8993\n",
      "Epoch 242/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2377 - accuracy: 0.9066\n",
      "Epoch 264/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2269 - accuracy: 0.9112\n",
      "Epoch 265/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2293 - accuracy: 0.9092\n",
      "Epoch 266/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2434 - accuracy: 0.9059\n",
      "Epoch 267/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2414 - accuracy: 0.9097\n",
      "Epoch 268/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2383 - accuracy: 0.9077\n",
      "Epoch 269/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2263 - accuracy: 0.9143\n",
      "Epoch 270/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2535 - accuracy: 0.9039\n",
      "Epoch 271/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2419 - accuracy: 0.9040\n",
      "Epoch 272/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2232 - accuracy: 0.9132\n",
      "Epoch 273/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2481 - accuracy: 0.9051\n",
      "Epoch 274/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2551 - accuracy: 0.9036\n",
      "Epoch 275/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2597 - accuracy: 0.9015\n",
      "Epoch 276/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2495 - accuracy: 0.8996\n",
      "Epoch 277/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2630 - accuracy: 0.8983\n",
      "Epoch 278/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2422 - accuracy: 0.9011\n",
      "Epoch 279/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2388 - accuracy: 0.9045\n",
      "Epoch 280/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2354 - accuracy: 0.9110\n",
      "Epoch 281/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2541 - accuracy: 0.8996\n",
      "Epoch 282/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2541 - accuracy: 0.9036\n",
      "Epoch 283/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2498 - accuracy: 0.9000\n",
      "Epoch 284/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2264 - accuracy: 0.9081\n",
      "Epoch 285/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2446 - accuracy: 0.9037\n",
      "Epoch 286/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2370 - accuracy: 0.9041\n",
      "Epoch 287/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2348 - accuracy: 0.9117\n",
      "Epoch 288/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2659 - accuracy: 0.9000\n",
      "Epoch 289/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2423 - accuracy: 0.9065\n",
      "Epoch 290/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2357 - accuracy: 0.9085\n",
      "Epoch 291/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2335 - accuracy: 0.9094\n",
      "Epoch 292/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2487 - accuracy: 0.8991\n",
      "Epoch 293/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2481 - accuracy: 0.8986\n",
      "Epoch 294/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2408 - accuracy: 0.9072\n",
      "Epoch 295/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2293 - accuracy: 0.9046\n",
      "Epoch 296/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2179 - accuracy: 0.9123\n",
      "Epoch 297/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2414 - accuracy: 0.9044\n",
      "Epoch 298/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2447 - accuracy: 0.9021\n",
      "Epoch 326/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2367 - accuracy: 0.9111\n",
      "Epoch 327/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2267 - accuracy: 0.9107\n",
      "Epoch 328/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2346 - accuracy: 0.9140\n",
      "Epoch 329/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2554 - accuracy: 0.8983\n",
      "Epoch 330/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2446 - accuracy: 0.9068\n",
      "Epoch 331/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2520 - accuracy: 0.9028\n",
      "Epoch 332/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2689 - accuracy: 0.8935\n",
      "Epoch 333/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2404 - accuracy: 0.9035\n",
      "Epoch 334/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2478 - accuracy: 0.8999\n",
      "Epoch 335/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2468 - accuracy: 0.9029\n",
      "Epoch 336/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2338 - accuracy: 0.9072\n",
      "Epoch 337/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2383 - accuracy: 0.9052\n",
      "Epoch 338/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2414 - accuracy: 0.9079\n",
      "Epoch 339/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2343 - accuracy: 0.9104\n",
      "Epoch 340/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2324 - accuracy: 0.9033\n",
      "Epoch 341/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2396 - accuracy: 0.8994\n",
      "Epoch 342/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2592 - accuracy: 0.8951\n",
      "Epoch 343/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2472 - accuracy: 0.9045\n",
      "Epoch 344/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2482 - accuracy: 0.9027\n",
      "Epoch 345/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2225 - accuracy: 0.9140\n",
      "Epoch 346/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2283 - accuracy: 0.9091\n",
      "Epoch 347/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2513 - accuracy: 0.9019\n",
      "Epoch 348/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2382 - accuracy: 0.9033\n",
      "Epoch 349/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2422 - accuracy: 0.9048\n",
      "Epoch 350/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2408 - accuracy: 0.9049\n",
      "Epoch 351/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2467 - accuracy: 0.9056\n",
      "Epoch 352/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2237 - accuracy: 0.9076\n",
      "Epoch 353/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2346 - accuracy: 0.9049\n",
      "Epoch 354/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2346 - accuracy: 0.9048\n",
      "Epoch 355/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2450 - accuracy: 0.9020\n",
      "Epoch 356/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2304 - accuracy: 0.9071\n",
      "Epoch 357/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2440 - accuracy: 0.9017\n",
      "Epoch 358/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2343 - accuracy: 0.9086\n",
      "Epoch 359/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2162 - accuracy: 0.9188\n",
      "Epoch 360/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2427 - accuracy: 0.9052\n",
      "Epoch 361/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2433 - accuracy: 0.9089\n",
      "Epoch 362/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2645 - accuracy: 0.8951\n",
      "Epoch 363/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2437 - accuracy: 0.9046\n",
      "Epoch 364/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2453 - accuracy: 0.9036\n",
      "Epoch 365/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2304 - accuracy: 0.9058\n",
      "Epoch 366/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2469 - accuracy: 0.9036\n",
      "Epoch 367/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2540 - accuracy: 0.8993\n",
      "Epoch 368/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2272 - accuracy: 0.9099\n",
      "Epoch 369/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2339 - accuracy: 0.9058\n",
      "Epoch 370/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2477 - accuracy: 0.9027\n",
      "Epoch 371/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2395 - accuracy: 0.9037\n",
      "Epoch 372/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2409 - accuracy: 0.9009\n",
      "Epoch 373/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2394 - accuracy: 0.9043\n",
      "Epoch 374/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2152 - accuracy: 0.9156\n",
      "Epoch 375/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2349 - accuracy: 0.9096\n",
      "Epoch 376/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2444 - accuracy: 0.9029\n",
      "Epoch 377/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2403 - accuracy: 0.9041\n",
      "Epoch 378/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2369 - accuracy: 0.9062\n",
      "Epoch 379/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2246 - accuracy: 0.9072\n",
      "Epoch 380/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2413 - accuracy: 0.9064\n",
      "Epoch 381/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2492 - accuracy: 0.9029\n",
      "Epoch 382/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2426 - accuracy: 0.9014\n",
      "Epoch 383/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2233 - accuracy: 0.9130\n",
      "Epoch 384/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2536 - accuracy: 0.8954\n",
      "Epoch 385/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2412 - accuracy: 0.8992\n",
      "Epoch 386/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2234 - accuracy: 0.9124\n",
      "Epoch 387/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2289 - accuracy: 0.9054\n",
      "Epoch 388/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2428 - accuracy: 0.9020\n",
      "Epoch 389/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2264 - accuracy: 0.9113\n",
      "Epoch 390/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2405 - accuracy: 0.9005\n",
      "Epoch 391/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2228 - accuracy: 0.9106\n",
      "Epoch 392/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2468 - accuracy: 0.8982\n",
      "Epoch 393/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2300 - accuracy: 0.9054\n",
      "Epoch 394/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2427 - accuracy: 0.9038\n",
      "Epoch 395/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2273 - accuracy: 0.9100\n",
      "Epoch 396/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2320 - accuracy: 0.9077\n",
      "Epoch 397/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2192 - accuracy: 0.9183\n",
      "Epoch 398/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2408 - accuracy: 0.9023\n",
      "Epoch 399/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2426 - accuracy: 0.9021\n",
      "Epoch 400/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2270 - accuracy: 0.9070\n",
      "Epoch 401/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2299 - accuracy: 0.9044\n",
      "Epoch 402/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2348 - accuracy: 0.9049\n",
      "Epoch 403/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2470 - accuracy: 0.8991\n",
      "Epoch 404/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2472 - accuracy: 0.8965\n",
      "Epoch 405/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2291 - accuracy: 0.9080\n",
      "Epoch 406/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2275 - accuracy: 0.9076\n",
      "Epoch 407/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2239 - accuracy: 0.9128\n",
      "Epoch 408/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2499 - accuracy: 0.9035\n",
      "Epoch 409/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2468 - accuracy: 0.8986\n",
      "Epoch 410/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2425 - accuracy: 0.9023\n",
      "Epoch 411/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2280 - accuracy: 0.9096\n",
      "Epoch 412/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2206 - accuracy: 0.9120\n",
      "Epoch 413/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2265 - accuracy: 0.9089\n",
      "Epoch 414/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2409 - accuracy: 0.9043\n",
      "Epoch 415/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2293 - accuracy: 0.9053\n",
      "Epoch 416/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2633 - accuracy: 0.8961\n",
      "Epoch 417/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2281 - accuracy: 0.9103\n",
      "Epoch 418/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2297 - accuracy: 0.9089\n",
      "Epoch 419/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2336 - accuracy: 0.9015\n",
      "Epoch 420/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2275 - accuracy: 0.9114\n",
      "Epoch 421/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2468 - accuracy: 0.9027\n",
      "Epoch 422/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2340 - accuracy: 0.9103\n",
      "Epoch 423/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2409 - accuracy: 0.9004\n",
      "Epoch 424/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2316 - accuracy: 0.9054\n",
      "Epoch 425/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2402 - accuracy: 0.9036\n",
      "Epoch 426/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2188 - accuracy: 0.9122\n",
      "Epoch 427/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2251 - accuracy: 0.9102\n",
      "Epoch 428/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2314 - accuracy: 0.9040\n",
      "Epoch 429/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2162 - accuracy: 0.9103\n",
      "Epoch 430/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2228 - accuracy: 0.9078\n",
      "Epoch 431/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2407 - accuracy: 0.8979\n",
      "Epoch 432/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2430 - accuracy: 0.8963\n",
      "Epoch 433/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2186 - accuracy: 0.9103\n",
      "Epoch 434/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2285 - accuracy: 0.9088\n",
      "Epoch 435/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2304 - accuracy: 0.9043\n",
      "Epoch 436/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2513 - accuracy: 0.8930\n",
      "Epoch 437/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2268 - accuracy: 0.9042\n",
      "Epoch 438/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2466 - accuracy: 0.9013\n",
      "Epoch 439/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2281 - accuracy: 0.9107\n",
      "Epoch 440/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2494 - accuracy: 0.9016\n",
      "Epoch 441/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2133 - accuracy: 0.9097\n",
      "Epoch 442/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2281 - accuracy: 0.9033\n",
      "Epoch 443/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2335 - accuracy: 0.9049\n",
      "Epoch 444/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2337 - accuracy: 0.9015\n",
      "Epoch 445/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2462 - accuracy: 0.8949\n",
      "Epoch 446/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2302 - accuracy: 0.9051\n",
      "Epoch 447/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2489 - accuracy: 0.8953\n",
      "Epoch 448/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2406 - accuracy: 0.9027\n",
      "Epoch 449/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2306 - accuracy: 0.9069\n",
      "Epoch 450/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2313 - accuracy: 0.9056\n",
      "Epoch 451/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2383 - accuracy: 0.8999\n",
      "Epoch 452/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2256 - accuracy: 0.9090\n",
      "Epoch 453/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2295 - accuracy: 0.9037\n",
      "Epoch 454/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2191 - accuracy: 0.9104\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2272 - accuracy: 0.9094\n",
      "Epoch 456/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2495 - accuracy: 0.8953\n",
      "Epoch 457/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2547 - accuracy: 0.8990\n",
      "Epoch 458/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2166 - accuracy: 0.9106\n",
      "Epoch 459/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2338 - accuracy: 0.9063\n",
      "Epoch 460/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2415 - accuracy: 0.9001\n",
      "Epoch 461/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2278 - accuracy: 0.9046\n",
      "Epoch 462/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2312 - accuracy: 0.9110\n",
      "Epoch 463/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2441 - accuracy: 0.9027\n",
      "Epoch 464/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2616 - accuracy: 0.8971\n",
      "Epoch 465/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2276 - accuracy: 0.9030\n",
      "Epoch 466/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2394 - accuracy: 0.9007\n",
      "Epoch 467/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2313 - accuracy: 0.9059\n",
      "Epoch 468/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2511 - accuracy: 0.8979\n",
      "Epoch 469/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2178 - accuracy: 0.9082\n",
      "Epoch 470/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2258 - accuracy: 0.9069\n",
      "Epoch 471/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2323 - accuracy: 0.9086\n",
      "Epoch 472/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2361 - accuracy: 0.9047\n",
      "Epoch 473/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2429 - accuracy: 0.9014\n",
      "Epoch 474/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2329 - accuracy: 0.9089\n",
      "Epoch 475/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2314 - accuracy: 0.9071\n",
      "Epoch 476/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2490 - accuracy: 0.8967\n",
      "Epoch 477/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2332 - accuracy: 0.9047\n",
      "Epoch 478/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2271 - accuracy: 0.9084\n",
      "Epoch 479/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2426 - accuracy: 0.8959\n",
      "Epoch 480/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2371 - accuracy: 0.9040\n",
      "Epoch 481/500\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.2201 - accuracy: 0.9101\n",
      "Epoch 482/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2311 - accuracy: 0.9013\n",
      "Epoch 483/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2358 - accuracy: 0.9034\n",
      "Epoch 484/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2361 - accuracy: 0.9041\n",
      "Epoch 485/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2390 - accuracy: 0.9023\n",
      "Epoch 486/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2272 - accuracy: 0.9065\n",
      "Epoch 487/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2319 - accuracy: 0.9077\n",
      "Epoch 488/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2196 - accuracy: 0.9113\n",
      "Epoch 489/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2294 - accuracy: 0.9039\n",
      "Epoch 490/500\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.2323 - accuracy: 0.9071\n",
      "Epoch 491/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2330 - accuracy: 0.9043\n",
      "Epoch 492/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2388 - accuracy: 0.9031\n",
      "Epoch 493/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2326 - accuracy: 0.9081\n",
      "Epoch 494/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2313 - accuracy: 0.9034\n",
      "Epoch 495/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2500 - accuracy: 0.9008\n",
      "Epoch 496/500\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.2402 - accuracy: 0.9026\n",
      "Epoch 497/500\n",
      "137/145 [===========================>..] - ETA: 0s - loss: 0.2414 - accuracy: 0.9046"
     ]
    }
   ],
   "source": [
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model = Sequential([\n",
    "    Embedding(TOTAL_WORDS, 512, input_length=MAX_SEQ_LEN-1),\n",
    "    Dropout(.5),\n",
    "    Bidirectional(LSTM(256,return_sequences=True, kernel_initializer='random_uniform')),\n",
    "    Bidirectional(LSTM(256,return_sequences=False, kernel_initializer='random_uniform')),  \n",
    "    Dropout(.5),\n",
    "    Dense(TOTAL_WORDS, activation='softmax')\n",
    "])\n",
    "\n",
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model.fit(xs,ys,epochs=500,verbose=1, callbacks = [TensorBoard()])\n",
    "\n",
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-clarity",
   "metadata": {},
   "source": [
    "#### Compare with the best results from the previous check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "exposed-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Double Bidirectional LSTM layer model 500 epochs 256 units 128 embedding dimensions 0.001 LR</th>\n",
       "      <th>Double Bidirectional LSTM layer model 500 epochs 256 units 256 embedding dimensions 0.001 LR</th>\n",
       "      <th>Double Bidirectional LSTM layer model 500 epochs 256 units 512 embedding dimensions 0.001 LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>голяма</td>\n",
       "      <td>голяма лае за да опази не селото а себе си се не се казва се или преувеличава или не раче да вникне в положението</td>\n",
       "      <td>голяма мечка и пак за мишките мислела много се хвали обещава или преувеличава или за нещо несъществено несериозно несъществено несериозно а цялото другиго цялото</td>\n",
       "      <td>голяма мечка с мравки не се насища а се познава той ще сполучи рога му минава му трябва да яде а като се качват</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>кърпиш</td>\n",
       "      <td>кърпиш петко празна му торбата трябва да яде яде и сам се да не ти пука да ти пука долния не раче да вникне</td>\n",
       "      <td>кърпиш мляко котките не го лочат сладка у малко зад полето гръб да спи по малко друг а от 30 нагоре го жени цялото</td>\n",
       "      <td>кърпиш се раждат хора а умират магарета през свинско а се отнема с иглата а се познава по малко хитрувай тояга от 30 нагоре</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>магаре</td>\n",
       "      <td>магаре от прякор не умира по горите и скалите а по хората в ръката му парите в положението на всички го червена в другиго</td>\n",
       "      <td>магаре от срам не мре а мокра е лош гората а той се разсърди или един нещо да го отричаш предварително в другиго от</td>\n",
       "      <td>магаре от срам не разбира само — вика но не се вари леща ли ще го направи пука му го да го отричаш другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>жена</td>\n",
       "      <td>жена и съдран калпак лесно се добиват но ще знай видяло не го за опак и неразбран човек го или от хайвера кога другиго</td>\n",
       "      <td>жена и съдран калпак лесно се добиват кома̀та кой ще се върне ли ще е крив негодувание нещо да го отричаш предварително в другиго</td>\n",
       "      <td>жена и кокошка синор нямат пари и все е и с пари да дават да ти е як да не ти пука другиго и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>мъж</td>\n",
       "      <td>мъж под чехъл камък що да закачиш е без бълхата години ли оттам големи поразии прави да го счупим не раче да вникне на</td>\n",
       "      <td>мъж — като лайно на дъжд а се голяма нея ще се разсърди за по умни един от друг а от другиго от другиго</td>\n",
       "      <td>мъж — като лайно на дъжд а керемидчията — слънце се качват други слизат е голяма за утре не се в праха насред другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>бълха</td>\n",
       "      <td>бълха е най скъпата покъщнина баща да е съжаляват — тежко ти ти да не ти с нея парите по висок а върху другиго</td>\n",
       "      <td>бълха се бои да влезе у работлива жена по малко зад полето гръб да спи по малко един един несериозно а от другиго нагоре</td>\n",
       "      <td>бълха не пада по далеч не стига но далеч не стига но — дваж вика под праха му го в положението на другиго мед</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>кучето</td>\n",
       "      <td>кучето скача според тоягата с пари не се купуват а се за опак и неразбран човек в положението на всички го червена в извара</td>\n",
       "      <td>кучето лае за да опази не селото а себе си слагам в нея парите в по висок от друг от 30 нагоре го жени</td>\n",
       "      <td>кучето скача според тоягата виновната котка ще избяга умира и той цяло вдига шум разтръбява и предизвиква емоции негодувание възмущение за нещо несъществено несериозно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>бавно</td>\n",
       "      <td>бавно заек си езика в мозъка тогава акъл давай гащи да е умно — по голямата тояга негодувание твоя гръб и неразбран емоции негодувание</td>\n",
       "      <td>бавно чудо за три дни а той се хвали обещава или преувеличава или преувеличава все да го отричаш предварително в другиго в другиго цялото</td>\n",
       "      <td>бавно камъчето си хвали своите метли го мързи отдавна да е умрял не го яде а го чернят не бързай да го отричаш предварително</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>работа</td>\n",
       "      <td>работа при пари отиват да е умрял как се е въргаляло в праха насред мегдана кога друг го или не раче да вникне накрай</td>\n",
       "      <td>работа не е до колене той се голяма риба той върши се е въргаляло в праха насред мегдана от друг нагоре го жени цялото</td>\n",
       "      <td>работа не се хубавее а се гърбавее през стария го уловил я никне в ръката му се познава а му го му го го</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>учи</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал без ръката му парите в 30 нагоре го жени цялото село свършил направя</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал е от хайвера не го женят роднините му а от 30 нагоре го</td>\n",
       "      <td>учи се от мал кога остарееш да не ти е жал а му торбата му е и сам в праха насред мегдана го възмущение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>зло</td>\n",
       "      <td>зло не бие мъжа си но лесно го надвива което му трябва да ги продаде често да го счупим не раче да мъжа власт</td>\n",
       "      <td>зло не те лажем прост да те не милва — дваж вика по висок от всички го мегдана а все в положението на другиго</td>\n",
       "      <td>зло не се вади за рогата а му се да не е който прави ножове а който убива с тях мед тояга другиго другиго</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>добро</td>\n",
       "      <td>добро лозе копа юнак вино пие сляп с едното око да тегли счупим не се крив за нещо несъществено несериозно чернят не бързай да</td>\n",
       "      <td>добро гиздосия булка поразия а той пита колко деца имам кога някой не разбира или не раче да вникне в положението на другиго другиго</td>\n",
       "      <td>добро и насън си изкарва хляба да ядеш е як гърбът гърбът да го срещаш мед — голяма нещо ли го срещнеш несъществено несериозно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>котка</td>\n",
       "      <td>котка по гърб не пада по далеч не стига е без жълтък стиснат сам си върша работата не го или не раче да гнездо</td>\n",
       "      <td>котка по гърб не пада а за болярина един ще ум струва когато нещо много го чернят не бързай да го отричаш предварително в</td>\n",
       "      <td>котка по гърб не пада по далеч от дървото се стига — под праха насред мегдана го жени цялото село нещо го несериозно цялото</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>агнето</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите на другите ще сам ще ти е жал гърбът не раче да вникне в положението</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите един цепят през другите зад твоя гръб да вникне в положението на другиго цялото село</td>\n",
       "      <td>агнето го гледай по опашката а ярето по гърдите зад по голямата око за око така като че ли ще умреш утре ли го</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>пешеходец</td>\n",
       "      <td>пешеходец заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго</td>\n",
       "      <td>пешеходец е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето</td>\n",
       "      <td>пешеходец вечер се разработват дано рада излезе мома опашка му го от хайвера та й го трябва да го живеем му му му му</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>програмиране</td>\n",
       "      <td>програмиране заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго</td>\n",
       "      <td>програмиране е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето</td>\n",
       "      <td>програмиране вечер се разработват дано рада излезе мома опашка му го от хайвера та й го трябва да го живеем му му му му</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  \\\n",
       "0         голяма   \n",
       "1         кърпиш   \n",
       "2         магаре   \n",
       "3           жена   \n",
       "4            мъж   \n",
       "5          бълха   \n",
       "6         кучето   \n",
       "7          бавно   \n",
       "8         работа   \n",
       "9            учи   \n",
       "10           зло   \n",
       "11         добро   \n",
       "12         котка   \n",
       "13        агнето   \n",
       "14     пешеходец   \n",
       "15  програмиране   \n",
       "\n",
       "                                                  Double Bidirectional LSTM layer model 500 epochs 256 units 128 embedding dimensions 0.001 LR  \\\n",
       "0                            голяма лае за да опази не селото а себе си се не се казва се или преувеличава или не раче да вникне в положението   \n",
       "1                                  кърпиш петко празна му торбата трябва да яде яде и сам се да не ти пука да ти пука долния не раче да вникне   \n",
       "2                    магаре от прякор не умира по горите и скалите а по хората в ръката му парите в положението на всички го червена в другиго   \n",
       "3                       жена и съдран калпак лесно се добиват но ще знай видяло не го за опак и неразбран човек го или от хайвера кога другиго   \n",
       "4                       мъж под чехъл камък що да закачиш е без бълхата години ли оттам големи поразии прави да го счупим не раче да вникне на   \n",
       "5                               бълха е най скъпата покъщнина баща да е съжаляват — тежко ти ти да не ти с нея парите по висок а върху другиго   \n",
       "6                  кучето скача според тоягата с пари не се купуват а се за опак и неразбран човек в положението на всички го червена в извара   \n",
       "7       бавно заек си езика в мозъка тогава акъл давай гащи да е умно — по голямата тояга негодувание твоя гръб и неразбран емоции негодувание   \n",
       "8                        работа при пари отиват да е умрял как се е въргаляло в праха насред мегдана кога друг го или не раче да вникне накрай   \n",
       "9                              учи се от мал кога остарееш да не ти е жал без ръката му парите в 30 нагоре го жени цялото село свършил направя   \n",
       "10                               зло не бие мъжа си но лесно го надвива което му трябва да ги продаде често да го счупим не раче да мъжа власт   \n",
       "11              добро лозе копа юнак вино пие сляп с едното око да тегли счупим не се крив за нещо несъществено несериозно чернят не бързай да   \n",
       "12                              котка по гърб не пада по далеч не стига е без жълтък стиснат сам си върша работата не го или не раче да гнездо   \n",
       "13                        агнето го гледай по опашката а ярето по гърдите на другите ще сам ще ти е жал гърбът не раче да вникне в положението   \n",
       "14     пешеходец заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго   \n",
       "15  програмиране заек е колкото сладка толкова и горчива ми е и от хайвера умира да пикае цялото село нещо да го отричаш предварително другиго   \n",
       "\n",
       "                                                                         Double Bidirectional LSTM layer model 500 epochs 256 units 256 embedding dimensions 0.001 LR  \\\n",
       "0   голяма мечка и пак за мишките мислела много се хвали обещава или преувеличава или за нещо несъществено несериозно несъществено несериозно а цялото другиго цялото   \n",
       "1                                                  кърпиш мляко котките не го лочат сладка у малко зад полето гръб да спи по малко друг а от 30 нагоре го жени цялото   \n",
       "2                                                 магаре от срам не мре а мокра е лош гората а той се разсърди или един нещо да го отричаш предварително в другиго от   \n",
       "3                                   жена и съдран калпак лесно се добиват кома̀та кой ще се върне ли ще е крив негодувание нещо да го отричаш предварително в другиго   \n",
       "4                                                             мъж — като лайно на дъжд а се голяма нея ще се разсърди за по умни един от друг а от другиго от другиго   \n",
       "5                                            бълха се бои да влезе у работлива жена по малко зад полето гръб да спи по малко един един несериозно а от другиго нагоре   \n",
       "6                                                              кучето лае за да опази не селото а себе си слагам в нея парите в по висок от друг от 30 нагоре го жени   \n",
       "7                           бавно чудо за три дни а той се хвали обещава или преувеличава или преувеличава все да го отричаш предварително в другиго в другиго цялото   \n",
       "8                                              работа не е до колене той се голяма риба той върши се е въргаляло в праха насред мегдана от друг нагоре го жени цялото   \n",
       "9                                                                  учи се от мал кога остарееш да не ти е жал е от хайвера не го женят роднините му а от 30 нагоре го   \n",
       "10                                                      зло не те лажем прост да те не милва — дваж вика по висок от всички го мегдана а все в положението на другиго   \n",
       "11                               добро гиздосия булка поразия а той пита колко деца имам кога някой не разбира или не раче да вникне в положението на другиго другиго   \n",
       "12                                          котка по гърб не пада а за болярина един ще ум струва когато нещо много го чернят не бързай да го отричаш предварително в   \n",
       "13                               агнето го гледай по опашката а ярето по гърдите един цепят през другите зад твоя гръб да вникне в положението на другиго цялото село   \n",
       "14                                  пешеходец е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето   \n",
       "15                               програмиране е на гърба си има очи чест са невястата пари струва върши е по голямата тояга един несериозно а друг цялото село своето   \n",
       "\n",
       "                                                                               Double Bidirectional LSTM layer model 500 epochs 256 units 512 embedding dimensions 0.001 LR  \n",
       "0                                                           голяма мечка с мравки не се насища а се познава той ще сполучи рога му минава му трябва да яде а като се качват  \n",
       "1                                               кърпиш се раждат хора а умират магарета през свинско а се отнема с иглата а се познава по малко хитрувай тояга от 30 нагоре  \n",
       "2                                                                магаре от срам не разбира само — вика но не се вари леща ли ще го направи пука му го да го отричаш другиго  \n",
       "3                                                                              жена и кокошка синор нямат пари и все е и с пари да дават да ти е як да не ти пука другиго и  \n",
       "4                                                     мъж — като лайно на дъжд а керемидчията — слънце се качват други слизат е голяма за утре не се в праха насред другиго  \n",
       "5                                                             бълха не пада по далеч не стига но далеч не стига но — дваж вика под праха му го в положението на другиго мед  \n",
       "6   кучето скача според тоягата виновната котка ще избяга умира и той цяло вдига шум разтръбява и предизвиква емоции негодувание възмущение за нещо несъществено несериозно  \n",
       "7                                              бавно камъчето си хвали своите метли го мързи отдавна да е умрял не го яде а го чернят не бързай да го отричаш предварително  \n",
       "8                                                                  работа не се хубавее а се гърбавее през стария го уловил я никне в ръката му се познава а му го му го го  \n",
       "9                                                                   учи се от мал кога остарееш да не ти е жал а му торбата му е и сам в праха насред мегдана го възмущение  \n",
       "10                                                                зло не се вади за рогата а му се да не е който прави ножове а който убива с тях мед тояга другиго другиго  \n",
       "11                                           добро и насън си изкарва хляба да ядеш е як гърбът гърбът да го срещаш мед — голяма нещо ли го срещнеш несъществено несериозно  \n",
       "12                                              котка по гърб не пада по далеч от дървото се стига — под праха насред мегдана го жени цялото село нещо го несериозно цялото  \n",
       "13                                                           агнето го гледай по опашката а ярето по гърдите зад по голямата око за око така като че ли ще умреш утре ли го  \n",
       "14                                                     пешеходец вечер се разработват дано рада излезе мома опашка му го от хайвера та й го трябва да го живеем му му му му  \n",
       "15                                                  програмиране вечер се разработват дано рада излезе мома опашка му го от хайвера та й го трябва да го живеем му му му му  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model_result = getPredArray(\n",
    "    double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model)\n",
    "\n",
    "secondResultDf['Double Bidirectional LSTM layer model 500 epochs 256 units 512 embedding dimensions 0.001 LR'] = double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model_result\n",
    "secondResultDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-medline",
   "metadata": {},
   "source": [
    "There is an improvement of the predictions once again. The Double Bidirectional LSTM layer model 500 epochs 256 units 512 embedding dimensions 0.001 LR predictions make the most sense to me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-graham",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-specialist",
   "metadata": {},
   "source": [
    "Due to the low amount of Bulgarian proverb data and the fact that I have a limted amount of time, I will have to settle for these models and more precisely for the Double Bidirectional LSTM layer model 500 epochs 256 units 512 embedding dimensions 0.001 LR model. <br> I will try to make use of the generated data in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-approval",
   "metadata": {},
   "source": [
    "## Section II: Generate English proverbs based on the previous results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-replacement",
   "metadata": {},
   "source": [
    "#### NOTE: Please feel free to skip to the end of this section to view the [Translation Results](#translation_cell)\n",
    "I have followed the example provided by Tensorflow for the code below (I have made very slight modifications). My intention was to experiment by combining the results of the previous section with a translation model. What interested me is whether or not I can generate some interesting English proverbs.\n",
    "\n",
    "Source: https://www.tensorflow.org/tutorials/text/nmt_with_attention <br>\n",
    "Source for the translation dataset: http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-glass",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bored-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Здрасти.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>Здравейте!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheers!</td>\n",
       "      <td>Наздраве!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Got it?</td>\n",
       "      <td>Разбра ли?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm OK.</td>\n",
       "      <td>ОК съм.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target      source\n",
       "0      Hi.    Здрасти.\n",
       "1   Hello!  Здравейте!\n",
       "2  Cheers!   Наздраве!\n",
       "3  Got it?  Разбра ли?\n",
       "4  I'm OK.     ОК съм."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_data_path = \"./data/bg-en.txt\"\n",
    "#Read the data\n",
    "lines_raw= pd.read_table(translation_data_path,names=['target', 'source'], usecols=[0, 1])\n",
    "lines_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-carrier",
   "metadata": {},
   "source": [
    "#### Clean and preprocess the source and target sentences.\n",
    "We apply the following text cleaning\n",
    "Convert text to lower case\n",
    "Remove quotes\n",
    "Clean digits from the source and target sentences. If the source or the target language use different symbols for the numbers, then remove those symbols\n",
    "Remove spaces\n",
    "Add a space between the word and the punctuations like “?”\n",
    "Add “start_” tag at the start of the sentence and “_end” tag at the end of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "assured-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ongoing-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    num_digits= str.maketrans('','', digits)\n",
    "    \n",
    "    sentence= sentence.lower()\n",
    "    sentence= re.sub(\" +\", \" \", sentence)\n",
    "    sentence= re.sub(\"'\", '', sentence)\n",
    "    sentence= sentence.translate(num_digits)\n",
    "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    sentence=  'start_ ' + sentence + ' _end'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "subject-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_ can you do it in thirty minutes ? _end\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_sentence('Can you do it in thirty minutes?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-ozone",
   "metadata": {},
   "source": [
    "Preprocessing the source and target sentences to have word pairs in the format: [ENGLISH, SPANISH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "meaningful-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, BULGARIAN]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "solved-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_ понеже обикновено могат да се намерят много уебсайтове на дадена тема ,  обикновено кликвам бутона \"назад\" ,  когато попадна на някоя уебстраница с изскачащи реклами .  просто отивам на следващата страница ,  която ми предлага google ,  и се надявам тя да дразни по-малко . _end\n",
      "start_ since there are usually multiple websites on any given topic ,  i usually just click the back button when i arrive on any webpage that has pop-up advertising .  i just go to the next page found by google and hope for something less irritating . _end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size=60000\n",
    "target, source, comment = create_dataset(translation_data_path, sample_size)\n",
    "\n",
    "print(source[-1])\n",
    "print(target[-1])\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-indonesian",
   "metadata": {},
   "source": [
    "#### Tokenize source and target sentences\n",
    "We need to vectorize the text corpus where the text is converted into a sequence of integers.\n",
    "We first create the tokenizer and then apply the tokenizer on the source sentences.\n",
    "We now transform each word in the source sentences into a sequence of integers by replacing the word with its corresponding integer value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-boxing",
   "metadata": {},
   "source": [
    "#### Only words known by the tokenizer will be taken into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "perfect-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "essential-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "#Transforms each text in texts to a sequence of integers.\n",
    "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<!UNKNOWN WORD!>')\n",
    "source_sentence_tokenizer.fit_on_texts(source)\n",
    "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
    "#Sequences that are shorter than num_timesteps, padded with 0 at the end.\n",
    "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )\n",
    "print(len(source_tensor[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "enhanced-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prescribed-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# create the target sentence tokenizer\n",
    "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<!UNKNOWN WORD!>')\n",
    "# Fit the tokenizer on target sentences\n",
    "target_sentence_tokenizer.fit_on_texts(target)\n",
    "#conver target text to sequnec of integers\n",
    "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n",
    "# Post pad the shorter sequences with 0\n",
    "target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )\n",
    "print(len(target_tensor[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-hundred",
   "metadata": {},
   "source": [
    "#### Limit the size of the dataset to experiment faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-ozone",
   "metadata": {},
   "source": [
    "To train faster, we can limit the size of the dataset using sample_size sentences (of course, translation quality degrades with less data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "involved-chaos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "max_target_length= max(len(t) for t in  target_tensor)\n",
    "print(max_target_length)\n",
    "max_source_length= max(len(t) for t in  source_tensor)\n",
    "print(max_source_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-riding",
   "metadata": {},
   "source": [
    "#### Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "small-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start_ hi . _end',\n",
       " 'start_ hello ! _end',\n",
       " 'start_ cheers ! _end',\n",
       " 'start_ got it ? _end',\n",
       " 'start_ im ok . _end',\n",
       " 'start_ im ok . _end',\n",
       " 'start_ no way ! _end',\n",
       " 'start_ no way ! _end',\n",
       " 'start_ really ? _end',\n",
       " 'start_ thanks . _end',\n",
       " 'start_ ask tom . _end',\n",
       " 'start_ ask tom . _end',\n",
       " 'start_ ask tom . _end',\n",
       " 'start_ ask tom . _end',\n",
       " 'start_ ask tom . _end',\n",
       " 'start_ be cool . _end',\n",
       " 'start_ be cool . _end',\n",
       " 'start_ get out ! _end',\n",
       " 'start_ get out ! _end',\n",
       " 'start_ go away ! _end',\n",
       " 'start_ go away ! _end',\n",
       " 'start_ go away ! _end',\n",
       " 'start_ go away ! _end',\n",
       " 'start_ go away ! _end',\n",
       " 'start_ go away ! _end',\n",
       " 'start_ go away ! _end',\n",
       " 'start_ go away . _end',\n",
       " 'start_ go away . _end',\n",
       " 'start_ go away . _end',\n",
       " 'start_ go away . _end',\n",
       " 'start_ go away . _end',\n",
       " 'start_ he runs . _end',\n",
       " 'start_ he runs . _end',\n",
       " 'start_ im sad . _end',\n",
       " 'start_ its ok . _end',\n",
       " 'start_ me ,  too . _end',\n",
       " 'start_ me ,  too . _end',\n",
       " 'start_ me ,  too . _end',\n",
       " 'start_ see you . _end',\n",
       " 'start_ show me . _end',\n",
       " 'start_ welcome . _end',\n",
       " 'start_ you run . _end',\n",
       " 'start_ you run . _end',\n",
       " 'start_ you run . _end',\n",
       " 'start_ you run . _end',\n",
       " 'start_ get lost . _end',\n",
       " 'start_ get lost . _end',\n",
       " 'start_ have fun . _end',\n",
       " 'start_ have fun . _end',\n",
       " 'start_ hurry up . _end',\n",
       " 'start_ i forgot . _end',\n",
       " 'start_ i forgot . _end',\n",
       " 'start_ ill pay . _end',\n",
       " 'start_ ill pay . _end',\n",
       " 'start_ im full . _end',\n",
       " 'start_ im full . _end',\n",
       " 'start_ im full . _end',\n",
       " 'start_ im poor . _end',\n",
       " 'start_ im rich . _end',\n",
       " 'start_ its hot . _end',\n",
       " 'start_ lets go ! _end',\n",
       " 'start_ lets go ! _end',\n",
       " 'start_ lets go ! _end',\n",
       " 'start_ lets go ! _end',\n",
       " 'start_ lets go . _end',\n",
       " 'start_ lets go . _end',\n",
       " 'start_ she runs . _end',\n",
       " 'start_ she runs . _end',\n",
       " 'start_ use this . _end',\n",
       " 'start_ we agree . _end',\n",
       " 'start_ birds fly . _end',\n",
       " 'start_ calm down . _end',\n",
       " 'start_ chill out . _end',\n",
       " 'start_ chill out . _end',\n",
       " 'start_ do it now . _end',\n",
       " 'start_ dont die . _end',\n",
       " 'start_ excuse me . _end',\n",
       " 'start_ excuse me . _end',\n",
       " 'start_ excuse me . _end',\n",
       " 'start_ excuse me . _end',\n",
       " 'start_ forget it . _end',\n",
       " 'start_ go inside . _end',\n",
       " 'start_ go inside . _end',\n",
       " 'start_ go inside . _end',\n",
       " 'start_ i gave up . _end',\n",
       " 'start_ i gave up . _end',\n",
       " 'start_ i give in . _end',\n",
       " 'start_ i give up . _end',\n",
       " 'start_ i give up . _end',\n",
       " 'start_ i laughed . _end',\n",
       " 'start_ i laughed . _end',\n",
       " 'start_ i laughed . _end',\n",
       " 'start_ i laughed . _end',\n",
       " 'start_ i laughed . _end',\n",
       " 'start_ i lost it . _end',\n",
       " 'start_ i lost it . _end',\n",
       " 'start_ i met him . _end',\n",
       " 'start_ i met him . _end',\n",
       " 'start_ im a man . _end',\n",
       " 'start_ im early . _end',\n",
       " 'start_ im early . _end',\n",
       " 'start_ im sorry . _end',\n",
       " 'start_ im sorry . _end',\n",
       " 'start_ im sorry . _end',\n",
       " 'start_ im sorry . _end',\n",
       " 'start_ im tired . _end',\n",
       " 'start_ im tired . _end',\n",
       " 'start_ im tired . _end',\n",
       " 'start_ im tired . _end',\n",
       " 'start_ im young . _end',\n",
       " 'start_ is it bad ? _end',\n",
       " 'start_ is it bad ? _end',\n",
       " 'start_ its cold . _end',\n",
       " 'start_ its free . _end',\n",
       " 'start_ its free . _end',\n",
       " 'start_ its true ! _end',\n",
       " 'start_ its work . _end',\n",
       " 'start_ lets ask . _end',\n",
       " 'start_ lets ask . _end',\n",
       " 'start_ lets eat . _end',\n",
       " 'start_ lets eat . _end',\n",
       " 'start_ lets see . _end',\n",
       " 'start_ lets try ! _end',\n",
       " 'start_ of course ! _end',\n",
       " 'start_ of course . _end',\n",
       " 'start_ start now . _end',\n",
       " 'start_ start now . _end',\n",
       " 'start_ start now . _end',\n",
       " 'start_ start now . _end',\n",
       " 'start_ they swam . _end',\n",
       " 'start_ tom knits . _end',\n",
       " 'start_ whats up ? _end',\n",
       " 'start_ who cares ? _end',\n",
       " 'start_ you drive . _end',\n",
       " 'start_ you idiot ! _end',\n",
       " 'start_ am i clear ? _end',\n",
       " 'start_ am i clear ? _end',\n",
       " 'start_ am i dying ? _end',\n",
       " 'start_ am i early ? _end',\n",
       " 'start_ am i early ? _end',\n",
       " 'start_ am i fired ? _end',\n",
       " 'start_ am i fired ? _end',\n",
       " 'start_ am i first ? _end',\n",
       " 'start_ am i first ? _end',\n",
       " 'start_ am i hired ? _end',\n",
       " 'start_ am i hired ? _end',\n",
       " 'start_ am i wrong ? _end',\n",
       " 'start_ be careful ! _end',\n",
       " 'start_ be careful ! _end',\n",
       " 'start_ be careful ! _end',\n",
       " 'start_ be careful ! _end',\n",
       " 'start_ be careful ! _end',\n",
       " 'start_ be careful ! _end',\n",
       " 'start_ be careful ! _end',\n",
       " 'start_ be careful . _end',\n",
       " 'start_ be careful . _end',\n",
       " 'start_ be on time . _end',\n",
       " 'start_ be on time . _end',\n",
       " 'start_ be on time . _end',\n",
       " 'start_ birds sing . _end',\n",
       " 'start_ cut it out ! _end',\n",
       " 'start_ cut it out ! _end',\n",
       " 'start_ dont jump ! _end',\n",
       " 'start_ dont jump ! _end',\n",
       " 'start_ dont move . _end',\n",
       " 'start_ dont move . _end',\n",
       " 'start_ dont move . _end',\n",
       " 'start_ dont move . _end',\n",
       " 'start_ dont talk ! _end',\n",
       " 'start_ fill it up . _end',\n",
       " 'start_ fill it up . _end',\n",
       " 'start_ follow him . _end',\n",
       " 'start_ follow him . _end',\n",
       " 'start_ god exists . _end',\n",
       " 'start_ he is nice . _end',\n",
       " 'start_ he is nice . _end',\n",
       " 'start_ i can jump . _end',\n",
       " 'start_ i eat here . _end',\n",
       " 'start_ i found it . _end',\n",
       " 'start_ i know him . _end',\n",
       " 'start_ i know him . _end',\n",
       " 'start_ i like you . _end',\n",
       " 'start_ i love you . _end',\n",
       " 'start_ i need you . _end',\n",
       " 'start_ i need you . _end',\n",
       " 'start_ i need you . _end',\n",
       " 'start_ i remember . _end',\n",
       " 'start_ i think so . _end',\n",
       " 'start_ i think so . _end',\n",
       " 'start_ i want you . _end',\n",
       " 'start_ ill do it . _end',\n",
       " 'start_ im a hero . _end',\n",
       " 'start_ im a twin . _end',\n",
       " 'start_ im coming . _end',\n",
       " 'start_ im coming . _end',\n",
       " 'start_ im for it . _end',\n",
       " 'start_ im hungry ! _end',\n",
       " 'start_ im hungry ! _end',\n",
       " 'start_ im hungry . _end',\n",
       " 'start_ im hungry . _end',\n",
       " 'start_ im so fat . _end',\n",
       " 'start_ im so fat . _end',\n",
       " 'start_ it happens . _end',\n",
       " 'start_ keep still . _end',\n",
       " 'start_ lets chat . _end',\n",
       " 'start_ lets kiss . _end',\n",
       " 'start_ lets move . _end',\n",
       " 'start_ lets play . _end',\n",
       " 'start_ lets pray . _end',\n",
       " 'start_ lets sing . _end',\n",
       " 'start_ lets swim . _end',\n",
       " 'start_ lets swim . _end',\n",
       " 'start_ lets talk . _end',\n",
       " 'start_ lets vote . _end',\n",
       " 'start_ lets vote . _end',\n",
       " 'start_ lets work . _end',\n",
       " 'start_ lets work . _end',\n",
       " 'start_ no comment . _end',\n",
       " 'start_ no kidding ? _end',\n",
       " 'start_ once again . _end',\n",
       " 'start_ once again . _end',\n",
       " 'start_ take a bus . _end',\n",
       " 'start_ take a bus . _end',\n",
       " 'start_ time flies . _end',\n",
       " 'start_ tom jumped . _end',\n",
       " 'start_ try harder . _end',\n",
       " 'start_ we are men . _end',\n",
       " 'start_ we are men . _end',\n",
       " 'start_ were boys . _end',\n",
       " 'start_ whos that ? _end',\n",
       " 'start_ wood burns . _end',\n",
       " 'start_ you may go . _end',\n",
       " 'start_ you may go . _end',\n",
       " 'start_ you may go . _end',\n",
       " 'start_ all is well . _end',\n",
       " 'start_ are we lost ? _end',\n",
       " 'start_ are we lost ? _end',\n",
       " 'start_ are we safe ? _end',\n",
       " 'start_ are you cut ? _end',\n",
       " 'start_ are you hot ? _end',\n",
       " 'start_ ask for tom . _end',\n",
       " 'start_ ask for tom . _end',\n",
       " 'start_ ask for tom . _end',\n",
       " 'start_ check again . _end',\n",
       " 'start_ dont do it ! _end',\n",
       " 'start_ dont do it ! _end',\n",
       " 'start_ dont do it ! _end',\n",
       " 'start_ dont go in . _end',\n",
       " 'start_ dont worry . _end',\n",
       " 'start_ dont worry . _end',\n",
       " 'start_ dont worry . _end',\n",
       " 'start_ dont worry . _end',\n",
       " 'start_ he can read . _end',\n",
       " 'start_ he can read . _end',\n",
       " 'start_ he is alone . _end',\n",
       " 'start_ hes strong . _end',\n",
       " 'start_ here we are ! _end',\n",
       " 'start_ here we are ! _end',\n",
       " 'start_ how are you ? _end',\n",
       " 'start_ i am coming . _end',\n",
       " 'start_ i bought it . _end',\n",
       " 'start_ i buy tapes . _end',\n",
       " 'start_ i feel cold . _end',\n",
       " 'start_ i feel cold . _end',\n",
       " 'start_ i feel fine . _end',\n",
       " 'start_ i feel fine . _end',\n",
       " 'start_ i feel lost . _end',\n",
       " 'start_ i feel lost . _end',\n",
       " 'start_ i feel sick . _end',\n",
       " 'start_ i forgot it . _end',\n",
       " 'start_ i like jazz . _end',\n",
       " 'start_ i like math . _end',\n",
       " 'start_ i surrender . _end',\n",
       " 'start_ i surrender . _end',\n",
       " 'start_ ill attend . _end',\n",
       " 'start_ ill attend . _end',\n",
       " 'start_ ill get in . _end',\n",
       " 'start_ im careful . _end',\n",
       " 'start_ im curious . _end',\n",
       " 'start_ im serious . _end',\n",
       " 'start_ im serious . _end',\n",
       " 'start_ im starved . _end',\n",
       " 'start_ im thirsty . _end',\n",
       " 'start_ im thirsty . _end',\n",
       " 'start_ im too fat . _end',\n",
       " 'start_ it happened . _end',\n",
       " 'start_ its my job . _end',\n",
       " 'start_ let me help . _end',\n",
       " 'start_ let me help . _end',\n",
       " 'start_ let me help . _end',\n",
       " 'start_ lets begin . _end',\n",
       " 'start_ lets check . _end',\n",
       " 'start_ lets dance . _end',\n",
       " 'start_ lets do it ! _end',\n",
       " 'start_ lets do it . _end',\n",
       " 'start_ lets do it . _end',\n",
       " 'start_ lets drink . _end',\n",
       " 'start_ lets hurry . _end',\n",
       " 'start_ lets hurry . _end',\n",
       " 'start_ lets hurry . _end',\n",
       " 'start_ lets leave . _end',\n",
       " 'start_ lets relax . _end',\n",
       " 'start_ lets relax . _end',\n",
       " 'start_ lets split . _end',\n",
       " 'start_ lets start ! _end',\n",
       " 'start_ lets start ! _end',\n",
       " 'start_ lets start . _end',\n",
       " 'start_ life is fun . _end',\n",
       " 'start_ ok .  i agree . _end',\n",
       " 'start_ remember it . _end',\n",
       " 'start_ remember it . _end',\n",
       " 'start_ she blushed . _end',\n",
       " 'start_ stand still ! _end',\n",
       " 'start_ thats cool . _end',\n",
       " 'start_ thats cool . _end',\n",
       " 'start_ thats cool . _end',\n",
       " 'start_ thats life . _end',\n",
       " 'start_ tom frowned . _end',\n",
       " 'start_ tom frowned . _end',\n",
       " 'start_ tom is fast . _end',\n",
       " 'start_ wake tom up . _end',\n",
       " 'start_ wake tom up . _end',\n",
       " 'start_ walk slowly . _end',\n",
       " 'start_ walk slowly . _end',\n",
       " 'start_ was i wrong ? _end',\n",
       " 'start_ was i wrong ? _end',\n",
       " 'start_ what a pity ! _end',\n",
       " 'start_ whats this ? _end',\n",
       " 'start_ who are you ? _end',\n",
       " 'start_ who are you ? _end',\n",
       " 'start_ who are you ? _end',\n",
       " 'start_ who are you ? _end',\n",
       " 'start_ who are you ? _end',\n",
       " 'start_ who drew it ? _end',\n",
       " 'start_ who drew it ? _end',\n",
       " 'start_ who is that ? _end',\n",
       " 'start_ work slowly . _end',\n",
       " 'start_ work slowly . _end',\n",
       " 'start_ youre evil . _end',\n",
       " 'start_ youre evil . _end',\n",
       " 'start_ youre evil . _end',\n",
       " 'start_ youre evil . _end',\n",
       " 'start_ youre evil . _end',\n",
       " 'start_ youre late . _end',\n",
       " 'start_ am i correct ? _end',\n",
       " 'start_ am i correct ? _end',\n",
       " 'start_ am i invited ? _end',\n",
       " 'start_ am i invited ? _end',\n",
       " 'start_ are we alone ? _end',\n",
       " 'start_ are we ready ? _end',\n",
       " 'start_ are you cold ? _end',\n",
       " 'start_ are you done ? _end',\n",
       " 'start_ are you done ? _end',\n",
       " 'start_ are you nuts ? _end',\n",
       " 'start_ are you sure ? _end',\n",
       " 'start_ are you sure ? _end',\n",
       " 'start_ are you sure ? _end',\n",
       " 'start_ are you sure ? _end',\n",
       " 'start_ are you sure ? _end',\n",
       " 'start_ ask mary out . _end',\n",
       " 'start_ be our guest . _end',\n",
       " 'start_ be our guest . _end',\n",
       " 'start_ be quiet now . _end',\n",
       " 'start_ be quiet now . _end',\n",
       " 'start_ bear with me . _end',\n",
       " 'start_ bear with me . _end',\n",
       " 'start_ bring him in . _end',\n",
       " 'start_ bring him in . _end',\n",
       " 'start_ can you come ? _end',\n",
       " 'start_ can you stay ? _end',\n",
       " 'start_ can you stay ? _end',\n",
       " 'start_ can you swim ? _end',\n",
       " 'start_ check it out ! _end',\n",
       " 'start_ come help me . _end',\n",
       " 'start_ come with us . _end',\n",
       " 'start_ count to ten . _end',\n",
       " 'start_ count to ten . _end',\n",
       " 'start_ deal with it . _end',\n",
       " 'start_ did you call ? _end',\n",
       " 'start_ do it for me . _end',\n",
       " 'start_ do it for me . _end',\n",
       " 'start_ do it for me . _end',\n",
       " 'start_ do you drink ? _end',\n",
       " 'start_ drive safely . _end',\n",
       " 'start_ drive safely . _end',\n",
       " 'start_ drive slowly . _end',\n",
       " 'start_ drive slowly . _end',\n",
       " 'start_ good evening . _end',\n",
       " 'start_ he loved her . _end',\n",
       " 'start_ he loves her . _end',\n",
       " 'start_ he was brave . _end',\n",
       " 'start_ he was wrong . _end',\n",
       " 'start_ here you are . _end',\n",
       " 'start_ how dare you ! _end',\n",
       " 'start_ how dare you ! _end',\n",
       " 'start_ i almost won . _end',\n",
       " 'start_ i am curious . _end',\n",
       " 'start_ i cried ,  too . _end',\n",
       " 'start_ i dont know . _end',\n",
       " 'start_ i dont mind . _end',\n",
       " 'start_ i dont mind . _end',\n",
       " 'start_ i missed you . _end',\n",
       " 'start_ i missed you . _end',\n",
       " 'start_ i understand . _end',\n",
       " 'start_ i understand . _end',\n",
       " 'start_ ill sue you . _end',\n",
       " 'start_ ill sue you . _end',\n",
       " 'start_ im eighteen . _end',\n",
       " 'start_ im so happy . _end',\n",
       " 'start_ im starving . _end',\n",
       " 'start_ im ticklish . _end',\n",
       " 'start_ it felt nice . _end',\n",
       " 'start_ it was toms . _end',\n",
       " 'start_ itll happen . _end',\n",
       " 'start_ its an omen . _end',\n",
       " 'start_ its for tom . _end',\n",
       " 'start_ its raining . _end',\n",
       " 'start_ its raining . _end',\n",
       " 'start_ its snowing . _end',\n",
       " 'start_ its too big . _end',\n",
       " 'start_ its too hot . _end',\n",
       " 'start_ its unusual . _end',\n",
       " 'start_ jump over it . _end',\n",
       " 'start_ keep digging . _end',\n",
       " 'start_ lets listen . _end',\n",
       " 'start_ lets not go . _end',\n",
       " 'start_ lets review . _end',\n",
       " 'start_ lets switch . _end',\n",
       " 'start_ lets try it . _end',\n",
       " 'start_ life is hard . _end',\n",
       " 'start_ mary came in . _end',\n",
       " 'start_ mary is tall . _end',\n",
       " 'start_ my eyes hurt . _end',\n",
       " 'start_ my eyes hurt . _end',\n",
       " 'start_ my eyes itch . _end',\n",
       " 'start_ no one knows . _end',\n",
       " 'start_ please leave . _end',\n",
       " 'start_ please leave . _end',\n",
       " 'start_ see you soon ! _end',\n",
       " 'start_ see you soon . _end',\n",
       " 'start_ see you then . _end',\n",
       " 'start_ shame on you . _end',\n",
       " 'start_ shame on you . _end',\n",
       " 'start_ she may come . _end',\n",
       " 'start_ should we go ? _end',\n",
       " 'start_ show me that . _end',\n",
       " 'start_ show me that . _end',\n",
       " 'start_ speak softly . _end',\n",
       " 'start_ stop whining . _end',\n",
       " 'start_ take it down . _end',\n",
       " 'start_ take it easy . _end',\n",
       " 'start_ take it easy . _end',\n",
       " 'start_ tell tom why . _end',\n",
       " 'start_ thanks again . _end',\n",
       " 'start_ thats toms . _end',\n",
       " 'start_ thats toms . _end',\n",
       " 'start_ thats crazy . _end',\n",
       " 'start_ thats cruel . _end',\n",
       " 'start_ this is true . _end',\n",
       " 'start_ tom found it . _end',\n",
       " 'start_ tom found it . _end',\n",
       " 'start_ tom found it . _end',\n",
       " 'start_ tom found it . _end',\n",
       " 'start_ tom got an a . _end',\n",
       " 'start_ tom hates it . _end',\n",
       " 'start_ tom is a kid . _end',\n",
       " 'start_ tom is a pig ! _end',\n",
       " 'start_ tom is awake . _end',\n",
       " 'start_ tom stutters . _end',\n",
       " 'start_ tom ,  wake up . _end',\n",
       " 'start_ tom ,  wake up . _end',\n",
       " 'start_ try it again . _end',\n",
       " 'start_ try it again . _end',\n",
       " 'start_ unbelievable ! _end',\n",
       " 'start_ unbelievable ! _end',\n",
       " 'start_ wake up ,  tom . _end',\n",
       " 'start_ wake up ,  tom . _end',\n",
       " 'start_ welcome home . _end',\n",
       " 'start_ what a loser ! _end',\n",
       " 'start_ what a loser ! _end',\n",
       " 'start_ what a shame ! _end',\n",
       " 'start_ what is that ? _end',\n",
       " 'start_ what is this ? _end',\n",
       " 'start_ wont you go ? _end',\n",
       " 'start_ wont you go ? _end',\n",
       " 'start_ you are late . _end',\n",
       " 'start_ you are late . _end',\n",
       " 'start_ you are late . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre cruel . _end',\n",
       " 'start_ youre drunk . _end',\n",
       " 'start_ youre drunk . _end',\n",
       " 'start_ youre wrong . _end',\n",
       " 'start_ am i approved ? _end',\n",
       " 'start_ am i included ? _end',\n",
       " 'start_ am i included ? _end',\n",
       " 'start_ any questions ? _end',\n",
       " 'start_ are they cops ? _end',\n",
       " 'start_ are they cops ? _end',\n",
       " 'start_ are they cute ? _end',\n",
       " 'start_ are they cute ? _end',\n",
       " 'start_ are they dead ? _end',\n",
       " 'start_ are they gone ? _end',\n",
       " 'start_ are they here ? _end',\n",
       " 'start_ are you alive ? _end',\n",
       " 'start_ are you alive ? _end',\n",
       " 'start_ are you alive ? _end',\n",
       " 'start_ are you alone ? _end',\n",
       " 'start_ are you alone ? _end',\n",
       " 'start_ are you armed ? _end',\n",
       " 'start_ are you armed ? _end',\n",
       " 'start_ are you armed ? _end',\n",
       " 'start_ are you dying ? _end',\n",
       " 'start_ are you going ? _end',\n",
       " 'start_ are you going ? _end',\n",
       " 'start_ are you going ? _end',\n",
       " 'start_ are you happy ? _end',\n",
       " 'start_ are you happy ? _end',\n",
       " 'start_ are you happy ? _end',\n",
       " 'start_ are you happy ? _end',\n",
       " 'start_ are you happy ? _end',\n",
       " 'start_ are you lying ? _end',\n",
       " 'start_ are you lying ? _end',\n",
       " 'start_ are you tired ? _end',\n",
       " 'start_ are you tired ? _end',\n",
       " 'start_ ask tom again . _end',\n",
       " 'start_ ask an expert . _end',\n",
       " 'start_ ask an expert . _end',\n",
       " 'start_ can you drive ? _end',\n",
       " 'start_ can you drive ? _end',\n",
       " 'start_ check ,  please . _end',\n",
       " 'start_ do cats dream ? _end',\n",
       " 'start_ dont be late . _end',\n",
       " 'start_ dont be late . _end',\n",
       " 'start_ dont come in . _end',\n",
       " 'start_ dont get fat . _end',\n",
       " 'start_ dont go ,  tom . _end',\n",
       " 'start_ dont go ,  tom . _end',\n",
       " 'start_ dont go ,  tom . _end',\n",
       " 'start_ dont hang up ! _end',\n",
       " 'start_ dont push me . _end',\n",
       " 'start_ dont push me . _end',\n",
       " 'start_ everyone dies . _end',\n",
       " 'start_ everyone dies . _end',\n",
       " 'start_ flowers bloom . _end',\n",
       " 'start_ get some rest . _end',\n",
       " 'start_ get your coat . _end',\n",
       " 'start_ get your coat . _end',\n",
       " 'start_ hang on a sec . _end',\n",
       " 'start_ he came first . _end',\n",
       " 'start_ he cant read . _end',\n",
       " 'start_ he drank beer . _end',\n",
       " 'start_ he felt tired . _end',\n",
       " 'start_ he lied to us . _end',\n",
       " 'start_ he shot at me . _end',\n",
       " 'start_ he shot at me . _end',\n",
       " 'start_ he talks fast . _end',\n",
       " 'start_ hold on a sec . _end',\n",
       " 'start_ hold on tight . _end',\n",
       " 'start_ hold on to me . _end',\n",
       " 'start_ how about you ? _end',\n",
       " 'start_ how about you ? _end',\n",
       " 'start_ how did it go ? _end',\n",
       " 'start_ i believe you . _end',\n",
       " 'start_ i believe you . _end',\n",
       " 'start_ i believe you . _end',\n",
       " 'start_ i believe you . _end',\n",
       " 'start_ i cried today . _end',\n",
       " 'start_ i cried today . _end',\n",
       " 'start_ i did it once . _end',\n",
       " 'start_ i did it once . _end',\n",
       " 'start_ i did my best . _end',\n",
       " 'start_ i dont agree . _end',\n",
       " 'start_ i forgot them . _end',\n",
       " 'start_ i had to stop . _end',\n",
       " 'start_ i hate french . _end',\n",
       " 'start_ i hate flying . _end',\n",
       " 'start_ i like french . _end',\n",
       " 'start_ i like french . _end',\n",
       " 'start_ i like movies . _end',\n",
       " 'start_ i like sports . _end',\n",
       " 'start_ i like tennis . _end',\n",
       " 'start_ i love french . _end',\n",
       " 'start_ i love movies . _end',\n",
       " 'start_ i made coffee . _end',\n",
       " 'start_ i made dinner . _end',\n",
       " 'start_ i must go now . _end',\n",
       " 'start_ i own a yacht . _end',\n",
       " 'start_ i said id go . _end',\n",
       " 'start_ i think i can . _end',\n",
       " 'start_ i tricked you . _end',\n",
       " 'start_ i tricked you . _end',\n",
       " 'start_ i tricked you . _end',\n",
       " 'start_ i wasnt busy . _end',\n",
       " 'start_ i wasnt busy . _end',\n",
       " 'start_ ill buy this . _end',\n",
       " 'start_ ill eat here . _end',\n",
       " 'start_ ill take one . _end',\n",
       " 'start_ im a tourist . _end',\n",
       " 'start_ im an orphan . _end',\n",
       " 'start_ im dangerous . _end',\n",
       " 'start_ im dangerous . _end',\n",
       " 'start_ im dangerous . _end',\n",
       " 'start_ im dangerous . _end',\n",
       " 'start_ im home ,  tom . _end',\n",
       " 'start_ im home ,  tom . _end',\n",
       " 'start_ im not blind . _end',\n",
       " 'start_ im on a diet . _end',\n",
       " 'start_ im very busy . _end',\n",
       " 'start_ is that yours ? _end',\n",
       " 'start_ is that yours ? _end',\n",
       " 'start_ is that yours ? _end',\n",
       " 'start_ it is raining . _end',\n",
       " 'start_ it is raining . _end',\n",
       " 'start_ it was unjust . _end',\n",
       " 'start_ it works well . _end',\n",
       " 'start_ its a secret . _end',\n",
       " 'start_ its business . _end',\n",
       " 'start_ its business . _end',\n",
       " 'start_ its happened . _end',\n",
       " 'start_ its improved . _end',\n",
       " 'start_ its only tom . _end',\n",
       " 'start_ its too loud . _end',\n",
       " 'start_ its too loud . _end',\n",
       " 'start_ its very big . _end',\n",
       " 'start_ its very big . _end',\n",
       " 'start_ let me see it . _end',\n",
       " 'start_ let me see it . _end',\n",
       " 'start_ let me see it . _end',\n",
       " 'start_ let me try it . _end',\n",
       " 'start_ lets ask him . _end',\n",
       " 'start_ lets ask him . _end',\n",
       " 'start_ lets ask him . _end',\n",
       " 'start_ lets ease up . _end',\n",
       " 'start_ lets go away . _end',\n",
       " 'start_ lets hope so . _end',\n",
       " 'start_ lets proceed . _end',\n",
       " 'start_ lets proceed . _end',\n",
       " 'start_ lock the gate . _end',\n",
       " 'start_ my knee hurts . _end',\n",
       " 'start_ no ,  thank you . _end',\n",
       " 'start_ now keep calm . _end',\n",
       " 'start_ now you do it . _end',\n",
       " 'start_ pass it to me . _end',\n",
       " 'start_ pass it to me . _end',\n",
       " 'start_ pass it to me . _end',\n",
       " 'start_ people change . _end',\n",
       " 'start_ put on a robe . _end',\n",
       " 'start_ read it to me . _end',\n",
       " 'start_ read it to me . _end',\n",
       " 'start_ read it to me . _end',\n",
       " 'start_ read it to me . _end',\n",
       " 'start_ see you later . _end',\n",
       " 'start_ shake my hand . _end',\n",
       " 'start_ shake my hand . _end',\n",
       " 'start_ she cant ski . _end',\n",
       " 'start_ she hated him . _end',\n",
       " 'start_ she is french . _end',\n",
       " 'start_ she was young . _end',\n",
       " 'start_ shes dieting . _end',\n",
       " 'start_ show it to us . _end',\n",
       " 'start_ show it to us . _end',\n",
       " 'start_ shut the door . _end',\n",
       " 'start_ speak clearly . _end',\n",
       " 'start_ speak clearly . _end',\n",
       " 'start_ speak quietly . _end',\n",
       " 'start_ stand at ease ! _end',\n",
       " 'start_ start writing . _end',\n",
       " 'start_ stay in there . _end',\n",
       " 'start_ stay in there . _end',\n",
       " 'start_ that ones ok . _end',\n",
       " 'start_ that ones ok . _end',\n",
       " 'start_ that ones ok . _end',\n",
       " 'start_ thats a book . _end',\n",
       " 'start_ thats a copy . _end',\n",
       " 'start_ thats a fake . _end',\n",
       " 'start_ thats a fake . _end',\n",
       " 'start_ thats enough . _end',\n",
       " 'start_ thats enough . _end',\n",
       " 'start_ thats enough . _end',\n",
       " 'start_ they are busy . _end',\n",
       " 'start_ they fixed it . _end',\n",
       " 'start_ they fixed it . _end',\n",
       " 'start_ theyre early . _end',\n",
       " 'start_ theyre early . _end',\n",
       " 'start_ today was fun . _end',\n",
       " 'start_ tom did do it . _end',\n",
       " 'start_ tom felt fine . _end',\n",
       " 'start_ tom got a job . _end',\n",
       " 'start_ tom had a gun . _end',\n",
       " 'start_ tom had a son . _end',\n",
       " 'start_ tom has a dog . _end',\n",
       " 'start_ tom has a gun . _end',\n",
       " 'start_ tom has a job . _end',\n",
       " 'start_ tom has a map . _end',\n",
       " 'start_ tom has to go . _end',\n",
       " 'start_ tom has to go . _end',\n",
       " 'start_ tom is a monk . _end',\n",
       " 'start_ tom is absent . _end',\n",
       " 'start_ tom was brave . _end',\n",
       " 'start_ tom was fired . _end',\n",
       " 'start_ tom was fired . _end',\n",
       " 'start_ tom was wrong . _end',\n",
       " 'start_ wait a moment . _end',\n",
       " 'start_ wait a moment . _end',\n",
       " 'start_ we should eat . _end',\n",
       " 'start_ well rebuild . _end',\n",
       " 'start_ well rebuild . _end',\n",
       " 'start_ weve arrived . _end',\n",
       " 'start_ weve arrived . _end',\n",
       " 'start_ were you shot ? _end',\n",
       " 'start_ what happened ? _end',\n",
       " 'start_ what is a ufo ? _end',\n",
       " 'start_ when do we go ? _end',\n",
       " 'start_ when do we go ? _end',\n",
       " 'start_ when was that ? _end',\n",
       " 'start_ whos thirsty ? _end',\n",
       " 'start_ whose is this ? _end',\n",
       " 'start_ you are early . _end',\n",
       " 'start_ you are early . _end',\n",
       " 'start_ you are early . _end',\n",
       " 'start_ you dont say . _end',\n",
       " 'start_ you dont say . _end',\n",
       " 'start_ you look pale . _end',\n",
       " 'start_ you should go . _end',\n",
       " 'start_ youll see it . _end',\n",
       " 'start_ youre joking ! _end',\n",
       " 'start_ youre joking ! _end',\n",
       " 'start_ act like a man . _end',\n",
       " 'start_ am i intruding ? _end',\n",
       " 'start_ apples are red . _end',\n",
       " 'start_ are there kids ? _end',\n",
       " 'start_ are these real ? _end',\n",
       " 'start_ are they alive ? _end',\n",
       " 'start_ are they armed ? _end',\n",
       " 'start_ are we sinking ? _end',\n",
       " 'start_ are you afraid ? _end',\n",
       " 'start_ are you asleep ? _end',\n",
       " 'start_ are you coming ? _end',\n",
       " 'start_ are you coming ? _end',\n",
       " 'start_ are you crying ? _end',\n",
       " 'start_ are you famous ? _end',\n",
       " 'start_ are you famous ? _end',\n",
       " 'start_ are you scared ? _end',\n",
       " 'start_ are you scared ? _end',\n",
       " 'start_ are you stupid ? _end',\n",
       " 'start_ arent you tom ? _end',\n",
       " 'start_ arent you tom ? _end',\n",
       " 'start_ ask my friends . _end',\n",
       " 'start_ ask my friends . _end',\n",
       " 'start_ be careful now . _end',\n",
       " 'start_ be careful ,  ok ? _end',\n",
       " 'start_ birds lay eggs . _end',\n",
       " 'start_ both are alive . _end',\n",
       " 'start_ can i help you ? _end',\n",
       " 'start_ can i help you ? _end',\n",
       " 'start_ can i see that ? _end',\n",
       " 'start_ can i see that ? _end',\n",
       " 'start_ can i see that ? _end',\n",
       " 'start_ can i sit down ? _end',\n",
       " 'start_ catch the ball . _end',\n",
       " 'start_ coffee ,  please . _end',\n",
       " 'start_ coffee ,  please . _end',\n",
       " 'start_ do as you like . _end',\n",
       " 'start_ do as you like . _end',\n",
       " 'start_ do you like it ? _end',\n",
       " 'start_ do you love me ? _end',\n",
       " 'start_ dont back off . _end',\n",
       " 'start_ dont back off . _end',\n",
       " 'start_ dont cry ,  tom . _end',\n",
       " 'start_ dont get lost . _end',\n",
       " 'start_ dont touch it . _end',\n",
       " 'start_ eat more fruit . _end',\n",
       " 'start_ eat more fruit . _end',\n",
       " 'start_ get me a drink . _end',\n",
       " 'start_ get on the bus . _end',\n",
       " 'start_ get on the bus . _end',\n",
       " 'start_ get out of bed ! _end',\n",
       " 'start_ give it a rest . _end',\n",
       " 'start_ go talk to tom . _end',\n",
       " 'start_ go to the park . _end',\n",
       " 'start_ go to the park . _end',\n",
       " 'start_ go wake tom up . _end',\n",
       " 'start_ go wake tom up . _end',\n",
       " 'start_ happy new year ! _end',\n",
       " 'start_ happy new year ! _end',\n",
       " 'start_ he is a doctor . _end',\n",
       " 'start_ he is a doctor . _end',\n",
       " 'start_ hes in prison . _end',\n",
       " 'start_ here is a book . _end',\n",
       " 'start_ his head ached . _end',\n",
       " 'start_ hold tom tight . _end',\n",
       " 'start_ how can i help ? _end',\n",
       " 'start_ how can i help ? _end',\n",
       " 'start_ i am too short . _end',\n",
       " 'start_ i am too short . _end',\n",
       " 'start_ i borrow money . _end',\n",
       " 'start_ i dont see it . _end',\n",
       " 'start_ i drank coffee . _end',\n",
       " 'start_ i drank coffee . _end',\n",
       " 'start_ i feel a draft . _end',\n",
       " 'start_ i feel at ease . _end',\n",
       " 'start_ i feel at ease . _end',\n",
       " 'start_ i feel for you . _end',\n",
       " 'start_ i gave up hope . _end',\n",
       " 'start_ i got divorced . _end',\n",
       " 'start_ i have no clue . _end',\n",
       " 'start_ i have no idea . _end',\n",
       " 'start_ i have no idea . _end',\n",
       " 'start_ i have no kids . _end',\n",
       " 'start_ i have nothing . _end',\n",
       " 'start_ i have the key . _end',\n",
       " 'start_ i have to know . _end',\n",
       " 'start_ i have to know . _end',\n",
       " 'start_ i have to rest . _end',\n",
       " 'start_ i have to wait . _end',\n",
       " 'start_ i hear its ok . _end',\n",
       " 'start_ i hope its ok . _end',\n",
       " 'start_ i hope its ok . _end',\n",
       " 'start_ i hope its ok . _end',\n",
       " 'start_ i love parties . _end',\n",
       " 'start_ i love parties . _end',\n",
       " 'start_ i made cookies . _end',\n",
       " 'start_ i may know tom . _end',\n",
       " 'start_ i need my coat . _end',\n",
       " 'start_ i need my coat . _end',\n",
       " 'start_ i often travel . _end',\n",
       " 'start_ i often travel . _end',\n",
       " 'start_ i speak french . _end',\n",
       " 'start_ i teach french . _end',\n",
       " 'start_ i was impolite . _end',\n",
       " 'start_ id like to go . _end',\n",
       " 'start_ ill come ,  too . _end',\n",
       " 'start_ ill find work . _end',\n",
       " 'start_ ill see to it . _end',\n",
       " 'start_ ill stay home . _end',\n",
       " 'start_ ill teach tom . _end',\n",
       " 'start_ ill teach tom . _end',\n",
       " 'start_ ill treat you . _end',\n",
       " 'start_ im a busy guy . _end',\n",
       " 'start_ im a musician . _end',\n",
       " 'start_ im a musician . _end',\n",
       " 'start_ im against it . _end',\n",
       " 'start_ im an atheist . _end',\n",
       " 'start_ im behind him . _end',\n",
       " 'start_ im mad at you . _end',\n",
       " 'start_ im quite busy . _end',\n",
       " 'start_ im quite busy . _end',\n",
       " 'start_ im so ashamed . _end',\n",
       " 'start_ im thirty now . _end',\n",
       " 'start_ im unemployed . _end',\n",
       " 'start_ im unemployed . _end',\n",
       " 'start_ im unemployed . _end',\n",
       " 'start_ im unemployed . _end',\n",
       " 'start_ im very happy . _end',\n",
       " 'start_ im very happy . _end',\n",
       " 'start_ ive forgotten . _end',\n",
       " 'start_ ive forgotten . _end',\n",
       " 'start_ ive seen that . _end',\n",
       " 'start_ is this french ? _end',\n",
       " 'start_ isnt it black ? _end',\n",
       " 'start_ it was amusing . _end',\n",
       " 'start_ it was my idea . _end',\n",
       " 'start_ it will happen . _end',\n",
       " 'start_ its all right . _end',\n",
       " 'start_ its dangerous ! _end',\n",
       " 'start_ its hot today . _end',\n",
       " 'start_ its too large . _end',\n",
       " 'start_ its unnatural . _end',\n",
       " 'start_ its up to you . _end',\n",
       " 'start_ its very cold . _end',\n",
       " 'start_ its your book . _end',\n",
       " 'start_ its your home . _end',\n",
       " 'start_ its your loss . _end',\n",
       " 'start_ its your move . _end',\n",
       " 'start_ its your turn . _end',\n",
       " 'start_ leave it to me . _end',\n",
       " 'start_ leave it to me . _end',\n",
       " 'start_ leave me alone ! _end',\n",
       " 'start_ leave me alone ! _end',\n",
       " 'start_ lets continue . _end',\n",
       " 'start_ lets continue . _end',\n",
       " 'start_ lets hurry up . _end',\n",
       " 'start_ lets hurry up . _end',\n",
       " 'start_ lets hurry up . _end',\n",
       " 'start_ lets practice . _end',\n",
       " 'start_ lets practice . _end',\n",
       " 'start_ lets split it . _end',\n",
       " 'start_ lets watch tv . _end',\n",
       " 'start_ make it happen . _end',\n",
       " 'start_ mary looks hot . _end',\n",
       " 'start_ may i join you ? _end',\n",
       " 'start_ may i kiss you ? _end',\n",
       " 'start_ may i kiss you ? _end',\n",
       " 'start_ my joints ache . _end',\n",
       " 'start_ my joints ache . _end',\n",
       " 'start_ my tooth hurts . _end',\n",
       " 'start_ please come in . _end',\n",
       " 'start_ prices went up . _end',\n",
       " 'start_ say it clearly . _end',\n",
       " 'start_ see you around . _end',\n",
       " 'start_ see you around . _end',\n",
       " 'start_ shall we dance ? _end',\n",
       " 'start_ she grew roses . _end',\n",
       " 'start_ sugar is sweet . _end',\n",
       " 'start_ take your time . _end',\n",
       " 'start_ tell me a joke . _end',\n",
       " 'start_ thats my book . _end',\n",
       " 'start_ thats too bad . _end',\n",
       " 'start_ the birds sang . _end',\n",
       " 'start_ the birds sang . _end',\n",
       " 'start_ they both work . _end',\n",
       " 'start_ they both work . _end',\n",
       " 'start_ they both work . _end',\n",
       " 'start_ they both work . _end',\n",
       " 'start_ they both work . _end',\n",
       " 'start_ they hated tom . _end',\n",
       " 'start_ they quarreled . _end',\n",
       " 'start_ this isnt fun . _end',\n",
       " 'start_ time to get up . _end',\n",
       " 'start_ tom cant cook . _end',\n",
       " 'start_ tom cant walk . _end',\n",
       " 'start_ tom cant walk . _end',\n",
       " 'start_ tom is so rude . _end',\n",
       " 'start_ tom likes cats . _end',\n",
       " 'start_ tom looks cool . _end',\n",
       " 'start_ tom looks pale . _end',\n",
       " 'start_ tom wasnt fat . _end',\n",
       " 'start_ tom wont care . _end',\n",
       " 'start_ toms not busy . _end',\n",
       " 'start_ we drank a lot . _end',\n",
       " 'start_ we were eating . _end',\n",
       " 'start_ we were eating . _end',\n",
       " 'start_ well ,  lets go . _end',\n",
       " 'start_ what do you do ? _end',\n",
       " 'start_ whats his job ? _end',\n",
       " 'start_ whens it over ? _end',\n",
       " 'start_ where is paris ? _end',\n",
       " 'start_ where is paris ? _end',\n",
       " 'start_ where was that ? _end',\n",
       " 'start_ where was that ? _end',\n",
       " 'start_ where were you ? _end',\n",
       " 'start_ where were you ? _end',\n",
       " 'start_ why do you ask ? _end',\n",
       " 'start_ wipe your nose . _end',\n",
       " 'start_ yes ,  i know it . _end',\n",
       " 'start_ you could help . _end',\n",
       " 'start_ you could help . _end',\n",
       " 'start_ you could help . _end',\n",
       " 'start_ you could help . _end',\n",
       " 'start_ you could help . _end',\n",
       " 'start_ you look awful . _end',\n",
       " 'start_ you look bored . _end',\n",
       " 'start_ you look tired . _end',\n",
       " 'start_ you look tired . _end',\n",
       " 'start_ youre kidding ! _end',\n",
       " 'start_ youre kidding ! _end',\n",
       " 'start_ youre kidding ! _end',\n",
       " 'start_ youre kidding ! _end',\n",
       " 'start_ a man must work . _end',\n",
       " 'start_ a man must work . _end',\n",
       " 'start_ am i reinstated ? _end',\n",
       " 'start_ am i reinstated ? _end',\n",
       " 'start_ am i understood ? _end',\n",
       " 'start_ am i understood ? _end',\n",
       " 'start_ anybody can try . _end',\n",
       " 'start_ anybody can try . _end',\n",
       " 'start_ anybody miss me ? _end',\n",
       " 'start_ anybody see you ? _end',\n",
       " 'start_ are those yours ? _end',\n",
       " 'start_ are those yours ? _end',\n",
       " 'start_ are those yours ? _end',\n",
       " 'start_ are we finished ? _end',\n",
       " 'start_ are we finished ? _end',\n",
       " 'start_ are we prepared ? _end',\n",
       " 'start_ are we prepared ? _end',\n",
       " 'start_ are you at home ? _end',\n",
       " 'start_ are you doctors ? _end',\n",
       " 'start_ are you doctors ? _end',\n",
       " 'start_ are you injured ? _end',\n",
       " 'start_ are you injured ? _end',\n",
       " 'start_ are you injured ? _end',\n",
       " 'start_ are you injured ? _end',\n",
       " 'start_ are you jealous ? _end',\n",
       " 'start_ are you jealous ? _end',\n",
       " 'start_ are you leaving ? _end',\n",
       " 'start_ are you leaving ? _end',\n",
       " 'start_ are you leaving ? _end',\n",
       " 'start_ are you leaving ? _end',\n",
       " 'start_ are you nervous ? _end',\n",
       " 'start_ are you nervous ? _end',\n",
       " 'start_ are you nervous ? _end',\n",
       " 'start_ are you psychic ? _end',\n",
       " 'start_ are you sisters ? _end',\n",
       " ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dense-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "neutral-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "above-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11976 11976 2994 2994\n"
     ]
    }
   ],
   "source": [
    "print(len(source_train_tensor), len(target_train_tensor), len(source_test_tensor), len(target_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "undefined-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "front-compound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> start_\n",
      "67 ----> къде\n",
      "11 ----> се\n",
      "602 ----> намира\n",
      "2026 ----> пощата\n",
      "9 ----> ?\n",
      "3 ----> _end\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> start_\n",
      "100 ----> where\n",
      "12 ----> is\n",
      "9 ----> the\n",
      "1150 ----> post\n",
      "375 ----> office\n",
      "10 ----> ?\n",
      "3 ----> _end\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(source_sentence_tokenizer, source_train_tensor[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(target_sentence_tokenizer, target_train_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-language",
   "metadata": {},
   "source": [
    "#### Create a TF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "played-professor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(source_train_tensor)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(source_sentence_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(target_sentence_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "contemporary-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 47]), TensorShape([64, 48]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-institute",
   "metadata": {},
   "source": [
    "#### Write the encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "significant-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "finnish-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 47, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "speaking-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "known-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 47, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "crude-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "spare-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4561)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-renewal",
   "metadata": {},
   "source": [
    "#### Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "constitutional-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "headed-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-attribute",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-least",
   "metadata": {},
   "source": [
    "Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
    "The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
    "The decoder returns the predictions and the decoder hidden state.\n",
    "The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "Use teacher forcing to decide the next input to the decoder.\n",
    "Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
    "The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "signed-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "attended-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "psychological-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.3879\n",
      "Epoch 1 Batch 100 Loss 0.7189\n",
      "Epoch 1 Loss 0.7892\n",
      "Time taken for 1 epoch 256.261905670166 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.6714\n",
      "Epoch 2 Batch 100 Loss 0.5815\n",
      "Epoch 2 Loss 0.6123\n",
      "Time taken for 1 epoch 203.41360473632812 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.5404\n",
      "Epoch 3 Batch 100 Loss 0.4835\n",
      "Epoch 3 Loss 0.5129\n",
      "Time taken for 1 epoch 200.62329840660095 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4661\n",
      "Epoch 4 Batch 100 Loss 0.4789\n",
      "Epoch 4 Loss 0.4180\n",
      "Time taken for 1 epoch 203.89607048034668 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.3243\n",
      "Epoch 5 Batch 100 Loss 0.3507\n",
      "Epoch 5 Loss 0.3276\n",
      "Time taken for 1 epoch 201.07072496414185 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2377\n",
      "Epoch 6 Batch 100 Loss 0.2755\n",
      "Epoch 6 Loss 0.2483\n",
      "Time taken for 1 epoch 204.7037148475647 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1883\n",
      "Epoch 7 Batch 100 Loss 0.1862\n",
      "Epoch 7 Loss 0.1811\n",
      "Time taken for 1 epoch 201.03500533103943 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1658\n",
      "Epoch 8 Batch 100 Loss 0.1265\n",
      "Epoch 8 Loss 0.1293\n",
      "Time taken for 1 epoch 204.70975542068481 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0687\n",
      "Epoch 9 Batch 100 Loss 0.1004\n",
      "Epoch 9 Loss 0.0912\n",
      "Time taken for 1 epoch 201.01731944084167 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0537\n",
      "Epoch 10 Batch 100 Loss 0.0755\n",
      "Epoch 10 Loss 0.0639\n",
      "Time taken for 1 epoch 203.75670385360718 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0439\n",
      "Epoch 11 Batch 100 Loss 0.0442\n",
      "Epoch 11 Loss 0.0463\n",
      "Time taken for 1 epoch 200.9589080810547 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0315\n",
      "Epoch 12 Batch 100 Loss 0.0346\n",
      "Epoch 12 Loss 0.0332\n",
      "Time taken for 1 epoch 203.74449467658997 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0228\n",
      "Epoch 13 Batch 100 Loss 0.0227\n",
      "Epoch 13 Loss 0.0252\n",
      "Time taken for 1 epoch 200.86977362632751 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0132\n",
      "Epoch 14 Batch 100 Loss 0.0299\n",
      "Epoch 14 Loss 0.0182\n",
      "Time taken for 1 epoch 203.50353169441223 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0108\n",
      "Epoch 15 Batch 100 Loss 0.0169\n",
      "Epoch 15 Loss 0.0137\n",
      "Time taken for 1 epoch 200.85957598686218 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "julian-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  #print(sentence)\n",
    "  #print(source_sentence_tokenizer.word_index)\n",
    "\n",
    "  inputs = []\n",
    "  for i in sentence.split(' '):\n",
    "    try:\n",
    "        inputs.append(source_sentence_tokenizer.word_index[i])\n",
    "    except:\n",
    "        inputs.append(0)\n",
    "        \n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_source_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
    "\n",
    "  for t in range(max_target_length):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "round-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "  \n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-shore",
   "metadata": {},
   "source": [
    "<a id='translation_cell'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-visiting",
   "metadata": {},
   "source": [
    "### Translating the data from Section I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-trout",
   "metadata": {},
   "source": [
    "#### Unfortunately a lot of proverb words are not present in the ManyThings corpus so I had to edit the evaluate function skip the unknown words\n",
    "Lets view the translation for the model with the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "resistant-marriage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: start_ голяма мечка с мравки не се насища а се познава той ще сполучи рога му минава му трябва да яде а като се качват _end\n",
      "Translation: there is no one of my knowledge , but be more than it looks like it . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ кърпиш се раждат хора а умират магарета през свинско а се отнема с иглата а се познава по малко хитрувай тояга от  нагоре _end\n",
      "Translation: there are no people have no more than it looks like it in practice . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ магаре от срам не разбира само — вика но не се вари леща ли ще го направи пука му го да го отричаш другиго _end\n",
      "Translation: it looks like im not really doesnt even bother it . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ жена и кокошка синор нямат пари и все е и с пари да дават да ти е як да не ти пука другиго и _end\n",
      "Translation: though his wife and though the bicycle may have beautiful , but she was ever got to . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ мъж — като лайно на дъжд а керемидчията — слънце се качват други слизат е голяма за утре не се в праха насред другиго _end\n",
      "Translation: in my opinion on the right back seemed to have twins . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ бълха не пада по далеч не стига но далеч не стига но — дваж вика под праха му го в положението на другиго мед _end\n",
      "Translation: it doesnt have a bad at any people didnt have enough less late . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ кучето скача според тоягата виновната котка ще избяга умира и той цяло вдига шум разтръбява и предизвиква емоции негодувание възмущение за нещо несъществено несериозно _end\n",
      "Translation: the dog is an accident , the bicycle will not worth though the bicycle will not worth though the bicycle will not worth though the bicycle will not worth though the bicycle will not worth though the bicycle will not worth though the bicycle will not worth though \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ бавно камъчето си хвали своите метли го мързи отдавна да е умрял не го яде а го чернят не бързай да го отричаш предварително _end\n",
      "Translation: the bananas you usually call me when you pass the way to have to me when i will light is not to me . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ работа не се хубавее а се гърбавее през стария го уловил я никне в ръката му се познава а му го му го го _end\n",
      "Translation: every man has not to have no way from his way . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ учи се от мал кога остарееш да не ти е жал а му торбата му е и сам в праха насред мегдана го възмущение _end\n",
      "Translation: sitting out of any happier in my computer is not an apple and its not an apple and its not an apple and its not an apple and its not an apple and its not an apple and its not an apple and its not an apple and \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ зло не се вади за рогата а му се да не е който прави ножове а който убива с тях мед тояга другиго другиго _end\n",
      "Translation: you wouldnt be the only one who thinks nothing to get up . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ добро и насън си изкарва хляба да ядеш е як гърбът гърбът да го срещаш мед — голяма нещо ли го срещнеш несъществено несериозно _end\n",
      "Translation: it and youre going to get up it looks like it now . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ котка по гърб не пада по далеч от дървото се стига — под праха насред мегдана го жени цялото село нещо го несериозно цялото _end\n",
      "Translation: in the cat until you didnt have a basic human heard . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ агнето го гледай по опашката а ярето по гърдите зад по голямата око за око така като че ли ще умреш утре ли го _end\n",
      "Translation: it looks like it stop , but it looks like it up on it . _end \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ пешеходец вечер се разработват дано рада излезе мома опашка му го от хайвера та й го трябва да го живеем му му му му _end\n",
      "Translation: the train make it was already got to his way to his way to his way to his way to his way to his way to his way to his way to his way to his way to his way to his way to his way to his \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Input: start_ програмиране вечер се разработват дано рада излезе мома опашка му го от хайвера та й го трябва да го живеем му му му му _end\n",
      "Translation: the twins sometimes i feel sick it looks like it looks like it looks like it looks like it looks like it looks like it looks like it looks like it looks like it looks like it looks like it looks like it looks like it looks like \n",
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for pred in double_bilstm_more_epochs_and_units_larger_embedding_dim_second_model_result:\n",
    "    translate(pred)\n",
    "    print('-' * 125)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-questionnaire",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-nightmare",
   "metadata": {},
   "source": [
    "I can definitely say that the predictions I got within the second section are not very impressive, however it was not the main focus of my project. With more training and an improved dataset, the translations should improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-midnight",
   "metadata": {},
   "source": [
    "## Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-battle",
   "metadata": {},
   "source": [
    "In the first and main section of this project I attempted to generate some proverb-like text and I believe I got some decent results. To achieve the proverb predictions, I used Bulgarian proverbs available online and a variety of BiLSTM models. The generated proverbs made some sense, however I believe the models require more training - more epochs/data. <br><br> In the second section I attempted to translate the results of one of the generators to English. Unfortunately the translation dataset provided by ManyThings did not include a lot of words that were present within the generated proverbs. The translation model also required more training so I got some questionable results. <br> <br> Nontheless this was an interesting experiment for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-charity",
   "metadata": {},
   "source": [
    "### Self-assessment:\n",
    "1. Problem statement 8\n",
    "2. Layout: 15\n",
    "3. Code quality: 16\n",
    "4. Gathering / generating, cleaning, and formatting data 7\n",
    "5. Testing 7\n",
    "6. Visualization 6\n",
    "7. Communication 8"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
